{
  "pages": [
    {
      "markdown": "# MUDiff: Unified Diffusion for Complete Molecule Generation \n\nChenqing Hua<br>McGill University; Mila<br>chenqing.hua@mail.mcgill.ca<br>Sitao Luan<br>McGill University; Mila<br>sitao.luan@mail.mcgill.ca<br>Minkai Xu<br>Stanford University<br>minkai@cs.stanford.edu<br>Rex Ying<br>Yale University<br>rex.ying@yale.edu<br>Jie Fu*<br>HKUST; Mila<br>jiefu@ust.hk<br>Stefano Ermon<br>Stanford University<br>ermon@cs.stanford.edu\n\n## Doina Precup <br> McGill University; Mila <br> dprecup@cs.mcgill.ca\n\n\n#### Abstract\n\nMolecule generation is a very important practical problem, with uses in drug discovery and material design, and AI methods promise to provide useful solutions. However, existing methods for molecule generation focus either on 2D graph structure or on 3D geometric structure, which is not sufficient to represent a complete molecule as 2D graph captures mainly topology while 3D geometry captures mainly spatial atom arrangements. Combining these representations is essential to better represent a molecule. In this paper, we present a new model for generating a comprehensive representation of molecules, including atom features, 2D discrete molecule structures, and 3D continuous molecule coordinates, by combining discrete and continuous diffusion processes. The use of diffusion processes allows for capturing the probabilistic nature of molecular processes and exploring the effect of different factors on molecular structures. Additionally, we propose a novel graph transformer architecture to denoise the diffusion process. The transformer adheres to 3D roto-translation equivariance constraints, allowing it to learn invariant atom and edge representations while preserving the equivariance of atom coordinates. This transformer can be used to learn molecular representations robust to geometric transformations. We evaluate the performance of our model through experiments and comparisons with existing methods, showing its ability to generate more stable and valid molecules. Our model is a promising approach for designing stable and diverse molecules and can be applied to a wide range of tasks in molecular modeling. Our codes and models are available on https://github.com/WillHua127/mudiff\n\n\n## 1 Introduction\n\nGenerative models for molecules in machine learning have gained significant attention in recent years as a promising approach for the design and discovery of novel molecules with desired properties [1-3]. These models are trained on a dataset of known molecular structures and can then generate unseen molecules similar to those in the training dataset. As one specific type of generative models, diffusion models are based on the idea of learning small changes in the molecular structures [4]. The model learns the likelihood of these changes and can generate new molecules by sampling from the learned distribution. This approach has been used to generate new drug candidates, optimize drug properties, etc.[4-6].\nWhile 2D graph structures capture the topology and connectivity of molecules [7, 8], 3D geometric structures provide an insight into the spatial arrangements of atoms [3, 9], the two structural information are essential for a comprehensive representation of a molecule. So, learning 2D and 3D structures together leads to an accurate and complete molecule representation. However, existing generative models for molecules focus solely on either 2D or 3D molecular data generation [2, 4, 6], thus\n\n[^0]\n[^0]:    *Corresponding to Jie Fu: jiefu@ust.hk"
    },
    {
      "markdown": "limiting their ability to exploit an accurate and complete representation of molecules. This limitation highlights the need for joint generation and learning of 2D and 3D molecular data, and motivates us to work on the joint generation problem. To address the gap, we are motivated to propose a novel generative model that jointly generates 2D and 3D molecular data, capturing both the topological information from 2D graphs, and spatial atom arrangements from 3D geometry, thereby enabling a more holistic understanding of molecular structures.\n\nIn this paper, we present a novel approach to overcome the aforementioned limitations by jointly generating 2D and 3D aspects of molecules, yielding a complete representation of molecules by learning the graph connectivity and atom arrangements together. We propose a diffusion generative model that co-generates the 2D graph structure and 3D geometric structure of a molecule, named MUDiff, and a transformer model that co-learns both molecular structures, named MUformer. Our diffusion model simultaneously adds continuous noises to the continuous features, including atom features and coordinates, and discrete noises to the categorical features, including the graph structure. The denoising model then makes predictions for the clean graph structure, as well as estimations of noises for atom features and coordinates, The primary innovation of our denoising transformer model lies in designing an attention mechanism that facilitates interaction between 2D and 3D structural information. This design enables our transformer to concurrently compute graph connectivity and spatial atom arrangements. Moreover, when computing 3D geometric structures, the denoising transformer model adheres to the critical 3D roto-translation equivariance constraints. This compliance ensures insensitivity to geometric transformations on the molecule, allowing the entire diffusion process to adhere to these constraints. Through the novel designs, our model can generate and learn a comprehensive molecular representation that captures both 2D and 3D structures, addressing the aforementioned limitations.\n\nFurthermore, a distinct advantage of MUDiff and MUformer is the ability to function independently when either 2D or 3D structural information is missing. Our model remains effective in generating and learning a complete representation of molecules, even when the input data lacks the 2D graph structure or the 3D geometric structure. This design is particularly useful because datasets sometimes have missing 3D coordinates and geometry, resulted from limitations in experimental techniques or the unavailability of suitable computational resources [10]. For instance, the conformational analysis of molecules, which involves determining the 3D structures that result from the rotation of single bonds, is of critical importance in understanding molecular interactions [11, 12]. However, obtaining accurate conformational data can be computationally demanding [13]. In such cases, MUDiff and MUformer can provide a robust and versatile solution for handling incomplete molecular datasets, ensuring comprehensive molecular representations even when faced with such challenges.\n\nEmperically, MUDiff generates $7.9 \\%$ more stable molecules and increases molecular uniqueness by $2 \\%$ compared to existing methods (see Sec 6.2). Additionally, even when trained with limited 3D structures, MUDiff still achieve competitive performance compared to existing methods trained with complete 3D structures (see Sec 6.1). The results show the better model performance in generating stable and valid molecules, emphasizing the importance of joint 2D and 3D molecule generation for advancing the field. In Sec 3, we present the molecule unified diffusion model (MUDiff), followed by the introduction of the molecule unified transformer model (MUformer) in Sec 4 and App A. The MUformer architecture is visually demonstrated in Fig 1. Detailed experimental results can be found in Sec 6 and App D.\n\n# 2 Preliminaries \n\n### 2.1 Diffusion Models\n\nDiffusion models consist of a noising model and a denoising network. The noising model $q$ adds noise to a data point $\\mathbf{X}$ to generate a sequence of noisy points $\\left\\{\\tilde{\\mathbf{X}}_{t}\\right\\}_{t=0}^{T}$. This process follows the Markov property, $q\\left(\\tilde{\\mathbf{X}}_{0}, \\ldots, \\tilde{\\mathbf{X}}_{T} \\mid \\mathbf{X}\\right)=q\\left(\\tilde{\\mathbf{X}}_{0} \\mid \\mathbf{X}\\right) \\prod_{t=1}^{T} q\\left(\\tilde{\\mathbf{X}}_{t} \\mid \\tilde{\\mathbf{X}}_{t-1}\\right)$. The denoising network $\\psi_{\\theta}$ aims to reverse the noising process: given a noisy point $\\tilde{\\mathbf{X}}_{t}$, it predicts a clean estimate $\\hat{\\mathbf{X}}=\\psi_{\\theta}\\left(\\tilde{\\mathbf{X}}_{t}, t\\right)$ of $\\mathbf{X}$.\nContinuous Data The noising process in diffusion models for continuous data point $\\mathbf{X}$ can be represented by a multivariate normal distribution, $q\\left(\\tilde{\\mathbf{X}}_{t} \\mid \\mathbf{X}\\right)=\\mathcal{N}\\left(\\tilde{\\mathbf{X}}_{t} \\mid \\alpha_{t} \\mathbf{X}, \\sigma_{t}^{2} \\mathbf{I}\\right)$, where $\\alpha_{t} \\in \\mathbb{R}^{+}$ controls the amount of signal retained and $\\sigma_{t} \\in \\mathbb{R}^{+}$represents the amount of Gaussian noise added, and $\\alpha_{t}$ smoothly transitions from 1 to 0 . Following [14], we choose $\\alpha_{t}=\\sqrt{1-\\sigma_{t}^{2}}$ in order to obtain a variance preserving process, and the signal-to-noise ratio $\\operatorname{SNR}(t)=\\alpha_{t}^{2} / \\sigma_{t}^{2}$ is defined by [15]. For every two time steps $t, t-1$, the noising process is $q\\left(\\tilde{\\mathbf{X}}_{t} \\mid \\tilde{\\mathbf{X}}_{t-1}\\right)=\\mathcal{N}\\left(\\tilde{\\mathbf{X}}_{t} \\mid \\alpha_{t \\mid t-1} \\tilde{\\mathbf{X}}_{t-1}, \\sigma_{t \\mid t-1}^{2} \\mathbf{I}\\right)$, where $\\alpha_{t \\mid t-1}=\\alpha_{t} / \\alpha_{t-1}$ and $\\sigma_{t \\mid t-1}^{2}=\\sigma_{t}^{2}-\\alpha_{t \\mid t-1}^{2} \\sigma_{t-1}^{2}$."
    },
    {
      "markdown": "The posterior of the transitions gives the denoising process, $q\\left(\\hat{\\mathbf{X}}_{t-1} \\mid \\hat{\\mathbf{X}}_{t}, \\mathbf{X}\\right)=$ $\\mathcal{N}\\left(\\hat{\\mathbf{X}}_{t-1} \\mid \\boldsymbol{\\mu}_{t \\rightarrow t-1}\\left(\\hat{\\mathbf{X}}_{t}, \\mathbf{X}\\right), \\sigma_{t \\rightarrow t-1}^{2} \\mathbf{I}\\right)$, where the functions are defined as $\\boldsymbol{\\mu}_{t \\rightarrow t-1}\\left(\\hat{\\mathbf{X}}_{t}, \\mathbf{X}\\right)=$ $\\frac{\\alpha_{i|t-1} \\sigma_{t-1}^{2}}{\\sigma_{t}^{2}} \\hat{\\mathbf{X}}_{t}+\\frac{\\alpha_{t-1} \\sigma_{t|t-1}^{2}}{\\sigma_{t}^{2}} \\mathbf{X}, \\sigma_{t \\rightarrow t-1}=\\frac{\\sigma_{i|t-1} \\sigma_{t-1}}{\\sigma_{t}}$. In the true denoising process, the clean data $\\mathbf{X}$ is unknown, so it is replaced by the network approximation $\\hat{\\mathbf{X}}$ as,\n\n$$\np\\left(\\hat{\\mathbf{X}}_{t-1} \\mid \\hat{\\mathbf{X}}_{t}\\right)=\\mathcal{N}\\left(\\hat{\\mathbf{X}}_{t-1} \\mid \\boldsymbol{\\mu}_{t \\rightarrow t-1}\\left(\\hat{\\mathbf{X}}_{t}, \\hat{\\mathbf{X}}\\right), \\sigma_{t \\rightarrow t-1}^{2} \\mathbf{I}\\right)\n$$\n\nDiscrete Data Discrete objects, such as graph structures, may not be well suited for Gaussian noise models as they can destroy sparsity and connectivity, as suggested by [6]. Following [6, 16], we use a series of transition matrices $\\left\\{Q_{t}\\right\\}_{t=0}^{T}$ to represent noise on one-hot encoded discrete data points, where $Q_{t_{i j}}=q\\left(\\mathbf{X}_{t}=j \\mid \\mathbf{X}_{t-1}=i\\right)$ is the probability of transitioning from state $i$ to state $j$. We obtain noisy data by multiplying the clean data point with a transition matrix, $q\\left(\\hat{\\mathbf{X}}_{t} \\mid \\hat{\\mathbf{X}}_{t-1}\\right)=\\hat{\\mathbf{X}}_{t} Q_{t}, q\\left(\\hat{\\mathbf{X}}_{t} \\mid \\mathbf{X}\\right)=\\mathbf{X} \\tilde{Q}_{t}$, where $\\tilde{Q}_{t}=Q_{t} Q_{t-1} \\ldots Q_{0}$. The posterior distribution is computed using the Bayes rule, $q\\left(\\hat{\\mathbf{X}}_{t-1} \\mid \\hat{\\mathbf{X}}_{t}, \\mathbf{X}\\right) \\propto \\hat{\\mathbf{X}}_{t} Q_{t}^{T} \\odot \\mathbf{X} \\tilde{Q}_{t-1}$, where $Q^{T}$ represents the transpose of the transition matrix $Q$, and $\\odot$ denotes the Hadamard product.\n\n# 2.2 The Basics of Molecules \n\nA molecule is a group of atoms held together by chemical bonds, which can be classified into various types based on the nature of the bond. The structure of a molecule can be visualized and represented in both 2D and 3D forms, with the 2D representation showing the connectivity of the atoms and the 3D representation showing the arrangement of the atoms in space. To completely describe a molecule, we represent it as a tuple $\\mathbf{M}=(\\mathbf{H}, \\mathbf{E}, \\mathbf{X})$, where $\\mathbf{H} \\in \\mathbb{R}^{n \\times d}$ denotes the collection of atoms, $n$ is the number of atoms, and $d$ is the feature dimension; $\\mathbf{E} \\in \\mathbb{R}^{n \\times n \\times b}$ is the 2 D graph representation for chemical bonds, the bond type is represented by one-hot encoding, and $b$ is the number of bond(edge) types; $\\mathbf{X} \\in \\mathbb{R}^{n \\times 3}$ represents the 3D geometric structure and each row indicates the position of the atom in the Euclidean space. For simplicity, we assume that molecules are fully connected and include no-bond as a special edge type. To account for symmetry, we use symmetric edge representations, i.e., $\\mathbf{E}=\\mathbf{E}^{T}$.\n3D Molecule Representation For each pair of atoms $(i, j)$ in the 3D space, we process the Euclidean distance between them using an exponential normal radial basis function [9], i.e., $f_{\\mathrm{RBF}^{b}}\\left(d_{i j}\\right)=\\exp \\left(-\\beta_{k}\\left(\\exp \\left(-d_{i j}\\right)-\\mu_{k}\\right)^{2}\\right)$, where $k$ is the number of basis kernels, $d_{i j}$ is the distance between atoms $i$ and $j, \\beta_{k}$ and $\\mu_{k}$ are fixed parameters determining the function's center, and width, respectively. These parameters are initialized as per [17].\nTo smooth out the transition to 0 as the distance $d_{i j}$ approaches a cutoff distance of $d_{\\text {cut }}=5 \\AA$, we also apply a cosine cutoff function $f_{\\text {cos }}\\left(d_{i j}\\right)$, i.e., $f_{\\text {cos }}\\left(d_{i j}\\right)=\\frac{1}{2}\\left(\\cos \\left(\\frac{\\pi d_{i j}}{d_{\\text {cut }}}\\right)+1\\right)$ if $d_{i j} \\leq d_{\\text {cut }}$, and $f_{\\text {cos }}\\left(d_{i j}\\right)=0$ if $d_{i j}>d_{\\text {cut }}$. In the model, we will use both $f_{\\text {cos }}\\left(d_{i j}\\right)$ and $f_{\\text {cos }}\\left(f_{\\mathrm{RBF}^{b}}\\left(d_{i j}\\right)\\right)$.\n\n## 3 MUDiff: Molecule Unified Diffusion\n\nBoth the continuous and discrete elements of molecules are essential in order to depict a comprehensive molecular representation, however, the existing models [2-4,6] have only been able to generate a portion of these components. Our diffusion model is designed to denoise continuous and discrete aspects of a molecule separately. The continuous aspects encompass atom features and 3D coordinates, while the discrete aspects include molecular structure. This separation allows for independent handling of atoms and edges, a similar approach is shown to be successful in image diffusion models [16], but unexplored for molecules. By jointly generating the continuous 3D geometry and discrete 2D graph representation, our model enhances the representation of atom and edge features, yielding a more comprehensive and holistic understanding of the molecule that incorporates both geometric and topological information.\n\n### 3.1 Diffusion Process\n\nOur diffusion model distinctly applies noises to atom and edge representations to enhance the generative process. Specifically, we apply continuous noises to atom representations, encompassing both atom features and coordinates, while introducing discrete noises to edge representations, which correspond to the graph structure. This targeted approach differentiates our diffusion process from previous molecule diffusion models, allowing for a more comprehensive generation of molecules that captures both geometric and topological information.\nAtom Features and Coordinates As introduced in Sec 2.1, we add Gaussian noise to atom features and coordinates at each time step $t$, with $\\boldsymbol{\\epsilon}_{\\mathbf{H}}^{\\mathrm{t}} \\sim \\mathcal{N}_{\\mathbf{H}}(\\mathbf{0}, \\mathbf{I}) \\in \\mathbb{R}^{n \\times d}, \\boldsymbol{\\epsilon}_{\\mathbf{X}}^{\\mathrm{t}} \\sim \\mathcal{N}_{\\mathbf{X}}(\\mathbf{0}, \\mathbf{I}) \\in \\mathbb{R}^{n \\times 3}$, where $n$ is the number of atoms, $d$ denotes the feature dimension. For the 3D coordinates, we follow [18] to"
    },
    {
      "markdown": "use the linear subspace of zero center of gravity for $\\mathcal{N}_{\\mathbf{X}}$ such that $\\sum_{i} \\mathbf{x}_{i}=0$. This leads to noisy atom features and coordinates,\n\n$$\n\\widehat{\\mathbf{H}}_{t}=\\alpha_{t} \\mathbf{H}+\\sigma_{t} \\boldsymbol{\\epsilon}_{\\mathbf{H}}^{t}, \\widehat{\\mathbf{X}}_{t}=\\alpha_{t} \\mathbf{X}+\\sigma_{t} \\boldsymbol{\\epsilon}_{\\mathbf{X}}^{t}\n$$\n\nThis method ensures that the perturbations applied to the 3D coordinates do not affect the center of gravity of the molecule, allowing for the denoising process to be invariant w.r.t. to translations.\nEdge Features Following Sec 2.1, we transform the discrete clean edge type to obtain noisy ones,\n\n$$\n\\widehat{\\mathbf{E}}_{t}=\\mathbf{E} \\hat{Q}_{t}\n$$\n\nwhere the transition matrix $\\hat{Q}_{t}$ is obtained by $\\hat{Q}_{t}=\\alpha_{t} \\mathbf{I}+\\left(1-\\alpha_{t}\\right) \\mathbb{1}_{b} \\mathbb{1}_{b}^{t} / b \\in \\mathbb{E}^{b \\times b}$. We use uniform transitions over the number of edge types $b[6,16]$, resulting in a uniform limit distribution $q_{\\infty}$ over edge categories (see App E). Additionally, since molecules are always undirected graphs, we only apply noise to the upper triangular of the edge representation matrix and then symmetrize the matrix, which ensures that changes made on the edges are consistent across the graph.\n\n### 3.2 Denoising Process\n\nTo date, no existing models can simultaneously predict the features of atoms $\\mathbf{H}$, their coordinates $\\mathbf{X}$, and the structures of molecules $\\mathbf{E}$. To address this gap, we introduce a novel denoising network, named MUformer, which learns the denoising process to make predictions for the comprehensive representation of molecules. This model is unique in its ability to consider all aspects of the molecule in a unified manner while ensuring that the denoising process is equivariant, as suggested by [3].\n\nThe denoising network, denoted by $\\psi_{\\theta}$, takes as input a noisy molecule $\\widehat{\\mathbf{M}}_{t}=\\left(\\widehat{\\mathbf{H}}_{t}, \\widehat{\\mathbf{E}}_{t}, \\widehat{\\mathbf{X}}_{t}\\right)$ and outputs estimates for the clean molecule $\\widehat{\\mathbf{M}}$. The detailed architecture and methodology of MUformer are presented in Sec 4, showcasing its capacity to generate comprehensive molecular representations that encompass atom features, coordinates, and molecular structures.\nNetwork Estimation Instead of directly predicting the atom representations $\\hat{\\mathbf{H}}, \\widehat{\\mathbf{X}}$, the network attempts to predict the Gaussian noises for atom features and coordinates $\\hat{\\boldsymbol{\\epsilon}}_{\\mathbf{H}}, \\hat{\\boldsymbol{\\epsilon}}_{\\mathbf{X}}$, as it has been shown to be easier to optimize in [14]. This approach allows the network to differentiate between the noise added by the noising process and the ground-truth representations, $\\mathbf{H}, \\mathbf{X}$. The network takes as input a noisy molecule, where atom features are concatenated with the normalized time step $\\frac{t}{T}$, and predicts the probability of edge features, as well as the estimates of noises for atom features and coordinates,\n\n$$\n\\hat{\\epsilon}_{\\mathbf{H}}^{t}, \\hat{\\epsilon}_{\\mathbf{X}}^{t}, p(\\hat{\\mathbf{E}})=\\psi_{\\theta}\\left(\\left[\\widehat{\\mathbf{H}}_{t}, \\frac{t}{T}\\right], \\widehat{\\mathbf{X}}_{t}, \\widehat{\\mathbf{E}}_{t}\\right)-\\left(\\mathbf{0}, \\widehat{\\mathbf{X}}_{t}, \\mathbf{0}\\right)\n$$\n\nwhere the input coordinates are then subtracted from the estimated noise for coordinates to ensure that the outputs lie on the zero center of gravity subspace, as suggested by [4]. We subsequently obtain estimates of atom features and coordinates by\n\n$$\n\\hat{\\mathbf{H}}=\\frac{1}{\\alpha_{t}} \\widehat{\\mathbf{H}}_{t}-\\frac{\\sigma_{t}}{\\alpha_{t}} \\hat{\\epsilon}_{\\mathbf{H}}^{t}, \\hat{\\mathbf{X}}=\\frac{1}{\\alpha_{t}} \\hat{\\mathbf{X}}_{t}-\\frac{\\sigma_{t}}{\\alpha_{t}} \\hat{\\epsilon}_{\\mathbf{X}}^{t}\n$$\n\nTraining Objective For atom features and coordinates, the objective is to accurately predict the true noise present in the observations of atom features and coordinates. To achieve this, we follow the approach outlined in [4] and minimize the distance between the true noise and the estimates of noise predicted by the network $\\psi_{\\theta}$. The objectives for atoms are defined as,\n\n$$\n\\mathcal{L}_{t}^{\\mathbf{H}}=\\frac{1}{2} \\mathbb{E}_{\\mathbf{e}_{\\mathbf{H}}^{\\prime} \\sim N_{\\mathbf{H}}(\\mathbf{0}, \\mathbf{I})}\\left[\\omega(t)\\left\\|\\boldsymbol{\\epsilon}_{\\mathbf{H}}^{t}-\\hat{\\boldsymbol{\\epsilon}}_{\\mathbf{H}}^{t}\\right\\|^{2}\\right], \\mathcal{L}_{t}^{\\mathbf{X}}=\\frac{1}{2} \\mathbb{E}_{\\mathbf{e}_{\\mathbf{X}}^{\\prime} \\sim N_{\\mathbf{X}}(\\mathbf{0}, \\mathbf{I})}\\left[\\omega(t)\\left\\|\\boldsymbol{\\epsilon}_{\\mathbf{X}}^{t}-\\hat{\\boldsymbol{\\epsilon}}_{\\mathbf{X}}^{t}\\right\\|^{2}\\right]\n$$\n\nwhere $\\omega(t)=(1-\\operatorname{SNR}(t-1) / \\operatorname{SNR}(t))$. To stabilize the training process, we set $\\omega(t)=1$ during the training phase, as suggested by $[4,14]$.\nTo handle edge features, we approach it as a classification problem and minimize the cross-entropy loss for each atom pair $(i, j) \\in \\mathbf{E}$. The loss is calculated between the actual edge type and the predicted edge probability distribution,\n\n$$\n\\mathcal{L}_{t}^{\\mathbf{E}}=\\mathbb{E}_{(i, j) \\sim \\mathbf{E}}\\left[\\mathbf{E}_{i j} \\log \\left(p\\left(\\hat{\\mathbf{E}}_{i j}\\right)\\right)\\right]\n$$\n\nAt every time step $t$, the total loss is computed as the sum of the three losses, $\\mathcal{L}_{t}=\\mathcal{L}_{t}^{\\mathbf{H}}+\\mathcal{L}_{t}^{\\mathbf{E}}+\\mathcal{L}_{t}^{\\mathbf{X}}$."
    },
    {
      "markdown": "The entire training process is described in Algorithm 1. Additionally, the derivation of the variational evidence lower bound on the likelihood can be found in App F.\nSampling Once the model is trained, it can be used to sample new molecules. The true sampling process $p\\left(\\tilde{\\mathbf{M}}_{t-1} \\mid \\tilde{\\mathbf{M}}_{t}\\right)$ uses the approximation of a complete molecule $\\tilde{\\mathbf{M}}=(\\tilde{\\mathbf{H}}, \\tilde{\\mathbf{E}}, \\tilde{\\mathbf{X}})$. The complete molecule is sampled by taking the product of the posterior distributions of atom features, coordinates, and edge features as\n$p\\left(\\tilde{\\mathbf{M}}_{t-1} \\mid \\tilde{\\mathbf{M}}_{t}\\right)=p\\left(\\tilde{\\mathbf{H}}_{t-1} \\mid \\tilde{\\mathbf{H}}_{t}\\right) p\\left(\\tilde{\\mathbf{E}}_{t-1} \\mid \\tilde{\\mathbf{E}}_{t}\\right) p\\left(\\tilde{\\mathbf{X}}_{t-1} \\mid \\tilde{\\mathbf{X}}_{t}\\right) \\mid 9$ : end for\nwith the posterior distributions of atom features and coordinates from Eq 1 and the posterior distribution of edges defined in the App G. The sampling process is described in Algorithm 2. Also, the zeroth likelihood estimation is explained in App H.\n\n## 4 MUformer: Molecule Unified Transformer\n\nTo learn the complete molecular representation, in this section, we propose a novel equivariant graph transformer MUformer, denoted by $\\psi_{\\theta}$ (visualized in Fig 1), which contains 6 encoding functions (Sec 4.1\\&App A.1), 4 attention biases (Sec 4.2\\&App A.3), and 2 attention channels (Sec 4.3\\&App A.3). It takes as input a complete molecule $\\mathbf{M}=(\\mathbf{H}, \\mathbf{E}, \\mathbf{X})$ with $\\mathbf{H} \\in \\mathbb{R}^{n \\times d}, \\mathbf{E} \\in$ $\\mathbb{R}^{n \\times n \\times b}, \\mathbf{X} \\in \\mathbb{R}^{n \\times 3}$, and outputs the predicted molecule $\\hat{\\mathbf{M}}=(\\tilde{\\mathbf{H}}, \\tilde{\\mathbf{E}}, \\tilde{\\mathbf{X}})$. For clarity, we refer to the 2 D molecular structure as $\\mathbf{M}^{2 \\mathrm{D}}=(\\mathbf{H}, \\mathbf{E})$, and the 3D geometric structure as $\\mathbf{M}^{3 \\mathrm{D}}=(\\mathbf{H}, \\mathbf{X})$. In the following subsections, we will introduce each component of our MUformer in details.\nOur MUformer architecture can be used under different input conditions. When only 2D molecular information is available, only the invariant channel is activated, and the model makes predictions for atom and edge features only. When only 3D molecular information is available, only the equivariant channel is activated, and the model makes predictions for atom features and coordinates only. When both 2D and 3D molecular data are provided, the invariant and equivariant channels are activated, and the model can make predictions for the complete molecule, including atom features, molecular structure, and geometric structure. A detailed introduction of MUformer is discussed in App A.\n\n### 4.1 Encodings\n\nThe MUformer consists of 6 encoding functions, with 3 being message-passing based, designed to incorporate atomic, positional, and structural information into a concise and expressive representation, particularly suited for handling graph-structured inputs. A more complete introduction of MUformer encoding functions are discussed in App A.1.\n\n1. Atom Encoding The authors in [19] propose a method of utilizing in-degree $\\operatorname{deg}^{-}$and outdegree $\\operatorname{deg}^{+}$obtained from 2D molecular graphs $\\mathbf{M}^{2 \\mathrm{D}}$ to incorporate centrality information into the atom-wise encoding process, $\\mathbf{z}_{\\mathbf{h}_{i}}^{\\mathrm{ID}}$ for node $i$ is,\n\n$$\n\\mathbf{z}_{\\mathbf{h}_{i}}^{\\mathrm{ID}}=W_{\\text {atom }_{i}} \\mathbf{h}_{i}+W_{\\text {in-deg }_{i}} \\operatorname{deg}_{i}^{-}+W_{\\text {out-deg }_{i}} \\operatorname{deg}_{i}^{+}\n$$\n\n2. Bond Encoding We incorporate pair-wise atom information into the edge encoding with message-passing mechanism. For every edge $\\mathbf{e}_{i j}$, we use a permutation-invariant function to generate the embedded edge representations, ensuring consistency in the learned representation regardless of the order of the atoms,\n\n$$\n\\mathbf{z}_{\\mathbf{e}_{i j}}=W_{\\text {comb }_{1}}\\left(\\left[W_{\\text {atom }_{2}} \\mathbf{h}_{i}+W_{\\text {edge }_{1}} \\mathbf{e}_{i j}+W_{\\text {atom }_{2}} \\mathbf{h}_{j}\\right]\\right)+b_{\\text {comb }_{1}}\n$$\n\nIn addition, to ensure the symmetry of edge encoding, we calculate it as $\\mathbf{z}_{\\mathbf{e}_{i j}}=\\left(\\mathbf{z}_{\\mathbf{e}_{i j}}+\\mathbf{z}_{\\mathbf{e}_{i j}}\\right) / 2$.\n3. Graph Encoding We encode graph-level structural $\\mathbf{h}_{\\text {struct }}$, spectral $\\mathbf{h}_{\\text {spect }}$ and molecular information $\\mathbf{h}_{\\text {mol }}$ to a molecule $\\mathbf{M}$. As suggested in [6, 20], we add cycle counts for $\\mathbf{h}_{\\text {struct }}$, the number of cycles of up to size 6 and the number of connected components; and we add eigenvalue features to $\\mathbf{h}_{\\text {spect }}$, including the multiplicity of eigenvalue 0 , as well as the first 5 nonzero eigenvalues. For $\\mathbf{h}_{\\text {mol }}$, we include the current valency of each atom and the current molecular weight of the entire molecule as features. For every molecule $\\mathbf{M}$, the graph-level representation is given by,\n\n$$\n\\mathbf{Z}_{\\mathbf{M}}=W_{\\text {graph }}\\left(\\left[\\mathbf{h}_{\\text {struct }}, \\mathbf{h}_{\\text {spect }}, \\mathbf{h}_{\\text {mol }}\\right]\\right)+b_{\\text {graph }}\n$$"
    },
    {
      "markdown": "![img-0.jpeg](img-0.jpeg)\n\nFigure 1: The figure showcases our MUformer for processing 2D and 3D molecular data. Within the Transformer backbone, two channels exist: purple for 2D data and brown for 3D data. The blue part encodes 2D molecular structures, while the green part handles atom-level information and the red part processes 3D geometric structures. With missing 2D or 3D structures, the model activates either the invariant (purple) or equivariant (brown) channel. The invariant channel predicts atom and edge features, while the equivariant channel offers geometric transformation robustness and predicts atom features and positions. When both channels are operational, the model maintains robustness to geometric transformations and predicts a complete molecule, and final atom features are derived by merging outputs from both channels and feeding the combined data through an output network.\n4. 2D Neighborhood Encoding To get local neighborhood information, we use message passing to aggregate information from the immediate neighbors of each atom in the 2D graph $\\mathbf{M}^{2 \\mathrm{D}}$. Specifically, for $\\mathbf{h}_{i} \\in \\mathbf{H}$ and $\\mathbf{e}_{i j} \\in E$, the aggregated representation of atom $i$ is calculated by\n\n$$\n\\mathbf{m}_{j \\rightarrow i}=\\left(W_{\\mathrm{atom}_{2}} \\mathbf{h}_{j}\\right) \\odot\\left(W_{\\mathrm{edge}_{2}} \\mathbf{e}_{i j}\\right), \\mathbf{z}_{\\mathbf{h}_{i}}^{2 \\mathrm{D}}=W_{\\mathrm{atom}_{2}} \\mathbf{h}_{i}+\\frac{1}{|N(i)|} \\sum_{j \\in N(i)} \\mathbf{m}_{j \\rightarrow i}\n$$\n\nwhere $N(i)$ denotes the neighbors of atom. To formulate the messages $\\mathbf{m}$, we use the Hadamard product, $\\odot$, between the atom embedding and edge embeddings.\n5. 3D Neighborhood Encoding We use message passing to collect the atom information in the vicinity of the given atom to get the 3D neighborhood encoding $\\mathbf{M}^{3 \\mathrm{D}}$. For atom $i$, it follows\n\n$$\n\\begin{aligned}\n& d_{i j}=\\left\\|x_{i}-x_{j}\\right\\|_{2}, \\mathbf{e}_{i j}=\\operatorname{SiLU}\\left(W_{\\text {edge }_{3}}\\left(f_{\\mathrm{RBF}_{1}}\\left(d_{i j}\\right)\\right)\\right) \\odot f_{\\mathrm{cos}}\\left(d_{i j}\\right) \\\\\n& \\mathbf{m}_{j \\rightarrow i}=\\left(W_{\\text {atom }_{2}} \\mathbf{h}_{j}\\right) \\odot \\mathbf{e}_{i j}, \\mathbf{z}_{\\mathbf{h}_{i}}^{3 \\mathrm{D}}=W_{\\text {atom }_{2}} \\mathbf{h}_{i}+\\frac{1}{|N(i)|} \\sum_{j \\in N(i)} \\mathbf{m}_{j \\rightarrow i}\n\\end{aligned}\n$$\n\nwhere $d_{i j}$ is the Euclidean distance between atoms $i, j$ and $f_{\\mathrm{RBF}_{1}}(\\cdot)$ is the exp radial basis function. To calculate messages $\\mathbf{m}$, we use the Hadamard product, $\\odot$, between the atom and edge embeddings. We use the cosine cutoff $f_{\\text {cos }}\\left(d_{i j}\\right)$ to determine which atoms in the Euclidean space given by $\\mathbf{M}^{3 \\mathrm{D}}$ should be considered as part of the neighborhood of atom $i$. This provides a smooth way to incorporate spatial locality in the message-passing process. Only atoms $j$ for which $f_{\\text {cos }}\\left(d_{i j}\\right)>0$ are included in the message-passing process, resulting in a new node representation $\\mathbf{z}_{\\mathbf{h}_{i}}^{3 \\mathrm{D}} \\in \\mathbb{R}^{f h_{3}}$ for atom $i$.\nRemark We can integrate 2D graph information by assigning $f_{\\text {cos }}\\left(d_{i j}\\right)=1$ when an edge is present between atoms $i$ and $j$ in the 2D molecular structure $\\mathbf{M}^{3 \\mathrm{D}}$. By doing so, we effectively incorporate locality information from both the 2D molecular structure and the 3D geometric structure, providing a more comprehensive representation of the molecule.\n6. Combine Encoding In the final step of encoding, we compute the atomic embedding $\\mathbf{Z}_{\\mathbf{H}}$ by concatenating the atom encoding, 2D neighborhood encoding, and 3D neighborhood encoding,\n\n$$\n\\mathbf{Z}_{\\mathbf{H}}=W_{\\text {comb }_{2}}\\left(\\left[\\mathbf{Z}_{\\mathbf{H}}^{\\mathrm{1D}}, \\mathbf{Z}_{\\mathbf{H}}^{\\mathrm{2D}}, \\mathbf{Z}_{\\mathbf{H}}^{\\mathrm{3D}}\\right]\\right)+b_{\\text {comb }_{2}}\n$$\n\nAdditionally, the bond encoding $\\mathbf{Z}_{\\mathbf{E}}$ and graph encoding $\\mathbf{Z}_{\\mathbf{M}}$ are utilized to calculate attentions (visualized in Fig 1), with details discussed in Sec 4.3 and App A.3."
    },
    {
      "markdown": "# 4.2 Attention Biases \n\nThe MUformer incorporates 4 attention biases, which serve to encode spatial relationships in both 2D molecular structure and 3D geometric arrangement. These biases are integrated into the attention mechanism, enhancing the model's ability to process and understand molecular representations. A more complete introduction of MUformer attention biases is discussed in App A.2. And a detailed discussion of the importance and advantages of employing these attention biases for computing attentions in the MUformer can be found in App B.\n\n1. 2D Spatial Attention Bias To capture the structural relationships between atoms in the 2D molecular graph, we use the shortest path distance (SPD) encoding [19]. The SPD encoding, denoted as $\\Phi_{\\mathrm{SPD}}^{2 \\mathrm{D}}(i, j): V \\times V \\rightarrow \\mathbb{R}$, calculates the distance between atoms $i, j$ in $\\mathbf{M}^{2 \\mathrm{D}}$. Moreover, we incorporate edge information along the shortest path between atoms $i, j$ to reflect edge characteristics,\n\n$$\n\\Phi_{\\mathrm{LNC}_{i j}}^{2 \\mathrm{D}}=\\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{e}_{n}\\left(w_{n}\\right)^{T} \\in \\mathbb{R}\n$$\n\nThe combined bias, $\\Phi_{\\mathbf{E}}^{2 \\mathrm{D}}$, is calculated as the sum of $\\Phi_{\\mathrm{SPD}}^{2 \\mathrm{D}}$ and $\\Phi_{\\mathrm{LNC}}^{2 \\mathrm{D}}$, both in $\\mathbb{R}^{n \\times n \\times 1}$. The 2 D spatial attention bias enables the model to capture the intricate relationships between atoms and their surroundings, ultimately improving its performance.\n2. 3D Spatial Attention Bias To encode 3D spatial relationships between atom pairs in $\\mathbf{M}^{3 \\mathrm{D}}$, we use Euclidean distance and an exponential radial basis function, $f_{\\mathrm{RBF} 2}(\\cdot)$ [9]. This 3D spatial attention bias, $\\Phi_{\\mathbf{E}}^{3 \\mathrm{D}}$, enables the model to account for the geometric arrangement of atoms in the molecule, which is crucial for understanding 3D structure and molecular properties.\n\n$$\nd_{i j}=\\left\\|x_{i}-x_{j}\\right\\|_{2}, \\Phi_{\\mathbf{e}_{i j}}^{3 \\mathrm{D}}=W_{3 \\mathrm{D}_{2}}\\left(\\operatorname{SiLU}\\left(W_{3 \\mathrm{D}_{1}}\\left(f_{\\mathrm{RBF}_{2}}\\left(d_{i j}\\right)\\right)\\right)\\right)\n$$\n\nBy incorporating this 3D spatial attention bias, the MUformer is able to better capture complex 3D spatial relationships between atoms, leading to improved performance in tasks involving 3D molecular structures.\nEdge Feature \\& Graph Feature The embeddings obtained from the 2D structure, $\\mathbf{Z}_{\\mathbf{E}}$, and the molecular graph information, $\\mathbf{Z}_{\\mathbf{M}}$, can be further projected and employed as additional attention biases, enhancing the model's understanding of the molecular structure and relationships.\n\n### 4.3 Transformer Channels\n\nThe MUformer employs two channels, the invariant and the equivariant channel, to process molecular data, and an output block to combine the processed information from the two channels (see Fig 1). A more complete introduction of MUformer transformer channels is discussed in App A.3.\nInvariant Channel The invariant channel in MUformer captures intrinsic properties of the input 2D molecule graph, $\\mathbf{M}^{2 \\mathrm{D}}$, but also utilizes 2D and 3D spatial biases as attention biases when 3D geometric structure is provided. Its main goal is to predict invariant features, including atom and edge-level features, by leveraging the underlying graph structure. Unlike in [19], the invariant channel in MUformer is used to predict atom and edge features, generating embeddings for invariant features $\\hat{\\mathbf{Z}}_{\\mathbf{H}}$ and $\\hat{\\mathbf{Z}}_{\\mathbf{E}}$, respectively (see purple part in Fig 1).\nEquivariant Channel The equivariant channel in MUformer extracts features from the input 3D molecule graph $\\mathbf{M}^{3 \\mathrm{D}}$ that can vary under geometric transformations. Unlike [21], which only focuses on the 3D molecular structure, our equivariant channel can utilize both 2D molecular structure and 3D geometric structure in Euclidean space (if the 2D molecular structure is provided). This enables the channel to predict atom features $\\hat{\\mathbf{Z}}_{\\mathbf{H}}$ and their coordinates $\\hat{\\mathbf{Z}}_{\\mathbf{X}}$ that are insensitive to geometric transformations (see the brown part in Fig 1). The unique capability of our equivariant channel enables it to capture richer structural information from both 2D and 3D molecular representations.\nInteraction Embedding The atom representations $\\hat{\\mathbf{Z}}_{\\mathbf{H}}$ from two transformer channels are combined, and fed in to the next layer of the transformer channels or used as input for the final predictions,\n\n$$\n\\hat{\\mathbf{Z}}_{\\mathbf{H}}=W_{\\text {comb }_{2}}\\left[\\mathbf{Z}_{\\mathbf{H}}^{\\mathrm{inv}}, \\mathbf{Z}_{\\mathbf{H}}^{\\mathrm{eqv}}\\right]+b_{\\text {comb }_{2}}\n$$\n\nOutput Block The output block generates the final output utilizing the embeddings from invariant and equivariant channels. Specifically, it takes in the atom $\\hat{\\mathbf{Z}}_{\\mathbf{H}}$ and edge embeddings $\\hat{\\mathbf{Z}}_{\\mathbf{E}}$, along with the velocity embedding $\\hat{\\boldsymbol{v}}$. Through feature extractions, the output block makes predictions,\n\n$$\n\\begin{aligned}\n& \\mathbf{H}_{\\text {out }}=W_{\\mathbf{X}_{\\text {out }_{2}}}\\left(\\operatorname{SiLU}\\left(W_{\\mathbf{X}_{\\text {out }_{1}}} \\hat{\\mathbf{Z}}_{\\mathbf{H}}\\right)\\right) \\in \\mathbb{R}^{n \\times d_{\\text {out }}}, \\mathbf{X}_{\\text {out }}=\\mathbf{X}+W_{\\mathbf{v}_{\\text {out }_{2}}}\\left(\\operatorname{SiLU}\\left(W_{\\mathbf{v}_{\\text {out }_{1}}} \\hat{\\boldsymbol{v}}\\right)\\right) \\in \\mathbb{R}^{n \\times 3} \\\\\n& \\mathbf{E}_{\\text {out }}=W_{\\mathbf{E}_{\\text {out }_{2}}}\\left(\\operatorname{SiLU}\\left(W_{\\mathbf{E}_{\\text {out }_{1}}} \\hat{\\mathbf{Z}}_{\\mathbf{E}}\\right)\\right) \\in \\mathbb{R}^{n \\times n \\times b_{\\text {out }}}\n\\end{aligned}\n$$"
    },
    {
      "markdown": "## 5 Related Work\n\n### 5.1 Graph Models and Equivariant Models\n\nGraph models, i.e., graph neural networks and graph transformers, and equivariant models have emerged as crucial tools to perform molecule-relevant tasks. Graph models are a class of neural networks specifically designed for graph-structured data [22-28], such as molecular structures, and have demonstrated effectiveness in capturing the complex relationships between atoms and bonds within a molecule [19, 21, 29, 30]. Equivariance is a property of a function $f$ w.r.t. a group, such that the function preserves its structure under group transformations, mathematically expressed as $f(g x)=g f(x)$ for any $g \\in G$ and input $x$ [2]. Equivariant graph models constitute a subcategory of GNNs that exhibit equivariance with respect to a group of symmetries, enabling them to learn representations invariant to specific transformations such as translation, rotation, and reflection. This makes them well-suited for tasks involving geometric structure [2, 21, 31]. The integration of graph models and equivariance in graph-structured data has led to significant advancements in the design and discovery of molecules.\n\n### 5.2 Diffusion Models\n\nDiffusion models have gained significant traction as powerful generative models for drug discovery applications [14-16]. For instance, [3] employs diffusion models to generate molecules with the lowest conformation energy. In another work, [6] presents a diffusion model that utilizes a graph transformer to denoise the diffusion process, operating jointly on atom features and molecular structures. Moreover, recent studies have explored the integration of equivariant graph models within diffusion models for molecule generation. For example, [4] introduces a diffusion model with an equivariant GNN, enabling the model to work jointly on atom features and coordinates. Overall, incorporating equivariant graph models into diffusion models for molecule generation has demonstrated promising results in recent research.\n\n### 5.3 Joint Generative Models\n\n[32] employs an autoregressive flow as the backbone model to generate atom types, bond types, and 3D coordinates sequentially. For the atomic coordinates, [32] constructs a local spherical coordinate system based on local reference atoms and predicts the relative coordinates. [33] tackles the atom-bond inconsistency problem in 3D molecule generation by employing a diffusion model that generates atoms and bonds simultaneously while maintaining their consistency. [33] incorporates a noise schedule to gradually add noise to the atom positions and types, as well as bond types with a guidance, to perturb them towards the correct values. Moreover, [34] works on the structure-based drug design that generate both 2D and 3D molecular graphs to enhance the overall representation.\n\n## 6 Experiments\n\nTo evaluate our MUDiff framework, we conduct experiments on the QM9 dataset [35], which contains 130 k small molecules with up to 9 heavy atoms ( 29 atoms including hydrogens) and their associated molecular properties and structures. We use the train/val/test splits from [36], consisting of $100 \\mathrm{~K} / 18 \\mathrm{~K} / 13 \\mathrm{~K}$ samples respectively, for evaluation. This protocol follows the method used in previous works such as $[2,4]$.\n\n### 6.1 Molecule Generation with Limited 3D Data\n\nIn this section, we introduce a new molecule generation task that incorporates limited 3D data, as many real-world datasets lack complete 3D structures. To accomplish this, we randomly split the 100 K training molecules into two sets: 30 K with both 2 D and 3D structures and 70 K with only 2 D structures. We train the model on the 30 K samples using both the invariant and equivariant channels and validate on 18 K samples until NLL converges. We then fine-tune the trained model on the remaining 70 K molecules with only 2D structures and validate/test on $18 \\mathrm{~K} / 13 \\mathrm{~K}$ samples.\nRemark Notably, this training framework with limited 3D data is only possible with MUDiff for now, because of the flexible two-channel design.\nResults The results of the molecule generation task with limited 3D data are summarized in Table 1. MUDiff achieved competitive results in generating stable molecules, even with limited 3D information in the training set, compared to the baselines. These results suggest that MUDiff has the ability to leverage sufficient 2D structures to infer 3D geometry. This finding may motivate further research on the co-generation of 2D and 3D structures for molecules.\n\n### 6.2 Molecule Generation"
    },
    {
      "markdown": "We compare the performance of our MUDiff model with popular generative models, including GraphVAE [1], GSchenet [37], Set2GraphVAE [38], ENF [2], GDM [4], EDM [4], DiGress [6], MDM [39], and GeoLDM [40]. The results of the baseline models can be found in the studies by [4] and [6].\nAs outlined in [2], we evaluate the atom and molecule stability of the generated compounds by measuring the proportion of atoms that have the correct valency for atom stability, and the proportion of generated molecules in which all atoms are stable for molecule stability. Additionally, we also measure the validity and uniqueness using the RDKit tool, as used in [4].\nRemark We would like to emphasize that the dataset statistics are not ideal, with atom stability at $99 \\%$, molecule stability at $95.2 \\%$, and molecule validity at $99.3 \\%$ in the original data. These statistics are not perfect, pointing to potential imperfections in the dataset. The imperfections of the dataset have also been acknowledged in $[2,4,6]$. Additionally, the metrics used in this study have their own limitations, which are discussed in App J.\nResults Table 2 presents the evaluated results of atom and molecule stability for molecules generated by MUDiff and the baseline models. The reported average results and standard deviations are over 3 runs, using 10,000 samples from each model. The table shows that MUDiff can generate molecules that are significantly more stable than the baseline models in terms of negative log-likelihood and molecule stability and matches the performance of SOTA model w.r.t. atom stability.\nTable 3 presents the results of the validity and uniqueness of the generated samples. It should be noted that, following the guidelines outlined in [38], novelty is not reported in this table. The table shows that MUDiff generates a significantly higher rate of unique molecules than the baselines and matches the rate of valid molecules of SOTA models.\n\n### 6.3 Conditional Generation\n\nWe follow the experimental setting in [4] to train the conditional MUDiff on the QM9 dataset, conditioning the generation on properties $\\alpha, \\epsilon_{\\text {homo }}, \\epsilon_{\\text {lomo }}, \\Delta \\epsilon, \\mu$, and $C_{v}$, respectively.\n\n### 6.4 Ablation Study\n\nTo investigate how different components affect the performance of MUDiff, we conduct an ablation study in App D.4. Further details about the experimental settings can be found in App D.4.1.\n\n### 6.5 Property Prediction\n\nAdditionally, we conduct a comprehensive comparison of our MUformer with several baselines on the QM9 dataset for property prediction, including SchNet [9], EGNN [2], PhysNet [17], DimeNet [41], Cormorant [36], PaiNN [42], and ET [21]. The dataset consists of molecules with various properties, and we estimate 12 chemical properties per molecule following [2]. The comparison results in terms of mean absolute error are presented in App D.3.\n\n## 7 Conclusion\n\nIn this work, we introduced MUDiff, a transformer-based framework for learning and generating a complete molecule representation using a novel architecture, MUformer. Our contributions include proposing a new molecule generation method, named MUDiff, which successfully generates more stable and valid molecules, demonstrating the potential for further research and applications. We also explored the interplay between 2D and 3D structure generation in App C, which reveals the benefits of jointly generating both structures to enhance the overall performance. Additionally, we discussed the scalability issues in App K and provided insights for future work to improve the efficiency and accuracy of MUDiff. By addressing these challenges, we aim to support progress in machine learning for molecules and facilitate advancements in areas such as drug discovery and material design."
    },
    {
      "markdown": "# 8 Acknowledgements \n\nThis work is supported by the Natural Sciences and Engineering Research Council of Canada (NSERC) Grant, Canadian Institute for Advanced Research (CIFAR) Grant, and Fonds d'accélération des collaborations en santé (FACS-Acuity) supported by Ministre de lconomie et de lInnovation Canada. Minkai Xu thanks the generous support of Sequoia Capital Stanford Graduate Fellowship.\n\n## References\n\n[1] Thomas N Kipf and Max Welling. Variational graph auto-encoders. arXiv preprint arXiv:1611.07308, 2016. 1, 9\n[2] Victor Garcia Satorras, Emiel Hoogeboom, Fabian B Fuchs, Ingmar Posner, and Max Welling. E (n) equivariant normalizing flows. arXiv preprint arXiv:2105.09016, 2021. 1, 3, 8, 9, 13, 20, 25\n[3] Minkai Xu, Lantao Yu, Yang Song, Chence Shi, Stefano Ermon, and Jian Tang. Geodiff: A geometric diffusion model for molecular conformation generation. arXiv preprint arXiv:2203.02923, 2022. 1, 4, 8\n[4] Emiel Hoogeboom, Victor Garcia Satorras, Clément Vignac, and Max Welling. Equivariant diffusion for molecule generation in 3d. In International Conference on Machine Learning, pages 8867-8887. PMLR, 2022. 1, 3, 4, 8, 9, 17, 19, 20, 23, 24, 25\n[5] Jaehyeong Jo, Seul Lee, and Sung Ju Hwang. Score-based generative modeling of graphs via the system of stochastic differential equations. arXiv preprint arXiv:2202.02514, 2022. 25\n[6] Clement Vignac, Igor Krawczuk, Antoine Siraudin, Bohan Wang, Volkan Cevher, and Pascal Frossard. Digress: Discrete denoising diffusion for graph generation. arXiv preprint arXiv:2209.14734, 2022. 1, 3, 4, 5, 8, 9, 13, 17, 21, 22\n[7] David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alán Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs for learning molecular fingerprints. In Advances in neural information processing systems, pages 22242232, 2015. 1\n[8] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1263-1272. JMLR. org, 2017. 1\n[9] Kristof Schütt, Pieter-Jan Kindermans, Huziel Enoc Sauceda Felix, Stefan Chmiela, Alexandre Tkatchenko, and Klaus-Robert Müller. Schnet: A continuous-filter convolutional neural network for modeling quantum interactions. Advances in neural information processing systems, 30, 2017. 1, 3, 7, 9, 15, 16, 20\n[10] David L Mobley and Michael K Gilson. Predicting binding free energies: frontiers and benchmarks. Annual review of biophysics, 46:531-558, 2017. 2\n[11] Andrew R Leach and Michael M Hann. Molecular complexity and fragment-based drug discovery: ten years on. Current opinion in chemical biology, 15(4):489-496, 2011. 2\n[12] Robert A Copeland. Evaluation of enzyme inhibitors in drug discovery: a guide for medicinal chemists and pharmacologists. John Wiley \\& Sons, 2013. 2\n[13] Anna Gaulton, Louisa J Bellis, A Patricia Bento, Jon Chambers, Mark Davies, Anne Hersey, Yvonne Light, Shaun McGlinchey, David Michalovich, Bissan Al-Lazikani, et al. Chembl: a large-scale bioactivity database for drug discovery. Nucleic acids research, 40(D1):D1100D1107, 2012. 2\n[14] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems, 33:6840-6851, 2020. 2, 4, 8\n[15] Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational diffusion models. Advances in neural information processing systems, 34:21696-21707, 2021. 2, 22, 23\n[16] Jacob Austin, Daniel D Johnson, Jonathan Ho, Daniel Tarlow, and Rianne van den Berg. Structured denoising diffusion models in discrete state-spaces. Advances in Neural Information Processing Systems, 34:17981-17993, 2021. 3, 4, 8, 22"
    },
    {
      "markdown": "[17] Oliver T Unke and Markus Meuwly. Physnet: A neural network for predicting energies, forces, dipole moments, and partial charges. Journal of chemical theory and computation, 15(6): 3678-3693, 2019. 3, 9, 20\n[18] Jonas Köhler, Leon Klein, and Frank Noé. Equivariant flows: exact likelihood generative learning for symmetric densities. In International conference on machine learning, pages 5361-5370. PMLR, 2020. 3\n[19] Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, and Tie-Yan Liu. Do transformers really perform badly for graph representation? Advances in Neural Information Processing Systems, 34:28877-28888, 2021. 5, 7, 8, 13, 14, 15\n[20] Dominique Beaini, Saro Passaro, Vincent Létourneau, Will Hamilton, Gabriele Corso, and Pietro Liò. Directional graph networks. In International Conference on Machine Learning, pages 748-758. PMLR, 2021. 5, 13\n[21] Philipp Thölke and Gianni De Fabritiis. Torchmd-net: Equivariant transformers for neural network based molecular potentials. arXiv preprint arXiv:2202.02541, 2022. 7, 8, 9, 16, 20\n[22] Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. arXiv, abs/1609.02907, 2016. URL http://arxiv.org/abs/1609.02907. 8\n[23] William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. arXiv, abs/1706.02216, 2017. URL http://arxiv.org/abs/1706.02216.\n[24] Sitao Luan, Mingde Zhao, Xiao-Wen Chang, and Doina Precup. Break the ceiling: Stronger multi-scale deep graph convolutional networks. Advances in neural information processing systems, 32, 2019.\n[25] Sitao Luan, Chenqing Hua, Qincheng Lu, Jiaqi Zhu, Mingde Zhao, Shuyuan Zhang, Xiao-Wen Chang, and Doina Precup. Is heterophily a real nightmare for graph neural networks to do node classification? arXiv preprint arXiv:2109.05641, 2021.\n[26] Sitao Luan, Chenqing Hua, Qincheng Lu, Jiaqi Zhu, Mingde Zhao, Shuyuan Zhang, Xiao-Wen Chang, and Doina Precup. Revisiting heterophily for graph neural networks. Advances in neural information processing systems, 35:1362-1375, 2022.\n[27] Chenqing Hua, Guillaume Rabusseau, and Jian Tang. High-order pooling for graph neural networks with tensor decomposition. arXiv preprint arXiv:2205.11691, 2022.\n[28] Sitao Luan, Chenqing Hua, Minkai Xu, Qincheng Lu, Jiaqi Zhu, Xiao-Wen Chang, Jie Fu, Jure Leskovec, and Doina Precup. When do graph neural networks help with node classification: Investigating the homophily principle on node distinguishability. Advances in Neural Information Processing Systems, 36, 2023. 8\n[29] Zhengdao Chen, Lei Chen, Soledad Villar, and Joan Bruna. Can graph neural networks count substructures? Advances in neural information processing systems, 33:10383-10395, 2020. 8, 13\n[30] Vijay Prakash Dwivedi and Xavier Bresson. A generalization of transformer networks to graphs. arXiv preprint arXiv:2012.09699, 2020. 8\n[31] Victor Garcia Satorras, Emiel Hoogeboom, and Max Welling. E (n) equivariant graph neural networks. In International conference on machine learning, pages 9323-9332. PMLR, 2021. 8, 19\n[32] Zaixi Zhang, Qi Liu, Chee-Kong Lee, Chang-Yu Hsieh, and Enhong Chen. An equivariant generative framework for molecular graph-structure co-design. Chemical Science, 14(31): 8380-8392, 2023. 8\n[33] Xingang Peng, Jiaqi Guan, Qiang Liu, and Jianzhu Ma. Moldiff: Addressing the atom-bond inconsistency problem in 3d molecule diffusion generation. arXiv preprint arXiv:2305.07508, 2023. 8\n[34] Zaixi Zhang, Yaosen Min, Shuxin Zheng, and Qi Liu. Molecule generation for target protein binding with structural motifs. In The Eleventh International Conference on Learning Representations, 2022. 8\n[35] Raghunathan Ramakrishnan, Pavlo O Dral, Matthias Rupp, and O Anatole Von Lilienfeld. Quantum chemistry structures and properties of 134 kilo molecules. Scientific data, 1(1):1-7, 2014. 8"
    },
    {
      "markdown": "[36] Brandon Anderson, Truong Son Hy, and Risi Kondor. Cormorant: Covariant molecular neural networks. Advances in neural information processing systems, 32, 2019. 8, 9, 20\n[37] Niklas Gebauer, Michael Gastegger, and Kristof Schütt. Symmetry-adapted generation of 3d point sets for the targeted discovery of molecules. Advances in neural information processing systems, 32, 2019.9\n[38] Clement Vignac and Pascal Frossard. Top-n: Equivariant set and graph generation without exchangeability. arXiv preprint arXiv:2110.02096, 2021. 9, 25\n[39] Lei Huang, Hengtong Zhang, Tingyang Xu, and Ka-Chun Wong. Mdm: Molecular diffusion model for 3d molecule generation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 5105-5112, 2023. 9, 19\n[40] Minkai Xu, Alexander S Powers, Ron O Dror, Stefano Ermon, and Jure Leskovec. Geometric latent diffusion models for 3d molecule generation. In International Conference on Machine Learning, pages 38592-38610. PMLR, 2023. 9, 19\n[41] Dominique Beani, Saro Passaro, Vincent Létourneau, Will Hamilton, Gabriele Corso, and Pietro Liò. Directional graph networks. In International Conference on Machine Learning, pages 748-758. PMLR, 2021. 9, 20\n[42] Kristof Schütt, Oliver Unke, and Michael Gastegger. Equivariant message passing for the prediction of tensorial properties and molecular spectra. In International Conference on Machine Learning, pages 9377-9388. PMLR, 2021. 9, 20\n[43] Shengjie Luo, Tianlang Chen, Yixian Xu, Shuxin Zheng, Tie-Yan Liu, Liwei Wang, and Di He. One transformer can understand both 2d \\& 3d molecular data. arXiv preprint arXiv:2210.01765, 2022. 15,17\n[44] Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In International Conference on Machine Learning, pages 8162-8171. PMLR, 2021. 25"
    },
    {
      "markdown": "# A MUformer \n\n## A. 1 MUformer Encodings\n\nThe MUformer consists of 6 encoding functions, with 3 being message-passing based, designed to incorporate atomic, positional, and structural information into a concise and expressive representation, particularly suited for handling graph-structured inputs.\n\n1. Atom Encoding Incorporating centrality information into the atom representations is crucial as it helps to highlight the importance of individual atoms in the molecular structure. The authors in [19] propose a method of utilizing in-degree deg ${ }^{-}$and out-degree deg ${ }^{+}$obtained from 2D molecular graphs $\\mathbf{M}^{2 \\mathrm{D}}$ to incorporate centrality information into the atom-wise encoding process. This allows for a detailed and accurate representation of the molecular structure, taking into account the relative importance of each atom. After the centrality encoding, the new representation $\\mathbf{z}_{\\mathbf{h}_{i}}^{\\mathrm{ID}}$ for node $i$ is,\n\n$$\n\\mathbf{z}_{\\mathbf{h}_{i}}^{\\mathrm{ID}}=W_{\\text {atom }_{i}} \\mathbf{h}_{i}+W_{\\text {in-deg }_{i}} \\operatorname{deg}_{i}^{-}+W_{\\text {out-deg }_{i}} \\operatorname{deg}_{i}^{+}\n$$\n\nwhere $W_{\\text {atom }_{i}} \\in \\mathbb{R}^{d \\times f h_{1}}, W_{\\text {in-deg }_{i}} \\in \\mathbb{R}^{1 \\times f h_{1}}, W_{\\text {out-deg }_{i}} \\in \\mathbb{R}^{1 \\times f h_{1}}$ are designated learnable parameters for the atom features, in-degree deg ${ }^{-}$, and out-degree deg ${ }^{+}$. The resulting atom embedding for atom $i, \\mathbf{z}_{\\mathbf{h}_{i}}^{\\mathrm{ID}} \\in \\mathbb{R}^{f h_{1}}$, includes the degree centrality information.\n2. Bond Encoding To obtain a richer edge representation, we incorporate the pair-wise atom information into the edge encoding with message-passing information. For each edge $\\mathbf{e}_{i j} \\in \\mathbf{E}$, we use a permutation-invariant function to generate the embedded edge representations, ensuring consistency in the learned representation regardless of the order of the atoms,\n\n$$\n\\mathbf{z}_{\\mathbf{e}_{i j}}=W_{\\text {comb }_{1}}\\left(\\left[W_{\\text {atom }_{2}} \\mathbf{h}_{i}+W_{\\text {edge }_{1}} \\mathbf{e}_{i j}+W_{\\text {atom }_{2}} \\mathbf{h}_{j}\\right]\\right)+b_{\\text {comb }_{1}}\n$$\n\nwhere $W_{\\text {atom }_{2}} \\in \\mathbb{R}^{d \\times f e_{\\text {in }}}$ and $W_{\\text {edge }_{1}} \\in \\mathbb{R}^{b \\times f e_{\\text {in }}}$ are learnable parameters that handle the atom features and edge types respectively, $W_{\\text {comb }_{1}} \\in \\mathbb{R}^{f e_{\\text {in }} \\times f e_{\\text {in }}}$ combines the representations with bias $b_{\\text {comb }_{1}}$. In addition, in order to make the edge representation symmetric, we calculate the edge representation as $\\mathbf{z}_{\\mathbf{e}_{i j}}=\\left(\\mathbf{z}_{\\mathbf{e}_{i j}}+\\mathbf{z}_{\\mathbf{e}_{j i}}\\right) / 2$. The resulting edge embedding is $\\mathbf{Z}_{\\mathbf{E}} \\in \\mathbb{R}^{n \\times n \\times f e_{\\text {in }}}$.\n3. Graph Encoding Standard GNNs have limitations in detecting simple substructures such as cycles [29], which can hinder their ability to accurately capture the properties of the data distribution. To overcome this limitation, we enhance our model by extra features as follows.\nIn the graph encoding process, we encode graph-level structural $\\mathbf{h}_{\\text {struct }}$, spectral $\\mathbf{h}_{\\text {spect }}$ and molecular information $\\mathbf{h}_{\\text {mol }}$ to a molecule $\\mathbf{M}$. As suggested in [6, 20], we add cycle counts for $\\mathbf{h}_{\\text {struct }}$, the number of cycles of up to size 6 and the number of connected components; and we add eigenvalue features to $\\mathbf{h}_{\\text {spect }}$, including the multiplicity of eigenvalue 0 , as well as the first 5 nonzero eigenvalues. For $\\mathbf{h}_{\\text {mol }}$, we include the current valency of each atom and the current molecular weight of the entire molecule as features. For every molecule $\\mathbf{M}$, the graph-level representation is given by,\n\n$$\n\\mathbf{Z}_{\\mathbf{M}}=W_{\\text {graph }}\\left(\\left[\\mathbf{h}_{\\text {struct }}, \\mathbf{h}_{\\text {spect }}, \\mathbf{h}_{\\text {mol }}\\right]\\right)+b_{\\text {graph }}\n$$\n\nwhere $W_{\\text {graph }} \\in \\mathbb{R}^{13 \\times f_{\\text {in }}}$ combines the encoded information with bias $b_{\\text {graph. }}$. The resulting graph representation, $\\mathbf{Z}_{\\mathbf{M}} \\in \\mathbb{R}^{1 \\times f_{\\text {in }}}$, encapsulates all the information from the structural, spectral and molecular features.\n4. 2D Neighborhood Encoding To get local neighborhood information, we use message passing to aggregate information from the immediate neighbors of each atom in the 2D graph $\\mathbf{M}^{2 \\mathrm{D}}$. Specifically, for $\\mathbf{h}_{i} \\in \\mathbf{H}$ and $\\mathbf{e}_{i j} \\in E$, the aggregated representation of atom $i$ is calculated by\n\n$$\n\\mathbf{m}_{j \\rightarrow i}=\\left(W_{\\text {atom }_{2}} \\mathbf{h}_{j}\\right) \\odot\\left(W_{\\text {edge }_{2}} \\mathbf{e}_{i j}\\right), \\mathbf{z}_{\\mathbf{h}_{i}}^{\\mathrm{ID}}=W_{\\text {atom }_{2}} \\mathbf{h}_{i}+\\frac{1}{|N(i)|} \\sum_{j \\in N(i)} \\mathbf{m}_{j \\rightarrow i}\n$$\n\nwhere $N(i)$ denotes the neighbors of atom $i, W_{\\text {atom }_{2}} \\in \\mathbb{R}^{d \\times f h_{2}}$ and $W_{\\text {edge }_{2}} \\in \\mathbb{R}^{b \\times f h_{2}}$ are learnable parameters for atom features and edge types, respectively. To formulate the messages $\\mathbf{m}$, we use the Hadamard product, $\\odot$, between the atom embedding and edge embedding. This new representation $\\mathbf{z}_{\\mathbf{h}_{i}}^{\\mathrm{2D}} \\in \\mathbb{R}^{f h_{2}}$ takes into account not only the atom features, but also the features of its neighboring atoms and the edges connecting them.\n5. 3D Neighborhood Encoding We use message passing to collect the atom information in the vicinity of the given atom to get the 3D neighborhood encoding $\\mathbf{M}^{3 \\mathrm{D}}$ as suggested by [2]. For atom $i$,"
    },
    {
      "markdown": "its representation $\\mathbf{z}_{\\mathbf{h}_{i}}^{3 \\mathrm{D}}$ is computed by following steps,\n\n$$\n\\begin{aligned}\n& d_{i j}=\\left\\|x_{i}-x_{j}\\right\\|_{2}, \\mathbf{e}_{i j}=\\operatorname{SiLU}\\left(W_{\\text {edge }_{3}}\\left(f_{\\mathrm{RBF}_{1}}\\left(d_{i j}\\right)\\right)\\right) \\odot f_{\\mathrm{con}}\\left(d_{i j}\\right) \\\\\n& \\mathbf{m}_{j \\rightarrow i}=\\left(W_{\\text {atom }_{4}} \\mathbf{h}_{j}\\right) \\odot \\mathbf{e}_{i j}, \\mathbf{z}_{\\mathbf{h}_{i}}^{3 \\mathrm{D}}=W_{\\text {atom }_{4}} \\mathbf{h}_{i}+\\frac{1}{|N(i)|} \\sum_{j \\in N(i)} \\mathbf{m}_{j \\rightarrow i}\n\\end{aligned}\n$$\n\nwhere $d_{i j}$ is the distance from atom $i$ to $j$ in the Euclidean space, $f_{\\mathrm{RBF}_{1}}(\\cdot)$ is the exponential radial basis function, $f_{\\text {con }}(\\cdot)$ is the cosine cutoff, SiLU( $\\cdot$ ) is the activation function, $\\odot$ denotes the Hadamard product, $W_{\\text {atom }_{4}} \\in \\mathbb{R}^{d \\times f h_{3}}$ and $W_{\\text {edge }_{3}} \\in \\mathbb{R}^{k \\times f h_{3}}$ are designated learnable parameters for atom features and edge features, $k$ is the number of basis kernels as mentioned in Sec 2.2. To calculate messages $\\mathbf{m}$, we use the Hadamard product, $\\odot$, between the atom and edge embeddings.\nWe use the cosine cutoff $f_{\\text {con }}\\left(d_{i j}\\right)$ to determine which atoms in the Euclidean space given by $\\mathbf{M}^{3 \\mathrm{D}}$ should be considered as part of the neighborhood of atom $i$. This provides a smooth and differentiable way to incorporate spatial locality in the message-passing process, focusing on atoms that are closer in the 3D space while ignoring distant ones. This allows the model to better capture local geometric information and reduce computational complexity by not considering interactions between atoms that are too far apart, which would be less relevant for the molecular properties under investigation. Only atoms $j$ for which $f_{\\text {con }}\\left(d_{i j}\\right)>0$ are included in the message passing aggregation process, resulting in a new node representation $\\mathbf{z}_{\\mathbf{h}_{i}}^{3 \\mathrm{D}} \\in \\mathbb{R}^{f h_{3}}$ for atom $i$.\nRemark We can integrate 2D graph information by assigning $f_{\\text {con }}\\left(d_{i j}\\right)=1$ when an edge is present between atoms $i$ and $j$ in the 2D molecular structure $\\mathbf{M}^{2 \\mathrm{D}}$. This ensures that messages between these atoms are not influenced by the smooth transition. By doing so, we effectively incorporate locality information from both the 2D molecular structure and the 3D geometric structure, providing a more comprehensive representation of the molecule.\n6. Combine Encoding In the final step of the encoding process, we compute the atomic embedding $\\mathbf{Z}_{\\mathbf{H}}$ by concatenating the centrality embedding, 2D neighborhood embedding, and 3D neighborhood embedding. This concatenated representation is then passed through a learnable parameter, $W_{\\text {comb } 2} \\in$ $\\mathbb{R}^{\\left(f h_{1}+f h_{2}+f h_{3}\\right) \\times f \\text { in }}$. The final equation for this calculation is given by\n\n$$\n\\mathbf{Z}_{\\mathbf{H}}=W_{\\text {comb }_{2}}\\left(\\left[\\mathbf{Z}_{\\mathbf{H}}^{1 \\mathrm{D}}, \\mathbf{Z}_{\\mathbf{H}}^{2 \\mathrm{D}}, \\mathbf{Z}_{\\mathbf{H}}^{3 \\mathrm{D}}\\right]\\right)+b_{\\text {comb }_{2}}\n$$\n\nThis combination of different embeddings, $\\mathbf{Z}_{\\mathbf{H}} \\in \\mathbb{R}^{n \\times f_{0}}$, enables the incorporation of various molecular structure features, including centrality, 2D, and 3D neighborhood information, into a unified, comprehensive representation.\nAdditionally, the bond encoding $\\mathbf{Z}_{\\mathbf{E}}$ and graph encoding $\\mathbf{Z}_{\\mathbf{M}}$ are utilized to calculate attentions, with details discussed in Sec 4.3 and App A.3.\n\n# A. 2 Attention Biases \n\nThe MUformer incorporates 4 attention biases, which serve to encode spatial relationships in both 2D molecular structure and 3D geometric arrangement. These biases are integrated into the attention mechanism, enhancing the model's ability to process and understand molecular representations. A detailed discussion of the importance and advantages of employing these attention biases for computing attentions in the MUformer can be found in App B.\n1. 2D Spatial Attention Bias To encode the structural relationships between atoms in the molecule graph $\\mathbf{M}^{2 \\mathrm{D}}$, we usethe shortest path distance (SPD) encoding [19], denoted as $\\Phi_{\\mathrm{SPD}}^{2 \\mathrm{D}}(i, j): V \\times V \\rightarrow$ $\\mathbb{R}$, which calculates the distance between atoms $i$ and $j$ in $\\mathbf{M}^{3 \\mathrm{D}}$, providing valuable information about the structural relationships between atoms in the 2D molecular graph.\nAdditionally, following the approach of [19], we incorporate edge-type information along the shortest path between atoms $i$ and $j$ to reflect edge characteristics. This inclusion of edge-type information further enriches the model's understanding of the 2D molecular structure. To achieve this, we determine the shortest path $S P_{i j}=\\left(\\mathbf{e}_{1}, \\mathbf{e}_{2}, \\ldots, \\mathbf{e}_{N}\\right)$, where $N$ is the longest shortest path distance for all pairs of atoms $i$ and $j$. The edge encoding is computed using the following equation,\n\n$$\n\\Phi_{\\mathrm{ENC}_{i j}}^{2 \\mathrm{D}}=\\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{e}_{n}\\left(w_{n}\\right)^{T} \\in \\mathbb{R}\n$$"
    },
    {
      "markdown": "where $w_{\\mu_{i}} \\in \\mathbb{R}^{k \\times 1}$ is a learnable vector with the same dimension as the edge feature. Both 2D spatial biases, $\\Phi_{\\mathrm{SPD}}^{\\text {2D }}$ and $\\Phi_{\\mathrm{ENC}}^{\\text {2D }}$, are in $\\mathbb{R}^{n \\times n \\times 1}$, and the combined bias is calculated as $\\Phi_{\\mathbf{E}}^{\\text {2D }}=\\Phi_{\\mathrm{SPD}}^{\\text {2D }}+\\Phi_{\\mathrm{ENC}}^{\\text {2D }}$. This 2D spatial attention bias enables the model to better capture the intricate relationships between atoms and their surroundings in the 2D molecular graph, ultimately improving its performance.\n2. 3D Spatial Attention Bias The 3D spatial relationships between atom pairs in $\\mathbf{M}^{\\text {3D }}$ can be effectively encoded using the Euclidean distance and an exponential radial basis function, $f_{\\mathrm{RBF} 2}(\\cdot)$ [9]. By incorporating this 3D spatial attention bias, the model is able to account for the geometric arrangement of atoms in the molecule, which is essential for understanding the 3D structure and its impact on molecular properties. The 3D spatial bias, $\\Phi_{\\mathbf{E}}^{\\text {3D }}$, is calculated using the following equation\n\n$$\nd_{i j}=\\left\\|x_{i}-x_{j}\\right\\|_{2}, \\Phi_{\\mathrm{e}_{i j}}^{\\mathrm{3D}}=W_{3 \\mathrm{D}_{2}}\\left(\\operatorname{SiLU}\\left(W_{3 \\mathrm{D}_{1}}\\left(f_{\\mathrm{RBF}_{2}}\\left(d_{i j}\\right)\\right)\\right)\\right)\n$$\n\nwhere $W_{3 \\mathrm{D}_{1}} \\in \\mathbb{R}^{k \\times k}, W_{3 \\mathrm{D}_{2}} \\in \\mathbb{R}^{k \\times 1}$ are learnable parameters, $k$ is the number of basis kernels, and the resulting 3D spatial bias, $\\Phi_{\\mathbf{E}}^{\\text {3D }}$, is in $\\mathbb{R}^{n \\times n \\times 1}$. By including this 3D spatial attention bias in the model, the MUformer is able to better capture the complex 3D spatial relationships between atoms, leading to improved performance in tasks involving 3D molecular structures.\nEdge Feature \\& Graph Feature The embeddings obtained from the 2D structure, $\\mathbf{Z}_{\\mathbf{E}}$, and the molecular graph information, $\\mathbf{Z}_{\\mathrm{M}}$, can be further projected and employed as additional attention biases, enhancing the model's understanding of the molecular structure and relationships. This allows the MUformer to better capture the complexities of the molecular system and improve its performance in various tasks. A detailed explanation of this process can be found in the subsequent section.\n\n# A. 3 Transformer Channels \n\nOur MUformer architecture draws inspiration from Transformer-M [43], which employs two separate channels to process 2D and 3D molecular data, respectively. However, our model takes a different approach to processing the invariant and equivariant features of molecular data. While Transformer-M is limited to predicting atom features only, and is invariant to geometric transformations, our model can predict atom features, molecule structures, and atom positions, and is equivariant to geometric transformations. Our model can be used under different conditions of the input data. When the input data only contains 2D molecular information $\\mathbf{M}^{2 \\mathrm{D}}=(\\mathbf{H}, \\mathbf{E})$ and the geometric structure is missing, only the invariant channel is applied, and the model predicts invariant features including atom features $\\mathbf{H}_{\\text {out }}$ and molecular structure $\\mathbf{E}_{\\text {out }}$. Similarly, when the input data only contains 3D molecular information $\\mathbf{M}^{3 \\mathrm{D}}=(\\mathbf{H}, \\mathbf{X})$ and the molecular structure is missing, only the equivariant channel is used and the model becomes insensitive to geometric information, predicting atom features $\\mathbf{H}_{\\text {out }}$ and coordinates $\\mathbf{X}_{\\text {out }}$. Finally, when both 2D and 3D molecular data are provided as input, both the invariant and equivariant channels are activated. The model is equivariant to geometric transformations, predicting the complete molecule including atom features $\\mathbf{H}_{\\text {out }}$, molecular structure $\\mathbf{E}_{\\text {out }}$, and geometric structure $\\mathbf{X}_{\\text {out }}$.\nThe MUformer architecture utilizes two channels, the invariant channel and the equivariant channel, to learn the 2D molecular structure and 3D geometric structure, respectively. We simplify the notation by omitting the indices of the attention head $h$ and layer $l$.\n\nInvariant Channel. The invariant channel is an improved version of the one presented in [19], which is specifically designed to extract the inherent characteristics of the input molecule graph $\\mathbf{M}^{2 \\mathrm{D}}$, and is utilized to make predictions for atom and edge features by leveraging the underlying graph structure.\n\nWe enhance the MUformer's attention mechanism by incorporating pair-wise information in the invariant channel. First, we calculate intermediate representations for the edge and graph features\n\n$$\n\\begin{aligned}\n& \\mathbf{Z}_{\\mathbf{E}_{1}}=W_{\\mathbf{E}_{1}} \\mathbf{Z}_{\\mathbf{E}}, \\mathbf{Z}_{\\mathbf{E}_{2}}=W_{\\mathbf{E}_{2}} \\mathbf{Z}_{\\mathbf{E}} \\\\\n& \\mathbf{Z}_{\\mathbf{M}_{1}}=W_{\\mathbf{M}_{1}} \\mathbf{Z}_{\\mathbf{M}}, \\mathbf{Z}_{\\mathbf{M}_{2}}=W_{\\mathbf{M}_{2}} \\mathbf{Z}_{\\mathbf{M}}\n\\end{aligned}\n$$\n\nusing weight matrices $W_{\\mathbf{E}_{1}}, W_{\\mathbf{E}_{2}}, W_{\\mathbf{M}_{1}}, W_{\\mathbf{M}_{2}}$. We then compute the attention weights by taking the dot product of the query and key, and modify them by multiplying and adding the intermediate representations,\n\n$$\n\\begin{aligned}\n& \\mathbf{A}=\\frac{\\left(W_{Q} \\mathbf{Z}_{\\mathbf{H}}\\right)^{T}\\left(W_{K} \\mathbf{Z}_{\\mathbf{H}}\\right)}{\\sqrt{F}} \\in \\mathbb{R}^{n \\times n \\times F} \\\\\n& \\mathbf{A}=\\mathbf{A} \\times\\left(\\mathbf{Z}_{\\mathbf{E}_{1}}+\\mathbf{1}\\right)+\\mathbf{Z}_{\\mathbf{E}_{2}}\n\\end{aligned}\n$$"
    },
    {
      "markdown": "And the predicted edge and graph representations, $\\hat{\\mathbf{Z}}_{\\mathbf{E}}, \\hat{\\mathbf{Z}}_{\\mathbf{M}}$, are computed from the attention weights as\n\n$$\n\\begin{aligned}\n& \\hat{\\mathbf{Z}}_{\\mathbf{E}}=W_{\\mathbf{E}_{\\text {out }}}\\left(\\left(\\mathbf{A} \\times\\left(\\mathbf{Z}_{\\mathbf{M}_{1}}+\\mathbf{1}\\right)+\\mathbf{Z}_{\\mathbf{M}_{2}}\\right)\\right. \\\\\n& \\hat{\\mathbf{Z}}_{\\mathbf{M}}=W_{\\mathbf{M}_{\\text {out }}}\\left(f_{\\text {Node2Graph }}\\left(\\mathbf{Z}_{\\mathbf{H}}\\right)+f_{\\text {Edge2Graph }}\\left(\\mathbf{Z}_{\\mathbf{E}}\\right)+\\mathbf{Z}_{\\mathbf{M}}\\right)\n\\end{aligned}\n$$\n\nwhere $f_{\\text {Node2Graph }}(\\cdot)$ and $f_{\\text {Edge2Graph }}(\\cdot)$ are designated functions (see App I) that map node and edge features to graph features, respectively. Finally, the spatial relationships in 2D and 3D are added to the attention weights, the attention is passed through a softmax function and the predicted representation $\\hat{\\mathbf{Z}}_{\\mathbf{F}}$ is obtained by the equation,\n\n$$\n\\begin{aligned}\n& \\mathbf{A}=\\operatorname{softmax}\\left(\\mathbf{A}+\\Phi_{\\mathbf{E}}^{2 \\mathrm{D}}+\\Phi_{\\mathbf{E}}^{3 \\mathrm{D}}\\right) \\in \\mathbb{R}^{n \\times n \\times F} \\\\\n& \\hat{\\mathbf{Z}}_{\\mathbf{H}}=\\mathbf{Z}_{\\mathbf{H}}+W_{\\mathbf{H}_{\\text {out }}}\\left(\\left(W_{V} \\mathbf{Z}_{\\mathbf{H}}\\right) \\mathbf{A}\\right)\n\\end{aligned}\n$$\n\nThe invariant channel can capture the inherent features of the input molecule graph, allowing for predictions of discrete 2D structures, as well as invariant atom and graph features.\n\nEquivariant Channel. The equivariant channel is an upgraded version of the one presented in [21]. It is specifically engineered to extract the features of the input molecule graph $\\mathbf{M}^{3 \\mathrm{D}}$ that change under 3D rotations and translations. This channel is used to make predictions for atom features and coordinates by leveraging the 3D geometric structure of the molecule. It is activated when only the 3D geometric structure $\\mathbf{M}^{3 \\mathrm{D}}$ is provided. The velocity features $\\boldsymbol{v} \\in \\mathbb{R}^{n \\times 3 \\times F}$ are initialized to 0 .\nFirst, we calculate the distance between each pair of atoms, $d_{i j}$, and project them into a multidimensional filter for keys. The attention weights are calculated by taking the dot product of the query, key, and filter, and are modified by incorporating the 3D spatial relationship between atoms. The attention weights are then passed through a softmax function, and the cosine cutoff is applied to the weights to ensure that atoms with a distance larger than $d_{\\text {cut }}$ do not interact.\n\n$$\n\\begin{aligned}\n& d_{i j}=\\left\\|x_{i}-x_{j}\\right\\|_{2} \\\\\n& D_{K}=\\operatorname{SiLU}\\left(W_{\\mathrm{dist}_{K}}\\left(f_{\\mathrm{RBF}_{3}}(d)\\right)+b_{\\mathrm{dist}_{K}}\\right) \\in \\mathbb{R}^{n \\times n \\times F} \\\\\n& \\mathbf{A}=\\frac{\\left(W_{Q} \\mathbf{Z}_{\\mathbf{H}}\\right)^{T}\\left(W_{K} \\mathbf{Z}_{\\mathbf{H}}\\right) \\odot D_{K}}{\\sqrt{F}} \\\\\n& \\mathbf{A}=\\operatorname{softmax}\\left(\\mathbf{A}+\\Phi_{\\mathbf{E}}^{3 \\mathrm{D}}\\right) \\odot f_{\\cos }(d)\n\\end{aligned}\n$$\n\nHere, the final attention weights can also include 2D spatial relationship by adding 2D spatial relationship term $\\Phi_{\\mathbf{E}}^{2 \\mathrm{D}}$ to the equation, and setting $f_{\\cos }\\left(d_{i j}\\right)=1$ if an edge exists between atoms $i$ and $j$ in the 2D molecule graph $\\mathbf{M}^{2 \\mathrm{D}}$.\nIn order to incorporate interatomic distances into the features directly, we also project the distance between atoms into a multidimensional filter for values. This approach, which has been used in [9, 21], enables the model to not only consider interatomic distances in the attention weights, but also to incorporate this information into the features themselves.\n\n$$\n\\begin{aligned}\n& D_{V}=\\operatorname{SiLU}\\left(W_{\\mathrm{dist}_{V}}\\left(f_{\\mathrm{RBF}_{3}}(d)\\right)+b_{\\mathrm{dist}_{V}}\\right) \\in \\mathbb{R}^{n \\times n \\times 3 F} \\\\\n& \\mathbf{Z}_{V}=W_{V} \\mathbf{Z}_{\\mathbf{H}} \\in \\mathbb{R}^{n \\times 3 F} \\\\\n& \\mathbf{Z}_{V_{1}}, \\mathbf{Z}_{V_{2}}, \\mathbf{Z}_{V_{3}}=\\operatorname{split}\\left(\\mathbf{Z}_{V} \\odot D_{V}\\right) \\in \\mathbb{R}^{n \\times n \\times F} \\\\\n& \\mathbf{Z}_{O}=W_{O}\\left(\\mathbf{Z}_{V_{1}} \\mathbf{A}\\right) \\in \\mathbb{R}^{n \\times 3 F} \\\\\n& \\mathbf{Z}_{O_{1}}, \\mathbf{Z}_{O_{2}}, \\mathbf{Z}_{O_{3}}=\\operatorname{split}\\left(\\mathbf{Z}_{O}\\right) \\in \\mathbb{R}^{n \\times F}\n\\end{aligned}\n$$\n\nwhere the function $\\operatorname{split}(\\cdot)$ divides the input into three equal-sized parts.\nThen, we use a weight matrix $W_{\\boldsymbol{v}}$ to project the velocity features $\\boldsymbol{v}$ into three separate vectors,\n\n$$\n\\begin{aligned}\n& \\mathbf{Z}_{\\boldsymbol{v}}=W_{\\boldsymbol{v}} \\boldsymbol{v} \\in \\mathbb{R}^{n \\times 3 \\times 3 F} \\\\\n& \\mathbf{Z}_{\\boldsymbol{v}_{1}}, \\mathbf{Z}_{\\boldsymbol{v}_{2}}, \\mathbf{Z}_{\\boldsymbol{v}_{3}}=\\operatorname{split}\\left(\\mathbf{Z}_{\\boldsymbol{v}}\\right) \\in \\mathbb{R}^{n \\times 3 \\times F}\n\\end{aligned}\n$$\n\nFinally, new atom and velocity features, $\\hat{\\mathbf{Z}}_{\\mathbf{H}}, \\hat{\\boldsymbol{v}}$, are calculated following the steps in [21]. The atom features are updated by adding the residual of the scaled features $\\mathbf{Z}_{O_{1}}$ and the inner product between"
    },
    {
      "markdown": "velocity projections $\\left\\langle\\mathbf{Z}_{\\boldsymbol{v}_{1}}, \\mathbf{Z}_{\\boldsymbol{v}_{2}}\\right\\rangle$. The velocity features are updated by incorporating equivariant features using the edge directional information $d_{i j}$ and scaled vector features.\n\n$$\n\\begin{aligned}\n& \\hat{\\mathbf{Z}}_{\\mathbf{H}}=\\mathbf{Z}_{\\mathbf{H}}+\\left(\\mathbf{Z}_{O_{1}}+\\mathbf{Z}_{O_{2}} \\odot\\left\\langle\\mathbf{Z}_{\\boldsymbol{v}_{1}}, \\mathbf{Z}_{\\boldsymbol{v}_{2}}\\right\\rangle\\right) \\\\\n& \\boldsymbol{w}_{i}=\\sum_{j \\in N(i)} \\mathbf{Z}_{V_{2, i j}} \\odot \\boldsymbol{v}_{i}+\\mathbf{Z}_{V_{3, i j}} \\odot d_{i j} \\\\\n& \\hat{\\boldsymbol{v}}=\\boldsymbol{v}+\\left(\\boldsymbol{w}+\\mathbf{Z}_{O_{3}} \\odot \\mathbf{Z}_{\\boldsymbol{v}_{3}}\\right)\n\\end{aligned}\n$$\n\nInteraction Embedding We denote the predicted atom features of the invariant channel and the equivariant channel as $\\mathbf{Z}_{\\mathbf{H}}^{\\text {inv }}$ and $\\mathbf{Z}_{\\mathbf{H}}^{\\text {apr }}$, respectively. We combine these predictions by multiplying them with a weight matrix $W_{\\text {comb }_{3}}$, and adding a bias term $b_{\\text {comb }_{3}}$,\n\n$$\n\\hat{\\mathbf{Z}}_{\\mathbf{H}}=W_{\\text {comb }_{3}}\\left[\\mathbf{Z}_{\\mathbf{H}}^{\\text {inv }}, \\mathbf{Z}_{\\mathbf{H}}^{\\text {apr }}\\right]+b_{\\text {comb }_{3}}\n$$\n\nBy doing so, we obtain a mixed feature that includes rich invariant representations. This mixed atom feature $\\hat{\\mathbf{Z}}_{\\mathbf{H}}$ is then fed into the next layer of the transformer channels or used as input for the final predictions.\n\nOutput Block The output block generates the final output by utilizing the embeddings from invariant and equivariant channels. Specifically, it takes in the atom $\\hat{\\mathbf{Z}}_{\\mathbf{H}}$ and edge embeddings $\\hat{\\mathbf{Z}}_{\\mathbf{E}}$, along with the velocity embedding $\\hat{\\boldsymbol{v}}$. Through feature extractions, the output block makes predictions for the atom features $\\mathbf{H}_{\\text {out }}$, edge features $\\mathbf{E}_{\\text {out }}$, and atom coordinates $\\mathbf{X}_{\\text {out }}$,\n\n$$\n\\begin{aligned}\n& \\mathbf{H}_{\\text {out }}=W_{\\mathbf{X}_{\\text {out }_{2}}}\\left(\\operatorname{SiLU}\\left(W_{\\mathbf{X}_{\\text {out }_{1}}} \\hat{\\mathbf{Z}}_{\\mathbf{H}}\\right)\\right) \\in \\mathbb{R}^{n \\times d_{\\text {out }}} \\\\\n& \\mathbf{E}_{\\text {out }}=W_{\\mathbf{E}_{\\text {out }_{2}}}\\left(\\operatorname{SiLU}\\left(W_{\\mathbf{E}_{\\text {out }_{1}}} \\hat{\\mathbf{Z}}_{\\mathbf{E}}\\right)\\right) \\in \\mathbb{R}^{n \\times n \\times b_{\\text {out }}} \\\\\n& \\mathbf{X}_{\\text {out }}=\\mathbf{X}+W_{\\boldsymbol{v}_{\\text {out }_{2}}}\\left(\\operatorname{SiLU}\\left(W_{\\boldsymbol{v}_{\\text {out }_{1}}} \\hat{\\boldsymbol{v}}\\right)\\right) \\in \\mathbb{R}^{n \\times 3}\n\\end{aligned}\n$$\n\nAnalysis of Memory Complexity We compare the memory complexity of our method, MUDiff, with two existing methods: EDM [4] and DiGress [6]. Considering atom features of size $n \\times d$, atom positions of size $n \\times 3$, and edge features of size $n \\times n \\times b$, where $n$ is the number of atoms, $d$ is the dimension of atom features, and $b$ is the dimension of edge features, EDM's memory complexity is $O(n d+3 n)$, and DiGress's is $O\\left(n d+n^{2} b\\right)$. MUDiff has a higher memory complexity of $O\\left(n d+3 n+n^{2} b\\right)$, but offers a more comprehensive molecular representation by including both 2D and 3D information for topological and geometric structures. For more on scalability issues and potential solutions, see App K.\n\nUnlike Transformer-M [43], which also employs a two-channel architecture to process 2D and 3D molecular data but is limited to predicting atom features only, our model can make predictions for atom features, molecular structures, and atom positions, while also being robust to geometric transformations. The two channels in Transformer-M are not explicitly designed as invariant and equivariant channels, which makes their model less robust to geometric transformations.\nOur MUformer architecture can be used under different input conditions. When only 2D molecular information is available, only the invariant channel is activated, and the model makes predictions for atom and edge features only. When only 3D molecular information is available, only the equivariant channel is activated, and the model makes predictions for atom features and coordinates only. When both 2D and 3D molecular data are provided, the invariant and equivariant channels are activated, and the model can make predictions for the complete molecule, including atom features, molecular structure, and geometric structure. More details about our MUformer architecture, as well as a comparison with Transformer-M, can be found in App A.3.\n\n# B Importance of 2D and 3D Attention Biases \n\nIn Sec 4.2, we introduce two attention biases employed in MUformer to compute attentions, one for 2D molecular structure and another for 3D geometric structure. For the 2D spatial attention bias, we use the Shortest Path Distance (SPD) encoding to capture the distance between atoms $i$ and $j$ in the 2D molecular graph, providing vital structural relationship information. Additionally, we incorporate edge-type information along the shortest path, which reflects the connections between atoms $i$ and"
    },
    {
      "markdown": "$j$, further enhancing the model's understanding of the 2D molecular graph. In the case of the 3D spatial attention bias, we calculate the bias using the Euclidean distance and an exponential radial basis function, which encodes the 3D spatial relationships between atom pairs in the 3D molecular structure. This approach helps the model account for the geometric arrangement of atoms in the molecule. These biases are used to improve the model's representation of molecular structures by capturing essential structural features and relationships in both 2D and 3D spaces.\n\n2D Attention Bias. The 2D spatial attention bias, which consists of the Shortest Path Distance (SPD) encoding and edge-type information, helps the model to capture the topological relationships between atoms in the 2D molecular graph. By incorporating this bias into the attention computation, the model can better understand the structural relationships and chemical properties of the molecule, leading to improved prediction and generation tasks.\n\n3D Attention Bias. The 3D spatial attention bias encodes the 3D spatial relationships between atom pairs in the molecular structure using Euclidean distance and an exponential radial basis function. By including this information as a bias in the attention computation, the model can account for the geometric arrangement of atoms in the molecule. This allows the MUformer to recognize spatial patterns and interactions that are not apparent in the 2D graph representation alone.\nThe attention biases introduced in Sec 4.2 for both 2D and 3D molecular structures enhance the MUformer ability to capture essential structural features and relationships in both spaces. By incorporating these biases in the attention computation, the model can prioritize and focus on the most relevant connections between atoms, resulting in a more accurate and comprehensive molecular representation.\n\n# C Analysis of Interdependence of Generation of 2D and 3D Structures \n\nMotivation. Generating both 2D and 3D structures can provide a more complete representation of the molecular structure, as it captures both the planar arrangement of atoms in the molecule and their spatial arrangement in 3D space. By combining the generation of 2D and 3D structures, we can provide a more comprehensive understanding of the molecular structure, which could be useful for a variety of applications in drug discovery, materials science, and other fields.\nWe discuss their effects from three perspectives, (1) conformational space, (2) stereochemistry, and (3) constraint.\n\nImpact of 2D Generation on 3D Generation. (1) From the conformational perspective, the 2D structure can provide information about the planar arrangement of atoms in the molecule, which can be used to guide the generation of the 3D structure. By considering the 2D structure, the generation algorithm can explore different conformations and orientations of the molecule in a 3D space, which can help generate a more accurate 3D structure. (2) From the stereochemistry perspective, the 2D structure can provide information about the stereochemistry and chirality of the molecule, which can be used to guide the generation of the 3D structure. For example, if the 2D structure indicates that two atoms are connected by a double bond, the generation algorithm can infer the correct geometry for the double bond in the 3D space based on the stereochemistry of the molecule. (3) From the constraints' perspective, the 2D structure can provide constraints on the geometry of the molecule, which can be used to guide the generation of the 3D structure. For example, if the 2D structure indicates that two atoms are connected by a ring, the generation algorithm can use this information to constrain the geometry of the ring in a 3D space.\n\nImpact of 3D Generation on 2D Generation. (1) From the conformational perspective, the generation of 3D structures can provide information about the conformational space of the molecule, which can be used to refine the 2D structure. For example, if the 3D structure indicates that two atoms are in close proximity, the generation algorithm can adjust the 2D structure to reflect this. (2) From the stereochemistry perspective, the 3D structure can provide additional information about the stereochemistry and chirality of the molecule, which can be used to refine the 2D structure. For example, if the 3D structure indicates that two atoms have a specific orientation in 3D space, the generation algorithm can adjust the 2D structure to reflect this. (3) From the constraint perspective, the 3D structure can provide additional constraints on the geometry of the molecule, which can be used to refine the 2D structure. For example, if the 3D structure indicates that two atoms are"
    },
    {
      "markdown": "connected by a ring, the generation algorithm can adjust the 2 D structure to ensure that the ring is planar.\n\n# D Additional Empirical Results \n\n## D. 1 Molecule Generation on DRUG\n\nWe compare the performance of our MUDiff model with popular generative models, including GDM [4], EDM [4], MDM [39], and GeoLDM [40]. The results are reported in Table 4 As outlined in $[39,40]$, we evaluate the atom and molecule stability of the generated compounds.\n\nTable 4: Atom stability, molecule stability, and validity are evaluated across 3 runs on DRUG.\n\n| Method | Validity | Atom Stable(\\%) | Mol Stable(\\%) |\n| :-- | :--: | :--: | :--: |\n| GDM | 90.8 | 75.0 | - |\n| EDM | 92.6 | 81.3 | 13.0 |\n| MDM | 99.8 | - | 62.2 |\n| GeoLDM | 99.3 | 84.4 | - |\n| MUDiff (ours) | 98.9 | 84.0 | 60.9 |\n\n## D. 2 Conditional Generation\n\nOur method can be extended for conditional molecule generation, as detailed in App D.2.1. We follow the experimental setting in [4] to train the conditional MUDiff model on the QM9 dataset, conditioning the generation on properties $\\alpha, \\epsilon_{\\text {homo }}, \\epsilon_{\\text {lumo }}, \\Delta \\epsilon, \\mu$, and $C_{v}$, respectively.\nAdditionally, we follow [4] to use a property classifier $\\psi_{c}$ proposed in [31]. We split QM9 training data into two halves, $A$ and $B$, each containing 50 K samples, and use $A$ subset to train $\\psi_{c}$ and $B$ subset for training the conditional MUDiff. Then, $\\psi_{c}$ is used to evaluate the generated samples of conditional MUDiff. Also, we follow [4] to report the loss of $\\psi_{c}$ on $B$ as a lower bound (L-bound). The smaller the gap between MUDiff and L-bound, the more similar MUDiff generated samples to $B$.\n\nTable 5: Mean Absolute Error for the prediction of molecular properties by the property classifier $\\psi_{c}$ on a QM9 subset (L-bound), MUDiff samples and three baselines.\n\n| Property <br> Units | $\\alpha$ | $\\epsilon_{\\text {homo }}$ | $\\epsilon_{\\text {lumo }}$ | $\\Delta \\epsilon$ | $\\mu$ | $C_{v}$ |\n| :-- | :--: | :--: | :--: | :--: | :--: | :--: |\n| U-bound | $9.01$ | 645 | 1457 | 1470 | 1.616 | 6.857 |\n| PAtoms | 3.86 | 426 | 813 | 866 | 1.053 | 1.971 |\n| EDM | 2.76 | 356 | $\\mathbf{5 8 4}$ | 655 | 1.111 | 1.101 |\n| MUDiff (ours) | $\\mathbf{2 . 1 5}$ | $\\mathbf{3 1 5}$ | 597 | $\\mathbf{6 0 4}$ | $\\mathbf{1 . 0 3 3}$ | $\\mathbf{0 . 9 7 8}$ |\n| L-bound | 0.10 | 39 | 36 | 64 | 0.043 | 0.040 |\n\nWe evaluate the performance against the baselines used in EDM [4]. In addition to L-bound, they also use two other baselines: U-bound and \\#Atoms. The U-bound is obtained by shuffling the properties of molecules in the $B$ subset and evaluating $\\psi_{c}$ on it. The \\#Atoms baseline predicts the molecular properties in the $B$ subset by only using the number of atoms in the molecule.\n\nResults. Table 5 showcases the results of conditional generation on the QM9 dataset. Evidently, conditional MUDiff generates samples that more closely resemble the molecules in subset B compared to the baselines, indicating that MUDiff outperforms baselines in generating molecules with desired properties and capturing structural similarities.\n\n## D.2.1 Conditional Generation\n\nWe follow the conditional molecule generation procedure in [4]. We train the conditional MUDiff by concatenating the conditions $c$ with atom features, the Eq 4 is rewritten as\n\n$$\n\\hat{\\boldsymbol{\\epsilon}}_{\\mathbf{H}}^{t}, p(\\hat{\\mathbf{E}}), \\hat{\\boldsymbol{\\epsilon}}_{\\mathbf{X}}^{t}=\\psi_{\\theta}\\left(\\left[\\hat{\\mathbf{H}}_{t}, \\frac{t}{T}, c\\right], \\hat{\\mathbf{E}}_{t}, \\hat{\\mathbf{X}}_{t}\\right)-\\left(\\mathbf{0}, \\mathbf{0}, \\hat{\\mathbf{X}}_{t}\\right)\n$$"
    },
    {
      "markdown": "and the loglikelihood (in Eq 43) is modified to\n\n$$\n\\log p(\\mathbf{M} \\mid c) \\geq \\underbrace{D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{M}_{T} \\mid \\mathbf{M}, c\\right)\\left\\|p\\left(\\mathbf{M}_{T} \\mid c\\right)\\right]}_{\\text {Prior loss }}+\\underbrace{\\mathbb{E}_{q\\left(\\mathbf{M}_{0} \\mid \\mathbf{M}, c\\right)}\\left[\\log p\\left(\\mathbf{M} \\mid \\mathbf{M}_{0}, c\\right)\\right]}_{\\text {Reconstriction loss }}+\\underbrace{\\sum_{t=1}^{T} \\mathcal{L}_{t, c}}_{\\text {Diffusion loss }}\n$$\n\nwhere\n\n$$\n\\mathcal{L}_{t, c}=\\mathbb{E}_{q\\left(\\mathbf{M}_{t} \\mid \\mathbf{M}, c\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{M}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}, c\\right)\\left\\|p\\left(\\mathbf{M}_{t-1} \\mid \\mathbf{M}_{t}, c\\right)\\right]\\right]\n$$\n\nIn order to perform conditional sampling, we adopt the method outlined in [4]. Specifically, we first sample a condition $c$ from the condition distribution, and then use this condition to generate molecules via the conditional distribution $p(\\widetilde{\\mathbf{M}} \\mid c)$. The details of the model training procedure and architecture can be found in App J. This approach allows us to generate molecules that are conditioned on specific properties, such as electronic energy levels or heat capacity.\n\nProperties. Following the methodology used in previous works such as [4], we condition the generation of molecules on several properties. Specifically, we condition the generation on the polarizability $(\\alpha)$, the highest occupied molecular orbital energy ( $\\epsilon_{\\text {homo }}$ ), the lowest unoccupied molecular orbital energy ( $\\epsilon_{\\text {lumo }}$ ), the energy difference between the highest occupied and lowest unoccupied molecular orbital energy ( $\\Delta \\epsilon$ ), the dipole moment $(\\mu)$ and the heat capacity at 298.15 K $\\left(C_{v}\\right)$. These properties provide specific information about the physical and chemical properties of a molecule, allowing us to generate molecules with specific desired characteristics.\n\n# D. 3 Property Prediction on QM9 \n\nWe conduct a thorough comparison of our MUformer model against several state-of-the-art (SOTA) models for property prediction on the QM9 dataset, including SchNet [9], EGNN [2], PhysNet [17], DimeNet [41], Cormorant [36], PaiNN [42], and ET [21]. The results, which can be found in Table 6, are obtained by averaging over three runs. We use a learning rate of $1 \\mathrm{e}-3,1 \\mathrm{e}-4,5 \\mathrm{e}-4$ and $1 \\mathrm{e}-5$, weight decay of $5 \\mathrm{e}-5,128$ hidden dimensions, and 6 layers for our MUformer model. The results of the baseline models are taken from [21].\n\nTable 6: Results on all QM9 targets and comparison to previous literature. Scores are reported as mean absolute errors (MAE) with standard deviation. Results of different models are averaged over three runs.\n\n| Target | Unit | SchNet | EGNN | PhysNet | DimeNet++ | Cormorant | PaiNN | ET | MUformer |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n| $\\mu$ | $D$ | 0.033 | 0.029 | 0.0529 | 0.041 | 0.0297 | 0.012 | 0.011 | $0.013 \\pm 0.003$ |\n| $\\alpha$ | $a_{0}^{3}$ | 0.235 | 0.071 | 0.0615 | 0.0435 | 0.085 | 0.045 | 0.059 | $0.041 \\pm 0.008$ |\n| $\\epsilon_{\\text {HOMO }}$ | $m e V$ | 41 | 29 | 32.9 | 24.6 | 34 | 27.6 | 20.3 | $24.7 \\pm 1.2$ |\n| $\\epsilon_{\\text {LOMO }}$ | $m e V$ | 34 | 25 | 24.7 | 19.5 | 38 | 20.4 | 17.5 | $20.2 \\pm 0.8$ |\n| $\\Delta \\epsilon$ | $m e V$ | 63 | 48 | 42.5 | 32.6 | 61 | 45.7 | 36.1 | $30.3 \\pm 1.7$ |\n| $\\left\\langle R^{2}\\right\\rangle$ | $a_{0}^{2}$ | 0.073 | 0.106 | 0.765 | 0.331 | 0.961 | 0.066 | 0.033 | $0.117 \\pm 0.012$ |\n| ZPVE | $m e V$ | 1.7 | 1.55 | 1.39 | 1.21 | 2.027 | 1.28 | 1.84 | $1.76 \\pm 0.08$ |\n| $\\mathbf{U}_{0}$ | $m e V$ | 14 | 11 | 8.15 | 6.32 | 22 | 5.85 | 6.15 | $6.11 \\pm 0.12$ |\n| U | $m e V$ | 19 | 12 | 8.34 | 6.28 | 21 | 5.83 | 6.38 | $6.04 \\pm 0.19$ |\n| H | $m e V$ | 14 | 12 | 8.42 | 6.53 | 21 | 5.98 | 6.16 | $6.77 \\pm 0.07$ |\n| G | $m e V$ | 14 | 12 | 9.4 | 7.56 | 20 | 7.35 | 7.62 | $7.24 \\pm 0.08$ |\n| $\\mathbf{C}_{v}$ | $\\frac{\\text { out }}{m m V}$ | 0.033 | 0.031 | 0.028 | 0.023 | 0.026 | 0.024 | 0.026 | $0.023 \\pm 0.002$ |\n\n## D. 4 Ablation Study\n\nTo investigate how different components will impact the performance of MUDiff, we conduct ablation study in this subsection. The details of the experimental settings can be found in App D.4.1.\n\nResults. The results in Table 7 demonstrate the effectiveness of each component in MUformer. We can see that each component proposed in Sec 4 plays an indispensable role in learning all aspects of the molecule in a unified manner and the diffusion model with all components combined generates the most stable and valid molecules."
    },
    {
      "markdown": "Table 7: The performance of molecule stability and validity across different ablation models, as shown by the average value with standard deviation of 1 K generated molecules (with hydrogen) from each model. Model variations include using (i) 2D structure encoding, (ii) graph encoding, (iii) 2D neighborhood encoding, (iv) 3D neighborhood encoding, (v) 2D spatial attention bias, (vi) 3D spatial attention bias, (vii) edge features as attention bias, (viii) graph features as attention bias, and (ix) 2D discrete graph structures into 3D geometric structures.\n\n| Encoding |  |  |  | Bias |  |  |  |  |  |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n| $i$ | $i i$ | $i i i$ | $i v$ | $v$ | $v i$ | $v i i$ | $v i i i$ | $i x$ | Mol Stable (\\%) | Valid (\\%) |\n|  |  |  |  |  |  |  |  | $82.5 \\pm 6.3$ |  | $90.7 \\pm 2.2$ |\n| $\\checkmark$ |  |  |  |  |  |  |  | $82.7 \\pm 1.9$ |  | $91.3 \\pm 1.7$ |\n| $\\checkmark$ |  | $\\checkmark$ |  |  |  |  |  | $82.9 \\pm 1.5$ |  | $91.6 \\pm 2.1$ |\n| $\\checkmark$ |  | $\\checkmark$ |  | $\\checkmark$ |  | $\\checkmark$ |  | $84.7 \\pm 1.2$ |  | $92.9 \\pm 1.3$ |\n| $\\checkmark$ |  |  | $\\checkmark$ |  |  |  |  | $85.3 \\pm 1.0$ |  | $93.6 \\pm 1.9$ |\n| $\\checkmark$ |  |  | $\\checkmark$ |  | $\\checkmark$ |  |  | $86.1 \\pm 1.7$ |  | $93.5 \\pm 1.3$ |\n| $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ |  |  |  |  | $87.2 \\pm 1.6$ |  | $93.4 \\pm 1.0$ |\n| $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ |  | $\\checkmark$ |  |  | $87.1 \\pm 1.5$ |  | $94.8 \\pm 1.4$ |\n| $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ |  |  | $88.3 \\pm 1.5$ |  | $94.5 \\pm 1.3$ |\n| $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | 88.4 5 |  | $95.1 \\pm 1.3$ |\n| $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $\\checkmark$ | $89.3 \\pm 1.3$ | $95.3 \\pm 1.2$ |\n\n# D.4.1 Ablation Study \n\nTo improve efficiency, we conduct ablation studies using smaller models than those described in App J. Specifically, these models consist of 4 layers, 64 embedding dimensions for atom- and edge-level features, 32 embedding dimensions for graph-level features, 8 attention heads, 100 feedforward dimensions for atom- and edge-level features, 50 feedforward dimensions for graph-level features, 0.3 dropout rate for all latent embeddings and attention values, SiLU activation function, 1e-4 learning rate, and Adam optimizer with $5 \\mathrm{e}-5$ weight decay. Additionally, we use a diffusion process with 500 time steps over the course of 3000 training epochs.\nAdditionally, if 2D structure encoding is not used, the edge type $\\mathbf{E}$ is simply embedded by a weight matrix $W$ as\n\n$$\n\\mathbf{Z}_{\\mathbf{E}}=W \\mathbf{E} \\in \\mathbb{R}^{n \\times n \\times f e_{\\mathbf{u}}}\n$$\n\nTo reduce computation costs, we sample 1,000 molecules from each MUDiff ablation model instead of the 10,000 samples typically generated by the diffusion model during sampling. This allows us to evaluate the performance of the various MUDiff models while minimizing the computational resources required.\n\nModel variations for ablation study include: (1) no extra technique, (2) 2D structure encoding, (3) 2D structure encoding +2 D neighborhood encoding, (4) 2D structure encoding +2 D neighborhood encoding +2 D spatial attention bias + edge features as attention bias, (5) 2D structure encoding + 3D neighborhood encoding, (6) 2D structure encoding +3 D neighborhood encoding +3 D spatial attention bias, (7) 2D structure encoding + graph encoding +2 D neighborhood encoding +3 D neighborhood encoding, (8) 2D structure encoding + graph encoding +2 D neighborhood encoding + 3D neighborhood encoding +3 D spatial attention bias, (9) 2D structure encoding + graph encoding + 2D neighborhood encoding +3 D neighborhood encoding +2 D spatial attention bias +3 D spatial attention bias, (10) 2D structure encoding + graph encoding +2 D neighborhood encoding +3 D neighborhood encoding +2 D spatial attention bias +3 D spatial attention bias + edge features as attention bias + graph features as attention bias, (11) 2D structure encoding + graph encoding + 2D neighborhood encoding +3 D neighborhood encoding +2 D spatial attention bias +3 D spatial attention bias + edge features as attention bias + graph features as attention bias +2 D discrete graph structures into 3D geometric structures.\n\n## E Limit Distribution for Edges\n\n[6] suggests that the limit distribution $q_{\\infty}=\\lim _{T \\rightarrow \\infty} q\\left(\\widehat{\\mathbf{E}}_{T} \\mid \\mathbf{E}\\right)$ should be independent of clean data E for efficient diffusion models. In our diffusion model, the discrete process for noising/denoising discrete graph structures $\\mathbf{E} \\in \\mathbb{R}^{n \\times n \\times b}$, we use a sequence of transition matrices $\\left\\{\\hat{Q}_{t}\\right\\}_{t=0}^{t}$ to add"
    },
    {
      "markdown": "noise to $\\mathbf{E}$. In our choice, we follow $[6,16]$ to use the simplest uniform transition parameterized by\n\n$$\n\\begin{aligned}\n& \\bar{Q}_{t}=\\alpha_{t} \\mathbf{I}+\\left(1-\\alpha_{t}\\right) \\frac{\\mathbb{1}_{b} \\mathbb{1}_{b}^{T}}{b} \\in \\mathbb{R}^{b \\times b} \\\\\n& \\tilde{\\mathbf{E}}_{t}=\\mathbf{E} \\bar{Q}_{t} \\in \\mathbb{R}^{n \\times n \\times b}\n\\end{aligned}\n$$\n\nwith $\\alpha_{t}$ smoothly transition from $1 \\rightarrow 0$ as $t$ goes from $0 \\rightarrow T$. When $t$ gradually goes to $\\infty$,\n\n$$\n\\begin{aligned}\n\\lim _{t \\rightarrow \\infty} \\bar{Q}_{t} & =\\lim _{t \\rightarrow \\infty} \\alpha_{t} \\mathbf{I}+\\left(1-\\alpha_{t}\\right) \\frac{\\mathbb{1}_{b} \\mathbb{1}_{b}^{T}}{b} \\\\\n& =\\lim _{t \\rightarrow \\infty} \\alpha_{t} \\mathbf{I}+\\left(1-\\lim _{t \\rightarrow \\infty} \\alpha_{t}\\right) \\frac{\\mathbb{1}_{b} \\mathbb{1}_{b}^{T}}{b} \\\\\n& =\\frac{\\mathbb{1}_{b} \\mathbb{1}_{b}^{T}}{b}\n\\end{aligned}\n$$\n\nIt suggests that $q\\left(\\tilde{\\mathbf{E}}_{t} \\mid \\mathbf{E}\\right)$ converges to a uniform distribution as $t \\rightarrow T$, and the limit distribution $q_{\\infty}$ is just a uniform distribution over the edge categories independently of $\\mathbf{E}$.\n\n# F Likelihood and Lower Bound \n\nFor simplicity, we use $\\mathbf{M}_{t}=\\left(\\mathbf{H}_{\\mathbf{t}}, \\mathbf{E}_{\\mathbf{t}}, \\mathbf{X}_{\\mathbf{t}}\\right)$ to denote the noisy molecule $\\tilde{\\mathbf{M}}_{t}=\\left(\\tilde{\\mathbf{H}}_{t}, \\tilde{\\mathbf{E}}_{t}, \\tilde{\\mathbf{X}}_{t}\\right)$ at time $t$. Following [15], the variational lower bound on the log-likelihood of a molecule $\\mathbf{M}$ is derived as\n\n$$\n\\log p(\\mathbf{M}) \\geq \\underbrace{D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{M}_{T} \\mid \\mathbf{M}\\right)\\left\\|p\\left(\\mathbf{M}_{T}\\right)\\right]\\right.}_{\\text {Prior loss }}+\\underbrace{\\mathbb{E}_{q\\left(\\mathbf{M}_{0} \\mid \\mathbf{M}\\right)}\\left[\\log p\\left(\\mathbf{M} \\mid \\mathbf{M}_{0}\\right)\\right]}_{\\text {Reconstruction loss }}+\\underbrace{\\sum_{t=1}^{T} \\mathcal{L}_{t}}_{\\text {Diffusion loss }}\n$$\n\nwhere\n\n$$\n\\mathcal{L}_{t}=\\mathbb{E}_{q\\left(\\mathbf{M}_{t} \\mid \\mathbf{M}\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{M}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}\\right)\\left\\|p\\left(\\mathbf{M}_{t-1} \\mid \\mathbf{M}_{t}\\right)\\right]\\right]\n$$\n\nThe prior loss is fairly simple,\n\n$$\n\\begin{aligned}\nD_{\\mathrm{KL}}\\left[q\\left(\\mathbf{M}_{T} \\mid \\mathbf{M}\\right)\\left\\|p\\left(\\mathbf{M}_{T}\\right)\\right]\\right. & =D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{T}, \\mathbf{E}_{T}, \\mathbf{X}_{T} \\mid \\mathbf{H}, \\mathbf{E}, \\mathbf{X}\\right)\\left\\|p\\left(\\mathbf{H}_{T}, \\mathbf{E}_{T}, \\mathbf{X}_{T}\\right)\\right]\\right. \\\\\n& \\text { by chain rule } \\\\\n& =D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{T} \\mid \\mathbf{H}, \\mathbf{E}, \\mathbf{X}\\right)\\left\\|p\\left(\\mathbf{H}_{T}\\right)\\right]+D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{E}_{T}, \\mathbf{X}_{T} \\mid \\mathbf{H}, \\mathbf{E}, \\mathbf{X}, \\mathbf{H}_{T}\\right)\\left\\|p\\left(\\mathbf{E}_{T}, \\mathbf{X}_{T} \\mid \\mathbf{H}_{T}\\right)\\right]\\right. \\\\\n& =D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{T} \\mid \\mathbf{H}, \\mathbf{E}, \\mathbf{X}\\right)\\left\\|p\\left(\\mathbf{H}_{T}\\right)\\right]+D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{E}_{T} \\mid \\mathbf{H}, \\mathbf{E}, \\mathbf{X}, \\mathbf{H}_{T}\\right)\\left\\|p\\left(\\mathbf{E}_{T} \\mid \\mathbf{H}_{T}\\right)\\right]\\right. \\\\\n& \\left.+D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{X}_{T} \\mid \\mathbf{H}, \\mathbf{E}, \\mathbf{X}, \\mathbf{H}_{T}, \\mathbf{E}_{T}\\right)\\left\\|p\\left(\\mathbf{X}_{T} \\mid \\mathbf{H}_{T}, \\mathbf{E}_{T}\\right)\\right)\\right]\n\\end{aligned}\n$$\n\ndue to indenpendence\n\n$$\n=D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{T} \\mid \\mathbf{H}\\right)\\left\\|p\\left(\\mathbf{H}_{T}\\right)\\right]+D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{E}_{T} \\mid \\mathbf{E}\\right)\\left\\|p\\left(\\mathbf{E}_{T}\\right)\\right]+D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{X}_{T} \\mid \\mathbf{X}\\right)\\left\\|p\\left(\\mathbf{X}_{T}\\right)\\right]\\right.\\right.\n$$\n\nwhere $D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{T} \\mid \\mathbf{H}\\right)\\left\\|p\\left(\\mathbf{H}_{T}\\right)\\right]\\right.$ models the distance between a standard normal distribution $\\mathcal{N}_{\\mathbf{H}}(\\mathbf{0}, \\mathbf{I})$ and the final noisy variable $q\\left(\\mathbf{H}_{T} \\mid \\mathbf{H}\\right), D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{X}_{T} \\mid \\mathbf{X}\\right)\\left\\|p\\left(\\mathbf{X}_{T}\\right)\\right]\\right.$ models the distance between another standard normal distribution $\\mathcal{N}_{\\mathbf{X}}(\\mathbf{0}, \\mathbf{I})$ and the final noisy variable $q\\left(\\mathbf{X}_{T} \\mid \\mathbf{X}\\right)$, and $D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{E}_{T} \\mid \\mathbf{E}\\right)\\left\\|p\\left(\\mathbf{E}_{T}\\right)\\right]\\right.$ measures the KL divergence between the uniform distribution over edge categories and the final noisy variable $q\\left(\\mathbf{E}_{T} \\mid \\mathbf{E}\\right)$. The prior loss $D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{M}_{T} \\mid \\mathbf{M}\\right)\\left\\|p\\left(\\mathbf{M}_{T}\\right)\\right]\\right.$ is always close to zero.\n\nThe reconstruction loss,\n\n$$\n\\begin{aligned}\n\\mathbb{E}_{q\\left(\\mathbf{M}_{0} \\mid \\mathbf{M}\\right)}\\left[\\log p\\left(\\mathbf{M} \\mid \\mathbf{M}_{0}\\right)\\right] & =\\mathbb{E}_{q\\left(\\mathbf{H}_{0}, \\mathbf{E}_{0}, \\mathbf{X}_{0} \\mid \\mathbf{H}, \\mathbf{E}, \\mathbf{X}\\right)}\\left[\\log p\\left(\\mathbf{H}, \\mathbf{X}, \\mathbf{E} \\mid \\mathbf{H}_{0}, \\mathbf{E}_{0}, \\mathbf{X}_{0}\\right)\\right] \\\\\n& =\\mathbb{E}_{q\\left(\\mathbf{H}_{0}, \\mathbf{E}_{0}, \\mathbf{X}_{0} \\mid \\mathbf{H}, \\mathbf{E}, \\mathbf{X}\\right)}\\left[\\log p\\left(\\mathbf{H}\\left|\\mathbf{H}_{0}\\right\\rangle p\\left(\\mathbf{E} \\mid \\mathbf{E}_{0}\\right) p\\left(\\mathbf{X} \\mid \\mathbf{X}_{0}\\right)\\right]\\right. \\\\\n& =\\mathbb{E}_{q\\left(\\mathbf{H}_{0}, \\mathbf{E}_{0}, \\mathbf{X}_{0} \\mid \\mathbf{H}, \\mathbf{E}, \\mathbf{X}\\right)}\\left[\\log p\\left(\\mathbf{H}\\left|\\mathbf{H}_{0}\\right\\rangle+\\log p\\left(\\mathbf{E} \\mid \\mathbf{E}_{0}\\right)+\\log p\\left(\\mathbf{X} \\mid \\mathbf{X}_{0}\\right)\\right]\\right. \\\\\n& =\\mathbb{E}_{q\\left(\\mathbf{H}_{0} \\mid \\mathbf{H}, \\mathbf{E}, \\mathbf{X}\\right)}\\left[\\log p\\left(\\mathbf{H}\\left|\\mathbf{H}_{0}\\right\\rangle\\right] \\mathbb{E}_{q\\left(\\mathbf{E}_{0}, \\mid \\mathbf{H}, \\mathbf{E}, \\mathbf{X}\\right)}\\left[\\log p\\left(\\mathbf{E} \\mid \\mathbf{E}_{0}\\right)\\right] \\mathbb{E}_{q\\left(\\mathbf{X}_{0} \\mid \\mathbf{H}, \\mathbf{E}, \\mathbf{X}\\right)}\\left[\\log p\\left(\\mathbf{X} \\mid \\mathbf{X}_{0}\\right)\\right]\\right. \\\\\n& =\\mathbb{E}_{q\\left(\\mathbf{H}_{0} \\mid \\mathbf{H}\\right)}\\left[\\log p\\left(\\mathbf{H}\\left|\\mathbf{H}_{0}\\right\\rangle\\right] \\mathbb{E}_{q\\left(\\mathbf{E}_{0}, \\mid \\mathbf{E}\\right)}\\left[\\log p\\left(\\mathbf{E} \\mid \\mathbf{E}_{0}\\right)\\right] \\mathbb{E}_{q\\left(\\mathbf{X}_{0} \\mid \\mathbf{X}\\right)}\\left[\\log p\\left(\\mathbf{X} \\mid \\mathbf{X}_{0}\\right)\\right]\\right.\n\\end{aligned}\n$$\n\nFor discrete data $\\mathbf{E}, \\log p\\left(\\mathbf{E} \\mid \\mathbf{E}_{0}\\right)$ is computed from the probability of clean edge features given noisy edge features $p\\left(\\mathbf{E} \\mid \\mathbf{E}_{0}\\right)$. For continuous data $\\mathbf{H}, \\mathbf{X}, \\log p\\left(\\mathbf{H} \\mid \\mathbf{H}_{0}\\right)$ models the likelihood of $\\mathbf{H}$ given"
    },
    {
      "markdown": "$\\mathbf{H}_{0} \\sim q\\left(\\mathbf{H}_{0} \\mid \\mathbf{H}\\right), \\log p\\left(\\mathbf{X} \\mid \\mathbf{X}_{0}\\right)$ models the likelihood of $\\mathbf{X}$ given $\\mathbf{X}_{0} \\sim q\\left(\\mathbf{X}_{0} \\mid \\mathbf{X}\\right)$, and the details of zeroth likelihood is discussed in App H.\n\nThe diffusion loss is different than the training loss in Eq 6,7, but still at each time step $t$, the diffusion loss is composed of atom feature loss, edge feature loss, and atom coordinate loss,\n\n$$\n\\begin{aligned}\n\\mathcal{L}_{t} & =\\mathbb{E}_{q\\left(\\mathbf{M}_{t} \\mid \\mathbf{M}\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{M}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}\\right) \\| p\\left(\\mathbf{M}_{t-1} \\mid \\mathbf{M}_{t}\\right)\\right]\\right] \\\\\n& =\\mathbb{E}_{q\\left(\\mathbf{M}_{t} \\mid \\mathbf{M}\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{t-1}, \\mathbf{E}_{t-1}, \\mathbf{X}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}\\right) \\| p\\left(\\mathbf{H}_{t-1}, \\mathbf{E}_{t-1}, \\mathbf{X}_{t-1} \\mid \\mathbf{M}_{t}\\right)\\right]\\right]\n\\end{aligned}\n$$\n\nby chain rule\n\n$$\n\\begin{aligned}\n& =\\mathbb{E}_{q\\left(\\mathbf{M}_{t} \\mid \\mathbf{M}\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}\\right) \\| p\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{M}_{t}\\right)\\right]+D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{E}_{t-1}, \\mathbf{X}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}, \\mathbf{H}_{t-1}\\right) \\| p\\left(\\mathbf{E}_{t-1}, \\mathbf{X}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{H}_{t-1}\\right)\\right]\\right] \\\\\n& =\\mathbb{E}_{q\\left(\\mathbf{M}_{t} \\mid \\mathbf{M}\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}\\right) \\| p\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{M}_{t}\\right)\\right]+D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}, \\mathbf{H}_{t-1}\\right) \\| p\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{H}_{t-1}\\right)\\right]\\right] \\\\\n& +D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}, \\mathbf{H}_{t-1}, \\mathbf{E}_{t-1}\\right) \\| p\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{H}_{t-1}, \\mathbf{E}_{t-1}\\right)\\right]\n\\end{aligned}\n$$\n\ndue to independence\n\n$$\n\\begin{aligned}\n& =\\mathbb{E}_{q\\left(\\mathbf{M}_{t} \\mid \\mathbf{M}\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}\\right) \\| p\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{M}_{t}\\right)\\right]+D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}\\right) \\| p\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{M}_{t}\\right)\\right]+D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}\\right) \\| p\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{M}_{t}\\right)\\right] \\\\\n& =\\mathbb{E}_{q\\left(\\mathbf{M}_{t} \\mid \\mathbf{M}\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}\\right) \\| p\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{M}_{t}\\right)\\right]\\right]+\\mathbb{E}_{q\\left(\\mathbf{M}_{t} \\mid \\mathbf{M}\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}\\right) \\| p\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{M}_{t}\\right)\\right]\\right] \\\\\n& +\\mathbb{E}_{q\\left(\\mathbf{M}_{t} \\mid \\mathbf{M}\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{M}_{t}, \\mathbf{M}\\right) \\| p\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{M}_{t}\\right)\\right]\\right] \\\\\n& =\\mathbb{E}_{q\\left(\\mathbf{H}_{t} \\mid \\mathbf{H}\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{H}_{t}, \\mathbf{H}\\right) \\| p\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{H}_{t}\\right)\\right]\\right]+\\mathbb{E}_{q\\left(\\mathbf{E}_{t} \\mid \\mathbf{E}\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{E}_{t}, \\mathbf{E}\\right) \\| p\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{E}_{t}\\right)\\right]\\right] \\\\\n& +\\mathbb{E}_{q\\left(\\mathbf{X}_{t} \\mid \\mathbf{X}\\right)}\\left[D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{X}_{t}, \\mathbf{X}\\right) \\| p\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{X}_{t}\\right)\\right]\\right.\n\\end{aligned}\n$$\n\nFor discrete data $\\mathbf{E}, D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{E}_{t}, \\mathbf{E}\\right) \\| p\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{E}_{t}\\right)\\right]$ measures the KL divergence between the true categorical distribution $q\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{E}_{t}, \\mathbf{E}\\right)$ and the predicted categorical distribution $p\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{E}_{t}\\right)$. For continuous data $\\mathbf{H}, \\mathbf{X}$ with Gaussian noise being added, [4, 15] show that $D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{H}_{t}, \\mathbf{H}\\right) \\| p\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{H}_{t}\\right)\\right], D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{X}_{t}, \\mathbf{X}\\right) \\| p\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{X}_{t}\\right)\\right]$ can be expressed as,\n\n$$\n\\begin{aligned}\n& D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{H}_{t}, \\mathbf{H}\\right) \\| p\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{H}_{t}\\right)\\right]=\\frac{1}{2} \\mathbb{E}_{\\mathbf{e}_{\\mathbf{H}}^{\\prime} \\sim N_{\\mathbf{H}}(\\mathbf{0}, \\mathbf{I})}\\left[\\omega(t) \\| \\epsilon_{\\mathbf{H}}^{t}-\\hat{\\epsilon}_{\\mathbf{H}}^{t} \\|^{2}\\right] \\\\\n& D_{\\mathrm{KL}}\\left[q\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{X}_{t}, \\mathbf{X}\\right) \\| p\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{X}_{t}\\right)\\right]=\\frac{1}{2} \\mathbb{E}_{\\mathbf{e}_{\\mathbf{X}}^{\\prime} \\sim N_{\\mathbf{X}}(\\mathbf{0}, \\mathbf{I})}\\left[\\omega(t) \\| \\epsilon_{\\mathbf{X}}^{t}-\\hat{\\epsilon}_{\\mathbf{X}}^{t} \\|^{2}\\right]\n\\end{aligned}\n$$\n\nwhere $\\omega(t)=(1-\\operatorname{SNR}(t-1) / \\operatorname{SNR}(t))$.\n\n# G Posterior Distribution of Edge Features $p\\left(\\widehat{\\mathbf{E}}_{t-1} \\mid \\widehat{\\mathbf{E}}_{t}\\right)$ \n\nFor simplicity, we use $\\mathbf{M}_{t}=\\left(\\mathbf{H}_{\\mathbf{t}}, \\mathbf{E}_{\\mathbf{t}}, \\mathbf{X}_{\\mathbf{t}}\\right)$ to denote the noisy molecule $\\widehat{\\mathbf{M}}_{t}=\\left(\\widehat{\\mathbf{H}}_{t}, \\widehat{\\mathbf{E}}_{t}, \\widehat{\\mathbf{X}}_{t}\\right)$ at time $t$. The posterior distribution of a molecule is calculated by,\n\n$$\n\\begin{aligned}\np\\left(\\mathbf{M}_{t-1} \\mid \\mathbf{M}_{t}\\right) & =p\\left(\\mathbf{H}_{t-1}, \\mathbf{E}_{t-1}, \\mathbf{X}_{t-1} \\mid \\mathbf{H}_{t}, \\mathbf{E}_{t}, \\mathbf{X}_{t}\\right) \\quad \\mathbf{H}, \\mathbf{E}, \\mathbf{X} \\text { are independent } \\\\\n& =p\\left(\\mathbf{H}_{t-1} \\mid \\mathbf{H}_{t}\\right) p\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{E}_{t}\\right) p\\left(\\mathbf{X}_{t-1} \\mid \\mathbf{X}_{t}\\right)\n\\end{aligned}\n$$\n\nPosterior distributions of atom features and coordinates are simple to compute as they are derived from normal distributions for continuous data (see Eq 1). Here, we compute the posterior distribution for edge features,\n\n$$\n\\begin{aligned}\np\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{E}_{t}\\right) & =\\prod_{(i, j) \\in \\mathbf{E}} p\\left(\\mathbf{e}_{t-1_{i j}} \\mid \\mathbf{e}_{t_{i j}}\\right) \\\\\np\\left(\\mathbf{e}_{t-1_{i j}} \\mid \\mathbf{e}_{t_{i j}}\\right) & =\\sum_{\\hat{\\mathbf{e}}_{i j} \\in \\hat{\\mathbf{E}}} p\\left(\\mathbf{e}_{t-1_{i j}} \\mid \\mathbf{e}_{t_{i j}}, \\hat{\\mathbf{e}}_{i j}\\right) p\\left(\\hat{\\mathbf{e}}_{i j} \\mid \\mathbf{e}_{t_{i j}}\\right) \\\\\n& =\\sum_{\\hat{\\mathbf{e}}_{i j} \\in \\hat{\\mathbf{E}}} p\\left(\\mathbf{e}_{t-1_{i j}} \\mid \\mathbf{e}_{t_{i j}}, \\hat{\\mathbf{e}}_{i j}\\right) p\\left(\\hat{\\mathbf{e}}_{i j}\\right)\n\\end{aligned}\n$$\n\nwhere we choose\n\n$$\np\\left(\\mathbf{e}_{t-1_{i j}} \\mid \\mathbf{e}_{t_{i j}}, \\hat{\\mathbf{e}}_{i j}\\right)= \\begin{cases}q\\left(\\mathbf{e}_{t-1_{i j}} \\mid \\mathbf{e}_{t_{i j}}, \\hat{\\mathbf{e}}_{i j}\\right), & \\text { if } q\\left(\\mathbf{e}_{t_{i j}} \\mid \\hat{\\mathbf{e}}_{i j}\\right)>0 \\\\ 0, & \\text { otherwise }\\end{cases}\n$$\n\nThe posterior distribution for discrete objects is given in Sec 2.1, as $q\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{E}_{t}, \\mathbf{E}\\right)$, but since the clean edge features $\\mathbf{E}$ are unknown during sampling, we substitute it with the network approximation $\\hat{\\mathbf{E}}$, resulting in the posterior distribution $q\\left(\\mathbf{E}_{t-1} \\mid \\mathbf{E}_{t}, \\hat{\\mathbf{E}}\\right)$."
    },
    {
      "markdown": "# H Zeroth Likelihood Estimation \n\nFor simplicity, we use $\\mathbf{M}_{t}=\\left(\\mathbf{H}_{\\mathbf{t}}, \\mathbf{E}_{\\mathbf{t}}, \\mathbf{X}_{\\mathbf{t}}\\right)$ to denote the noisy molecule $\\tilde{\\mathbf{M}}_{t}=\\left(\\tilde{\\mathbf{H}}_{t}, \\tilde{\\mathbf{E}}_{t}, \\tilde{\\mathbf{X}}_{t}\\right)$ at time $t$. The zeroth likelihood term for edge features is computed simply, which is just defined as the probabilities of the estimate of clean edge features computed from $\\mathbf{E}_{0}$.\nThe zeroth likelihood term for atom positions can be computed similarly to the way it is defined in Eq 1,\n\n$$\n\\begin{aligned}\n& p\\left(\\mathbf{X} \\mid \\mathbf{X}_{0}\\right)=\\mathcal{N}\\left(\\mathbf{X} \\mid \\frac{1}{\\alpha_{0}} \\mathbf{X}_{0}-\\frac{\\sigma_{0}}{\\alpha_{0}} \\boldsymbol{\\epsilon}_{\\mathbf{X}}^{0}, \\frac{\\sigma_{0}^{2}}{\\alpha_{0}^{2}} \\mathbf{I}\\right) \\\\\n& \\mathbf{X}=\\frac{1}{\\alpha_{0}} \\mathbf{X}_{0}-\\frac{\\sigma_{0}}{\\alpha_{0}} \\boldsymbol{\\epsilon}_{\\mathbf{X}}^{0}+\\frac{\\sigma_{0}}{\\alpha_{0}} \\boldsymbol{\\epsilon}_{\\mathbf{X}}\n\\end{aligned}\n$$\n\nand the reconstruction loglikelihood follows,\n\n$$\n\\log p\\left(\\mathbf{X} \\mid \\mathbf{X}_{0}\\right)=\\frac{1}{2} \\mathbb{E}_{\\boldsymbol{\\epsilon}_{\\mathbf{X}}^{0} \\sim N_{\\mathbf{X}}(\\mathbf{0}, \\mathbf{I})}\\left[\\omega(0)\\left\\|\\boldsymbol{\\epsilon}_{\\mathbf{X}}^{0}-\\boldsymbol{\\epsilon}_{\\mathbf{X}}^{0}\\right\\|^{2}\\right]\n$$\n\nwhere $\\omega(0)=-1$.\nThe zeroth likelihood term for atom features is not easy to compute as atom features can be continuous and categorical. We follow [4] to compute the zeroth likelihood term for atom features. For integer molecular properties, the likelihood follows\n\n$$\n\\begin{aligned}\np\\left(\\mathbf{H} \\mid \\mathbf{H}_{0}\\right) & =\\int_{\\mathbf{H}-\\frac{1}{2}}^{\\mathbf{H}+\\frac{1}{2}} \\mathcal{N}\\left(\\mathbf{h} \\mid \\mathbf{H}_{0}, \\sigma_{0}\\right) \\mathrm{d} \\mathbf{h} \\\\\n& =f_{\\mathrm{CDF}}\\left(\\frac{\\mathbf{H}+\\frac{1}{2}-\\mathbf{H}_{0}}{\\sigma_{0}}\\right)-f_{\\mathrm{CDF}}\\left(\\frac{\\mathbf{H}-\\frac{1}{2}-\\mathbf{H}_{0}}{\\sigma_{0}}\\right)\n\\end{aligned}\n$$\n\nwhere $f_{\\mathrm{CDF}}(\\cdot)$ denotes the cumulative distribution function of a standard normal distribution. For categorical features like atom types, a one-hot encoding is applied and the likelihood is calculated as,\n\n$$\np\\left(\\mathbf{H} \\mid \\mathbf{H}_{0}\\right)=\\mathcal{C}(\\mathbf{H} \\mid \\mathbf{p}), \\quad \\mathbf{p} \\propto \\int_{\\mathbf{1}-\\frac{1}{2}}^{\\mathbf{1}+\\frac{1}{2}} \\mathcal{N}\\left(\\mathbf{h} \\mid \\mathbf{H}_{0}, \\sigma_{0}\\right) \\mathrm{d} \\mathbf{h}\n$$\n\nwhere $\\mathbf{p}$ is normalized to one and $\\mathcal{C}$ is the categorical distribution, as suggested in [4].\n\n## I Node2Graph \\& Edge2Graph Functions\n\nNode2Graph $f_{\\text {Node2Graph }}(\\cdot)$ and Edge2Graph $f_{\\text {Edge2Graph }}(\\cdot)$ functions map node- and edge-level features to graph-level features, respectively.\nThe Node2Graph function transforms the node features $\\mathbf{H} \\in \\mathbb{R}^{n \\times F_{\\text {in }}}$ by computing the mean, max, and min values for each node, then concatenating them and applying a linear transformation with weight matrix $W_{\\text {Node2Graph }}$ and bias $b_{\\text {Node2Graph }}$,\n\n$$\n\\begin{aligned}\n& \\mathbf{H}_{\\text {mean }}=\\operatorname{mean}(\\mathbf{H}) \\in \\mathbb{R}^{1 \\times F_{\\text {in }}} \\\\\n& \\mathbf{H}_{\\max }=\\max (\\mathbf{H}) \\\\\n& \\mathbf{H}_{\\min }=\\min (\\mathbf{H}) \\\\\n& \\mathbf{H}_{\\text {out }}=W_{\\text {Node2Graph }}\\left(\\left[\\mathbf{H}_{\\text {mean }}, \\mathbf{H}_{\\max }, \\mathbf{H}_{\\min }\\right]\\right)+b_{\\text {Node2Graph }} \\in \\mathbb{R}^{1 \\times F_{\\text {out }}}\n\\end{aligned}\n$$\n\nThe Edge2Graph function transforms the node features $\\mathbf{E} \\in \\mathbb{R}^{n \\times n \\times F_{\\text {in }}}$ by computing the mean, max, and min values for each node pair $(i, j)$, then concatenating them and applying a linear transformation with weight matrix $W_{\\text {Edge2Graph }}$ and bias $b_{\\text {Edge2Graph }}$,\n\n$$\n\\begin{aligned}\n& \\mathbf{E}_{\\text {mean }}=\\operatorname{mean}(\\mathbf{E}) \\in \\mathbb{R}^{1 \\times 1 \\times F_{\\text {in }}} \\\\\n& \\mathbf{E}_{\\max }=\\max (\\mathbf{E}) \\\\\n& \\mathbf{E}_{\\min }=\\min (\\mathbf{E}) \\\\\n& \\mathbf{E}_{\\text {out }}=W_{\\text {Edge2Graph }}\\left(\\left[\\mathbf{E}_{\\text {mean }}, \\mathbf{E}_{\\max }, \\mathbf{E}_{\\min }\\right]\\right)+b_{\\text {Edge2Graph }} \\mathbb{R}^{1 \\times 1 \\times F_{\\text {out }}}\n\\end{aligned}\n$$"
    },
    {
      "markdown": "# J Molecule Generation \n\nDiscussion on Metrics. Following the methodology outlined in [2, 4], we evaluate the atom and molecule stability, as well as the validity and uniqueness of the generated samples by building a molecule with RdKit and attempting to obtain a valid SMILES string from it. However, as seen in Table 2 and Table 3, the statistics of the QM9 dataset are not perfect (not reaching 100\\%). This is due to the limitations of the method used by RDKit to process molecules, as explained in [4]. RDKit first builds a molecule that contains only heavy atoms, then adds hydrogens to each heavy atom in a way that matches the valency of each atom to its atom type. As a result, invalid molecules mostly appear when an atom has a valency bigger than expected. Additionally, as stated in [5], this method is not perfect as the QM9 dataset contains charged molecules that would be considered invalid by this method.\n\nRegarding novelty, [38] argue that the QM9 dataset is a comprehensive enumeration of small molecules that meet a set of specified constraints. Therefore, a novel molecule would not satisfy at least one of these constraints, indicating that the model does not accurately capture the correct data distribution. This makes evaluating and reporting novelty for molecules generated from the QM9 dataset difficult and potentially misleading.\n\nTraining Procedure. Our MUDiff model is trained using NVIDIA A100 GPUs. The model architecture consists of 6 layers, with 256 -dimensional embeddings for atom and edge-level features, and 64-dimensional embeddings for graph-level features. Additionally, we use 8 attention heads, 300 feedforward dimensions for atom and edge-level features, 100 feedforward dimensions for graph-level features, and 0.3 dropout rate for all latent embeddings and attention values. The activation function used is SiLU, the learning rate is set to $1 \\mathrm{e}-4$, and weight decay is set to $5 \\mathrm{e}-5$. The optimizer used is Adam. These hyperparameter settings are chosen to balance the trade-off between computational cost and model performance.\n\nFor the diffusion process, we use 1000 time steps and a cosine schedule for the diffusion coefficient over 10000 training epochs. This schedule is introduced in [44], where the coefficient is defined as $\\alpha_{t}=\\cos \\left(0.5 \\pi\\left(\\frac{t}{T}+s\\right) /(1+s)\\right)^{2}$, where $T$ is the total number of time steps and $s$ is a small value (e.g., $10^{-6}$ ). This schedule helps to ensure a smooth transition from an initial low diffusion coefficient at the start of the process to a high diffusion coefficient at the end. This schedule also helps avoid the problem of over-diffusion at the early stages of the process and under-diffusion at the later stages.\n\n## K Disscussion on Limitation \\& Future Work\n\n## K. 1 Scalability Issue\n\nProblem. Generating molecular structures using graph models presents a challenge in representing the structures in a way that can be processed by the model. One commonly used approach is to represent the structure as a dense adjacency tensor, where each element in the tensor corresponds to the presence or absence of a bond between two atoms. However, generating these dense tensors can be computationally expensive, particularly for larger or more complex molecular structures.\n\nApproach \\& Limitation. In our model, which includes a transformer and diffusion model, we generate 2D molecular structures and edge features by creating a dense adjacency tensor of size $n \\times n \\times b$, where n represents the number of atoms in a molecule and b represents the number of edge types. In the case of molecule scenarios, our model predicts a dense tensor of size $n \\times n \\times 4$, which includes four bond types (no-bond, single bond, double bond, and triple bond). One advantage of using dense tensors is that they can capture more detailed information about the molecular structure, including the precise location and type of each bond. This level of detail can be particularly crucial in cases where subtle differences in the structure can have a significant impact on the molecule's properties or behavior. However, a significant disadvantage of dense tensors is the computational cost required to generate and process them, which can limit the scalability and efficiency of the model.\n\nSparse Tensor Solution. Sparse tensors can be a useful approach to reducing the computational cost of generating molecular structures. Sparse tensors are similar to dense tensors, but they only store the non-zero elements of the tensor, rather than the entire tensor. To use sparse tensors for"
    },
    {
      "markdown": "the problem of generating molecular structures, one approach is to represent the adjacency matrix as a sparse tensor. Rather than creating a dense tensor of size $n \\times n \\times b$, we can instead create a sparse tensor that only stores the non-zero elements of the adjacency matrix. To make predictions for sparse tensors, we can use specialized algorithms designed for sparse tensors. One common approach is to use sparse matrix multiplication algorithms, which can efficiently perform matrix operations on sparse tensors. These algorithms are designed to take advantage of the sparsity of the tensor to perform the required computations more efficiently.\n\nMulti-resolution Representation Solution. Multi-resolution representation of molecules is an approach to represent molecular structures at multiple levels of detail, allowing for more efficient processing while still capturing important structural information. Essentially, the idea is to represent the molecule in different ways, with each representation capturing different levels of detail. One common approach is to use a hierarchical representation, where the molecular structure is represented as a series of nested substructures. For example, the molecule could be represented as a set of atoms, each associated with a set of neighboring atoms. This set of neighboring atoms could then be recursively expanded to include their own neighboring atoms, resulting in a hierarchical representation of the molecule that captures different levels of detail at different scales. Another approach is to use a multi-scale representation, where the molecular structure is represented at different levels of detail using different feature maps or descriptors. For example, the molecule could be represented as a set of atoms, each associated with a descriptor that captures its physical properties. By using multi-resolution representations, we can reduce the computational cost of generating molecular structures while still capturing important structural information."
    }
  ],
  "usage_info": {
    "pages_processed": 26,
    "doc_size_bytes": 1611088
  },
  "_metadata": {
    "model_version": "0.0.0",
    "llm_model": "mistral-ocr-2505",
    "query_data": {
      "pdf": "/Users/satyaortiz-gagne/CODE/paperext/data/cache/fulltext/a6d7eac52f31f7cfd3090de320afc8d7/fulltext.pdf"
    },
    "model_id": "parsepdf"
  }
}