{
  "pages": [
    {
      "markdown": "# The Machine Learning for Combinatorial Optimization Competition (ML4CO): Results and Insights \n\nCo-organizers<br>Maxime Gasse*, Simon Bowly, Quentin Cappart, Jonas Charfreitag, Laurent Charlin, Didier Ch√©telat, Antonia Chmiela, Justin Dumouchelle, Ambros Gleixner, Aleksandr M. Kazachkov, Elias Khalil, Pawel Lichocki, Andrea Lodi, Miles Lubin, Chris J. Maddison, Christopher Morris, Dimitri J. Papageorgiou, Augustin Parjadis, Sebastian Pokutta, Antoine Prouvost, Lara Scavuzzo, Giulia Zarpellon\n\nPrimal task winners\nLinxin Yang\nSha Lai\nAkang Wang\nXiaodong Luo\nXiang Zhou\nHaohan Huang\nShengcheng Shao\nYuanming Zhu\nDong Zhang\nTao Quan\nDual task winners\nZixuan Cao\nYang Xu\nZhewei Huang\nShuchang Zhou\nConfiguration task winners\nChen Binbin\nHe Minggui\nHao Hao\nZhang Zhiyu\nAn Zhiwu\nMao Kun\n\nYANGLINXIN@CUHK.EDU.CN\n221049039@LINK.CUHK.EDU.CN\nWANGAKANG@SRIBD.CN\nXIAODONGLUO@CUHK.EDU.CN\nZHOUXIANG60@HUAWEI.COM\nHUANGHAOHAN@HUAWEI.COM\nSHAOSHENGCHENG@HUAWEI.COM\nZHUYUANMING5@HUAWEI.COM\nZHANGDONG48@HUAWEI.COM\nQUANTAO@HUAWEI.COM\n\nCAOZIXUAN.PERCY@STU.PKU.EDU.CN\n1800010740@PKU.EDU.CN\nHUANGZHEWEI@MEGVII.COM\nZSC@MEGVII.COM\n\nCBB18@MAILS.TSINGHUA.EDU.CN HEMINGGUI@HUAWEI.COM\n52194506007@STU.ECNU.EDU.CN\nZHANGZHIYU6@HUAWEI.COM\nANZHIWU1@HUAWEI.COM\nMAOKUN@HUAWEI.COM\n\n[^0]\n[^0]:    * Primary contact (maxime.gasse@polymtl.ca)"
    },
    {
      "markdown": "# Abstract \n\n\n#### Abstract\n\nCombinatorial optimization is a well-established area in operations research and computer science. Until recently, its methods have focused on solving problem instances in isolation, ignoring that they often stem from related data distributions in practice. However, recent years have seen a surge of interest in using machine learning as a new approach for solving combinatorial problems, either directly as solvers or by enhancing exact solvers. Based on this context, the ML4CO aims at improving state-of-the-art combinatorial optimization solvers by replacing key heuristic components. The competition featured three challenging tasks: finding the best feasible solution, producing the tightest optimality certificate, and giving an appropriate solver configuration. Three realistic datasets were considered: balanced item placement, workload apportionment, and maritime inventory routing. This last dataset was kept anonymous for the contestants.\n\n\nKeywords: Combinatorial optimization, machine learning for combinatorial optimization\n\n## 1. Introduction\n\nThe Machine Learning for Combinatorial Optimization competition (ML4CO) aims at improving state-of-the-art combinatorial optimization solvers by replacing key heuristic components with machine learning models. The main scientific question is the following: \"Is machine learning a viable option for improving traditional combinatorial optimization solvers on specific problem distributions, when historical data is available?\"\n\nWhile most combinatorial optimization solvers are presented as general-purpose, one-size-fits-all algorithms, this competition focuses on the design of application-specific algorithms from historical data. This general problem captures a highly practical scenario relevant to many application areas, where a practitioner repeatedly solves problem instances from a specific distribution with similar patterns and characteristics. For example, managing a large-scale energy distribution network requires solving similar CO problems daily, with a fixed power grid structure while only the demand changes over time. This demand change is hard to capture by hand-engineered expert rules, and ML-enhanced approaches offer a possible solution to detect typical patterns in the demand history. Other examples include crew scheduling problems that have to be solved daily or weekly with minor variations or vehicle routing where the traffic conditions change over time, but the overall transportation network does not.\n\nThe competition features three challenges for machine learning. Each of them corresponds to a specific control task arising in the open-source solver SCIP (Gamrath et al., 2020) and is exposed through a unified OpenAI Gym-like API based on the Python library Ecole (Prouvost et al., 2020). The three challenges are as follows: (1) a primal task, consisting of producing the best feasible solution, (2) a dual task, consisting of producing the best branching decisions, and (3) a configuration task, consisting of finding the best parameters before calling the solver. For each challenge, participants were evaluated on three problem benchmarks originating from diverse application areas, each represented as a collection of mixed-integer linear program (MILP) instances."
    },
    {
      "markdown": "# 2. Datasets \n\nThe participants' solutions were evaluated on three problem benchmarks from diverse application areas for each challenge. Each participant submitted a decision-making code, i.e., an algorithmic solution or trained ML model, for each of the benchmarks, or a single code that works for all benchmarks. A problem benchmark consists of a collection of MILP instances in the standard MPS file format. Each benchmark was split into a training and a test set, originating from the same problem distribution. While the training instances were made public at the beginning of the competition for participants to train their models, the test instances were kept hidden for evaluation purposes and were only revealed at the end of the competition. The first two problem benchmarks were inspired by real-life applications of large-scale systems at Google, while the third benchmark was presented to the participants as an anonymous problem inspired by a real-world, large-scale industrial application. The dataset used are publicy available on Github. ${ }^{1}$\nBenchmark 1: Balanced Item Placement This problem involves spreading items, e.g., files or processes, across containers, e.g., disks or machines, utilizing them evenly. Items can have multiple copies, but at most, one copy can be placed in a single bin. The number of items that can be moved is constrained, modeling the real-life situation of a live system for which some placement already exists. Each problem instance is modeled as a MILP, using a multi-dimensional, multi-knapsack formulation. This dataset contains 10000 training instances (pre-split into 9900 train and 100 validation instances).\nBenchmark 2: Workload Apportionment This problem deals with apportioning workloads, e.g., data streams, across as few workers, e.g., servers, as possible. The apportionment is required to be robust to any worker's failure. Each instance problem is modeled as a MILP, using a bin-packing with an apportionment formulation. This dataset contains 10000 training instances (pre-split into 9900 train and 100 validation instances).\nBenchmark 3: Maritime Inventory Routing (Anonymous Problem) This problem plays an integral role in global bulk shipping. The instances corresponding to this benchmark are assembled from a public dataset (Papageorgiou et al., 2014), whose origin was kept secret to prevent cheating. Reverse-engineering for the purpose of recovering the test set was forbidden. The dataset contains 118 training instances (pre-split into 98 train and 20 validation instances).\n\n## 3. Evaluation Metrics\n\nEach of the three challenges is associated with a specific evaluation metric reflecting a different objective. We describe how each metric is computed over a single problem instance. The final goal of the participants is to optimize this metric in expectation over a hidden collection of test instances. Because the evaluation metrics are time-dependent, all evaluations were run on the same hardware setup, using an Intel Xeon processor with 2.4 GHz , 20GB of RAM, and an Nvidia Tesla V100-8G GPU with 8GB of GPU memory. A maximum time budget was given for each task to process each test instance ( 5,15 , and 15 minutes for the primal, dual, and configuration tasks, respectively), after which the environment was\n\n[^0]\n[^0]:    1. https://github.com/ds4dm/m14co-competition"
    },
    {
      "markdown": "terminated. By doing so, participants were asked to focus on making both good and fast decisions.\n\nIn general, a MILP instance is expressed as follows,\n\n$$\n\\begin{aligned}\n& \\underset{\\mathbf{x}}{\\arg \\min } \\mathbf{c}^{\\top} \\mathbf{x} \\\\\n& \\text { subject to } \\quad \\mathbf{A}^{\\top} \\mathbf{x} \\leq \\mathbf{b} \\\\\n& \\mathbf{x} \\in \\mathbb{Z}^{p} \\times \\mathbb{R}^{n-p},\n\\end{aligned}\n$$\n\nwhere $\\mathbf{c} \\in \\mathbb{R}^{n}$ denotes the coefficients of the linear objective, $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ and $\\mathbf{b} \\in \\mathbb{R}^{m}$, denote the coefficients and upper bounds of the linear constraints, respectively, while $n$ is the total number of variables, $p \\leq n$ is the number of integer-constrained variables, and $m$ is the number of linear constraints. We used the following three metrics for the evaluation. Primal Integral This metric measures the area under the curve of the solver's primal bound, i.e., its global upper bound, which corresponds to the value of the best feasible solution found so far. By providing better feasible solutions over time, the value of the primal bound decreases. With a time limit $T$, the primal integral is expressed as follows,\n\n$$\n\\int_{t=0}^{T} \\mathbf{c}^{\\top} \\mathbf{x}_{t}^{\\star} \\mathrm{d} t-T \\mathbf{c}^{\\top} \\mathbf{x}^{\\star}\n$$\n\nwhere $\\mathbf{x}_{t}^{\\star}$ is the best feasible solution found at time $t$, so that $\\mathbf{c}^{\\top} \\mathbf{x}_{t}^{\\star}$ is the primal bound at time $t$, and $T \\mathbf{c}^{\\top} \\mathbf{x}^{\\star}$ is an instance-specific constant that depends on the optimal solution $\\mathbf{x}^{\\star}$. The primal integral is to be minimized, and takes an optimal value of 0 . To compute this metric unambiguously, a trivial initial solution $x_{0}^{\\star}$ is always provided to the solver at the beginning of the solving process. Also, the constant term $\\mathbf{c}^{\\top} \\mathbf{x}^{\\star}$ can be safely ignored at training time when participants train their control policy. However, when we evaluated the participant submissions at test time, this constant term, or a proper substitute, was incorporated in the reported metric.\nDual Integral This metric measures the area over the curve of the solver's dual bound, i.e., its global lower bound, which usually corresponds to a solution of a valid relaxation of the MILP. By branching, the linear relaxation corresponding to the branch-and-bound tree's leaves gets tightened, and the dual bound increases over time. With a time limit $T$, the dual integral is expressed as follows,\n\n$$\nT \\mathbf{c}^{\\top} \\mathbf{x}^{\\star}-\\int_{t=0}^{T} \\mathbf{z}_{t}^{\\star} \\mathrm{d} t\n$$\n\nwhere $\\mathbf{z}_{t}^{\\star}$ is the best dual bound at time $t$, and $T \\mathbf{c}^{\\top} \\mathbf{x}^{\\star}$ is an instance-specific constant that depends on the optimal solution value $\\mathbf{c}^{\\top} \\mathbf{x}^{\\star}$. The dual integral is to be minimized, and takes an optimal value of 0 .\n\nIn the context of branching, this metric is unambiguous to compute, as the root node of the tree always provides an initial dual bound $\\mathbf{z}_{0}^{\\star}$ at the beginning of branching. The constant term $\\mathbf{c}^{\\top} \\mathbf{x}^{\\star}$ can be safely ignored for training, but it was incorporated in the evaluation metric.\nPrimal-Dual Gap Integral This metric measures the area between two curves, the solver's primal bound and dual bound. Hence, the metric benefits both from improvements obtained"
    },
    {
      "markdown": "from the primal side (finding good feasible solutions), and on the dual side (producing a tight optimality certificate). With a time limit $T$, the primal-dual gap integral is expressed as follows,\n\n$$\n\\int_{t=0}^{T} \\mathbf{c}^{\\top} \\mathbf{x}_{t}^{\\star}-\\mathbf{z}_{t}^{\\star} \\mathrm{d} t\n$$\n\nThe primal-dual gap integral is to be minimized, and takes an optimal value of 0 . In the context of algorithm configuration, an initial value is required for the two curves at time $t=0$. Therefore, an initial trivial solution $x_{0}^{\\star}$ and a valid initial dual bound $z_{0}^{\\star}$ are always provided to the solver for this task.\n\n# 4. Solving the Primal Task (Winning Solution by CUHKSZ_ATD) \n\nThe primal task deals with finding good primal solutions at the root node of the branch-and-bound tree (Khalil et al., 2017; Nazari et al., 2018; Li et al., 2018; Nair et al., 2020). To that end, the environment (SCIP solver) does not perform any branching but enters an infinite loop at the root node, which collects the solutions proposed by the agents, evaluates their feasibility and updates the overall best solution reached so far, thus lowering the current primal bound (upper bound). The metric of interest for this task is the primal integral, which considers the rate at which the primal bound decreases over time. To model a realistic scenario, each problem instance has been preprocessed by SCIP (problem reduction, cutting planes, etc.). Moreover, the root linear program (LP) relaxation was solved before the participants were asked to produce feasible solutions. To prevent SCIP from searching for primal solutions by itself, all primal heuristics were deactivated. Further, to compute this metric unambiguously, even when no solution has been found yet, an initial primal bound (trivial solution value) was provided for each instance, which is to be given to SCIP at the beginning of the solving process in the form of a user objective limit. Execution time was limited to five minutes. We exploit the problem structures and tackle item placement, workload apportionment, and anonymous problems by utilizing classic primal heuristics in a more judicious manner.\n\n### 4.1. Balanced Item Placement\n\nLet $I$ denote the set of items and $J$ denote the set of containers. Let a binary variable $x_{i j}$ be 1 if item $i$ is placed in container $j$ and 0 otherwise. Each item will be placed in exactly a single container, as shown by constraints (2). Let $K$ represent the set of dimensions. For dimension $k \\in K$ of container $j \\in J$, knapsack constraints (3) represent some physical considerations while (4) and (5) properly account for the placement unevenness, which is penalized in the objective (1)."
    },
    {
      "markdown": "$$\n\\begin{array}{ll}\n\\min _{x, y, z} & \\sum_{j \\in J} \\sum_{k \\in K} \\alpha_{k} y_{j k}+\\sum_{k \\in K} \\beta_{k} z_{k} \\\\\n\\text { s.t. } & \\sum_{j \\in J} x_{i j}=1 \\\\\n& \\forall i \\in I \\\\\n& \\sum_{i \\in I} a_{i k} x_{i j} \\leq b_{k} \\\\\n& \\forall j \\in J, \\forall k \\in K \\\\\n& \\sum_{i \\in I} d_{i k} x_{i j}+y_{j k} \\geq 1 \\\\\n& \\forall j \\in J, \\forall k \\in K \\\\\n& y_{j k} \\leq z_{k} \\\\\n& \\forall j \\in J, \\forall k \\in K \\\\\n& x_{i j} \\in\\{0,1\\} \\\\\n& \\forall i \\in I, \\forall j \\in J \\\\\n& y_{j k} \\geq 0\n\\end{array}\n$$\n\nWe analyze 10,000 item placement instances and find out that: (i) $|I|=105,|J|=10$; (ii) $a_{i k}, d_{i k}$ values of 5 items are big and placing any two of them in the same container would incur large penalty. Based on this empirical finding, we place the 5 big items into the first five containers respectively before applying any primal heuristics.\nMeta-heuristics We apply a greedy method in which items are first sorted based on their sizes and then assigned to containers. This will produce the very first feasible solution. After that, we select one or two items respectively from two containers and swap them if this leads to a better incumbent.\nMath-heuristics We consider a construction method and an improvement method, based on solving mathematical models. The construction method consists of two steps: (i) first assign items to the first five containers by solving an assignment model; (ii) then assign the remaining items to the last five containers by solving a sub-MIP. For solution improvement, we properly choose two out of the last five containers, and then solve a sub-MIP to reassign items within those two containers optimally.\n\n# 4.2. Workload Apportionment \n\nLet $M$ and $N$ denote the set of tasks and the set of machines, respectively. For task $i \\in M$, only a subset of machines, denoted by $N^{i} \\subseteq N$, are accessible. Let a binary variable $y_{j}$ be 1 if machine $j$ is used and 0 otherwise. Let $x_{i j}$ denote the amount of workload from task $i$ to machine $j$, as defined in constraints (9). Constraints (10) enforce the capacity requirement for each machine. The apportionment is required to be robust to any one machine's failure, as indicated by constraints (11).\n\n$$\n\\begin{array}{ll}\n\\min _{x, y} & \\sum_{j \\in N} y_{j} \\\\\n\\text { s.t. } & x_{i j} \\leq a_{i} y_{j} \\\\\n& \\sum_{i \\in M: j \\in N^{i}} x_{i j} \\leq b_{j} \\\\\n& \\sum_{j \\in N^{i} \\backslash\\left\\{j^{\\prime}\\right\\}} x_{i j} \\geq a_{i} \\\\\n& y_{j} \\in\\{0,1\\} \\\\\n& 0 \\leq x_{i j} \\leq b_{j}\n\\end{array} \\quad \\forall i \\in M, \\forall j \\in N^{i} \\quad \\forall j \\in N\n$$\n\n$$\n\\forall i \\in M, \\forall j^{\\prime} \\in N^{i}\n$$\n\n$$\n\\forall j \\in N\n$$\n\n$\\forall i \\in M, \\forall j \\in N^{i}$"
    },
    {
      "markdown": "Rounding up a solution to the linear programming relaxation of model (8) - (13) would produce a feasible solution to (8) - (13). To further exploit the possibility of rounding a fractional solution towards a new incumbent, we choose a rounding threshold parameter $\\eta$ in an adaptive manner and round up $y_{j}$ only if it exceeds $\\eta$. Specifically, we first select a target objective value based on the current primal and dual bounds and then determine $\\eta$ via quantile selection such that after rounding with $\\eta$ the objective matches the predetermined value. If the rounding step produces a new incumbent solution, we then update the primal bound; otherwise, we set the dual bound to the corresponding objective value. We iterate this process until the primal-dual gap falls below a predetermined value. In model (8) - (13), constraints (10) can be tightened as follows:\n\n$$\n\\sum_{i \\in M: j \\in N^{i}} x_{i j} \\leq b_{j} y_{j} \\quad \\forall j \\in N\n$$\n\nFurthermore, across 10,000 instances, we observe that $a_{i}<b_{j}$ for $i \\in M, j \\in N^{i}$. As a result, constraints (9) are dominated by (14) and thus eliminated from the model. Now we call (8), (11) - (14) as the \"tightened model\".\n\nIn our implementation, we first apply the rounding heuristic method to the root LP solution to the original model and then to the optimal LP solution to tightened model. We then use RINS (Danna et al., 2005) to further improve the incumbent. In particular, we define and solve a sub-MIP based on the tightened model, using its LP solution and the current incumbent as a guide to fix part of the binary variables.\n\n# 4.3. Anonymous Problem \n\nThough the concrete MILP formulation is not available, we discover some pattern from anonymous instances in the LP file format. In particular, one can define a planning horizon and associate with each discrete variable a time period. The details can be deduced from the constraint hypergraph (Rossi et al., 2006) in which every node represents a discrete variable and every edge joins a pair of variables if they occur together in a constraint. Let $H$ denote the planning horizon and $h \\in H$ denote a time period. We use a heuristic called the \"rolling-horizon\" method to generate our final high quality primal solution. It consists of the following steps: (i) ignore constraints involving discrete variables with their $h$ values greater than $\\widetilde{H}$; (ii) relax the integrality constraints on variables with their $h$ values greater than $\\bar{H}$; (iii) fix those discrete variables with their $h$ values less than $\\widetilde{H}$ at the optimal solution from a previous run; (iv) solve the sub-MIP;(v) increase $\\widetilde{H}, \\bar{H}$ and $\\widetilde{H}$ adaptively and then iterate steps (i) - (iv) until $\\widetilde{H}=H$. Before calling the computationally expensive rolling-horizon method, we utilize feasibility pump (Fischetti et al., 2005; Bertacco et al., 2007) to generate the very first solutions and call RENS (Berthold, 2014) once to improve that solution. The RENS model is a sub-MIP defined by fixing those discrete variables with their $h$ values less than $0.9 H$ at the incumbent.\n\n## 5. Solving the Dual Task (Winning Solution by Nuri)\n\nThe dual task deals with obtaining tight optimality guarantees (dual bounds) with branching (Khalil et al., 2016; Balcan et al., 2018; Gasse et al., 2019; Gupta et al., 2020; Cappart et al., 2021). Making good branching decisions is regarded as a critical component of modern branch-and-bound solvers. However, it has received little theoretical understanding to this"
    },
    {
      "markdown": "day (Lodi and Zarpellon, 2017). In this task, the environment runs a full-fledged branch-and-cut algorithm with SCIP, and the participants only control the branching decisions of the solver. The metric of interest is the dual integral, which considers the rate at which which the dual bound increases over time. Fruther, all primal heuristics are deactivated to focus only on proving optimality using branching. Execution time was limited to 15 minutes.\n\nWe propose Knowledge Inheriting Dataset Aggregation (KIDA), which trains a neural model to decide branching variables with an enhanced version of Dataset Aggregation and a surprisingly effective Model Weight Averaging (MWA) trick. KIDA consists of three steps. First, candidate models are trained by combining the ideas of DAgger (Ross et al., 2011) and Born-Again Neural Networks (Furlanello et al., 2018) to imitate the Strong Branching (Achterberg et al., 2005) heuristics on an expanded dataset. Then, we apply the MWA trick to derive more candidate models. Finally, the model with the highest cumulated reward on the validation set is selected as the final model to be used for testing in the deployment environment. We demonstrate that KIDA achieves top performance on the benchmarks of Balanced Item Placement and Anonymous Problem with a single model, surpassing methods that purely imitate Strong Branching heuristics.\nLimitations of Imitating Strong Branching Classical approaches (Gasse et al., 2019; Nair et al., 2020) to train neural models to decide branching variables rely on imitation of Strong Branching heuristics. However, on the two benchmarks of Balanced Item Placement and Anonymous Problem, we find that having good performance measured by the accuracy of imitating Strong Branching (SBA) does not always lead to good performance on the deployment environment measured as cumulated reward (CR), as shown in Table 1. On the other hand, though CR is a reliable evaluation metric that is highly consistent between validation and deployment, as shown in Table 1, it is a sparse signal and cannot be used directly in an Imitation Learning framework. In light of these, we propose to first train models to imitate Strong Branch heuristics, and then use a greedy search to select the final model from trained models and their derived weight averaging models. We also note on the benchmark of Workload Apportionment, SBA almost completely fails to correlate with the deployment-time CR as models with high SBA are often inferior to simple random strategy, as shown in Table 2.\n\nTable 1: Performance Comparison of Models of Different Epochs on the benchmark of Balanced Item Placement. SBA is not strictly related to CR\n\n| Epoch | Top 1 SBA | Top 3 SBA | Cum. Reward on <br> Validation Set | Cum. Reward on <br> Test Set |\n| :--: | :--: | :--: | :--: | :--: |\n| 1 | 0.780 | 0.932 | 5202.6 | 5028.6 |\n| 5 | 0.803 | $\\mathbf{0 . 9 4 8}$ | $\\mathbf{5 5 4 5 . 7}$ | $\\mathbf{5 2 8 9 . 3}$ |\n| 10 | 0.808 | 0.946 | 5131.9 | 4807.9 |\n| 20 | $\\mathbf{0 . 8 1 0}$ | 0.947 | 5038.8 | 4840.7 |\n\nEnhanced Dataset Aggregation We find that Dataset Aggregation (DAgger) (Ross et al., 2011) improves SBA of trained models and helps to get better final performance in the deployment environment. We are also inspired by Born-Again Neural Networks (Furlanello et al., 2018) to utilize all trained models from the whole training process. The training of the cur-"
    },
    {
      "markdown": "rent model depends on the data generated with the last model. By the end of this step, we have a collection of candidate models that can be leveraged in the next step.\nModel Weight Averaging and Greedy Search In the setting of Dual Task, Model Ensembles (Dietterich, 2000; Kidzi≈Ñski et al., 2018), which simply averages outputs of multiple models, doesn't work because the increase in run time by using multiple models will lead to fewer rounds of interaction with the underlying SCIP solver, and consequently degrading performance. In our experiments, averaging the weights of models trained in different epochs (Tarvainen and Valpola, 2017) doesn't have any positive effect either. In contrast, we consider building a new model $\\pi_{\\text {avg }}$ by averaging the weights of different trained models during the DAgger process. Formally, for $\\Omega$ models obtained from DAgger with parameters $\\left(\\theta_{0}, \\theta_{1}, \\ldots, \\theta_{\\Omega-1}\\right)$, the parameters of $\\pi_{\\text {avg }}$ are obtained by: $\\theta_{\\text {avg }}=\\sum_{i=0}^{\\Omega-1} \\theta_{i} / \\Omega$. In practice, we perform a greedy grid search over different model combinations and different $\\Omega$ to select the best averaged model with the highest CR. Note original models are also included in the search as the particular case of $\\Omega=1$.\n\n# Results \n\nThe final performance of our methods on benchmarks is shown in Table 2. Baseline results are strictly from the official code. For KIDA, we select the best-performing model by greedy search over $\\Omega=1,2, \\ldots, 5$.\n\nTable 2: The Cumulated Reward in Three Benchmarks of Different Methods\n\n|  | Random | Baseline | KIDA |\n| :-- | :--: | :--: | :--: |\n| Balanced Item Placement | 3300.7 | 4937.8 | $\\mathbf{7 5 6 1 . 6}(\\boldsymbol{\\Omega}=\\mathbf{3})$ |\n| Workload Apportionment | $\\mathbf{6 2 4 9 2 8 . 9}$ | 624043.6 | 623996.0 |\n| Anonymous Problem | 31145708.4 | 30965931.6 | $\\mathbf{3 2 8 3 2 6 1 8 . 7}(\\boldsymbol{\\Omega}=\\mathbf{1})$ |\n\nBalanced Item Placement: a KIDA model with $\\Omega=3$ overtakes the other methods with a significant margin.\nWorkload Apportionment: surprisingly, the random strategy is significantly better than the baseline model in this benchmark. This may be attributed to the failure of Strong Branching heuristics for this set.\nAnonymous Problem: the best KIDA model we find is a single DAgger model without averaging. Applying KIDA with $\\Omega \\geq 2$ leads to a slight decline in deployment-time CR.\n\n## 6. Solving the Configuration Task (Winning Solution by EI-OROAS)\n\nThe configuration task deals with deciding on a good parameterization of the solver for a given problem instance (Hutter et al., 2011). The environment required for this task is more straightforward than for the two previous ones since it involves only a single decision for the agents, i.e., contextual bandit problem). Participants were allowed to tune any of the existing parameters of SCIP. They could choose between providing a fixed set of parameters that work well on average for each problem benchmark or producing instancespecific parameterizations based on the characteristics of each instance. The metric of interest for this task was the primal-dual gap integral, which combines both improvements from the dual and from the primal side over time. To compute this metric unambiguously, even when no primal or dual bound exists, an initial primal bound (trivial solution value)"
    },
    {
      "markdown": "and an initial dual bound (pre-computed root LP solution value) for each instance are both provided. Execution time was limited to 15 minutes.\n\nThe configuration task deals with deciding on a good parameterization of the solver for a given problem instance. Specifically, there are two questions need to answer: 1. How to search good parameters for seen instances? 2. How to recommend parameters for unseen instances? With a basic exploration, we conclude the following challenges: 1) Numerous, heterogeneous and conditional dependent configurable parameters 2) Expensive optimization cost for open instances and Limited samples for anonymous set. In our solution, we proposed a novel space reduction pipeline and adopted HEBO (Cowen-Rivers et al., 2020) as optimizer to search good parameter, while a ML-based classifier to recommend parameters.\nImplementation of method First, the search space is reduced to accommodate Bayesian optimization. Expert experiences were introduced to filter insignificant parameters. Then, fitting a XGboost observer to tighten the region of candidate parameters again with Gini coefficients. The search space $\\Omega$ will be split to $k$ sub-space (om)at the start, then optimized one by one with broad first search order. Algorithm 1 presents the pseudo-code for search. Specifically, a two-layer loop is used to solve the problem. The outer loop optimizes each sub-space, and the inner loop is a standard BO method that minimizes the objective function. Some comments are all as follows. 1) Full solution initialization: The $x^{*}$ is assigned the SCIP default value for initialization and replaced by optimal partial solution $x^{i}(i=1, \\cdots, k)$ until the end of the iterations. 2) Partial solution initialization: The sub-space $\\Omega_{i}$ is defined as the current search space, and the initial dataset $\\mathcal{D}_{0}^{i}$ is sampled in this space. 3) Model construction and optimization: The surrogate model construction and acquisition function optimization is following the HEBO. 4) Objective evaluation: The new suggested solutions $x_{1: q}^{i}$ will supplemented by $x^{*}$ into full solutions, configuring for SCIP, and solving for all instances in $\\mathcal{I}$. the mean value of the Primal-dual gap integral for all instances is returned as an objective value. 5) Update full solution: When the inner loop ends, the optimal solutions $x_{i}$ will update the global full optimal solution $x^{*}$.\n\nTable 3: The statistical results of primal-dual gap by default and tuned parameters of SCIP.\n\n| Dataset | Default <br> Performance | Tuned <br> Performance | Improvement |\n| :-- | :--: | :--: | :--: |\n| Item Placement | 16942 | $\\mathbf{8 7 8 1}$ | $\\times 1.92$ |\n| Load Balancing | 22168 | $\\mathbf{9 4 9 9}$ | $\\times 2.33$ |\n| Anonymous-c1 | $277 \\mathrm{e}+4$ | $\\mathbf{2 5 7 e + 4}$ | $\\times 1.08$ |\n| Anonymous-c2 | $1133 \\mathrm{e}+6$ | $\\mathbf{7 3 0 e + 6}$ | $\\times 1.55$ |\n| Anonymous-c3 | $726 \\mathrm{e}+4$ | $\\mathbf{5 7 4 e + 4}$ | $\\times 1.26$ |\n\nEmpirical study We solve the problem as described above, where the anonymous dataset is divided into three clusters according to the features. The statistical results of SCIP solver with default and tuned parameters are summarize in Table 3. The performance of the SCIP has been improved, with a maximum of 2.33 times improvement on Load Balancing dataset and minimum of 1.08 times on Anonymous-c1. The experimental results demonstrate the effectiveness and robustness of our method in the MIP solver configuration."
    },
    {
      "markdown": "# MLACO COMPETition \n\n```\nAlgorithm 1: Pseudocode of Parameter Adaptive Bayesian Optimization\nInput : \\(\\Omega=\\left\\{\\Omega_{1}, \\Omega_{2}, \\cdots, \\Omega_{k}\\right\\}:\\) Search space; \\(\\mathcal{I}:\\) Instances set; \\(N\\) : Total number of iterations of each\n        sub-search space\n\\(x^{*} \\leftarrow \\operatorname{SCIP}\\) default value in \\(\\Omega . \\quad / *\\) full solution initialization */\nfor \\(i \\leftarrow 1\\) to \\(k\\) do\n    Initialize \\(\\mathcal{D}_{i j}^{i}\\) by random sample from sub-search space \\(\\Omega_{i} . \\quad / *\\) partial solution initialization */\n    for \\(j \\leftarrow 0\\) to \\(N-1\\) do\n        Fit a surrogate model to current dataset \\(\\mathcal{D}_{j^{\\prime}}^{i} \\quad / *\\) modeling */\n        Find \\(q\\) solutions \\(x_{1: q}^{i}\\) by maximizing three acquisition functions. /* suggest */\n        Evaluate new partial solutions \\(\\left(x_{1: q}^{i}\\right)\\) by querying the function to get \\(y_{1: q}=f\\left(x_{1: q}^{i}, x^{*}, \\mathcal{I}\\right)\\).\n        /* evaluate */\n        Update the dataset creating \\(\\mathcal{D}_{j+1}^{i}=\\mathcal{D}_{j}^{i} \\cup\\left\\{x_{l}^{i}, y_{l}\\right\\}_{l=1}^{q} \\quad\\) /* tell */\n    end\n    \\(x^{*} \\leftarrow x^{*} \\cup \\operatorname{argmin}_{x^{i} \\in \\mathcal{D}^{i}} \\quad / *\\) update full optimum solution */\nend\nOutput: \\(x^{*}\\) (the best-performing parameters set for SCIP solver on \\(\\mathcal{I}\\) ).\n```\n\n\n## 7. Conclusion\n\nThe goal of this competition was to foster the design of innovative methods to improve state-of-the-art combinatorial optimization solvers by replacing key heuristic components with machine learning models. To that, we proposed three challenging benchmarks. In total, we received 12 for the primal task 12,23 for the dual task, and 15 for the configuration task. We provide descriptions of some of the participants' solutions on the competition website. ${ }^{2}$ The results indicate that machine learning for combinatorial optimization has potential, although more work must be done before it becomes relevant for practical, realworld use. We plan to maintain this competition across the years to monitor performance improvements over the years.\n\n## Acknowledgments\n\nThe event was sponsored by the Artificial Intelligence Journal, as well as Compute Canada, Calcul Qu√©bec, and Westgrid who graciously provided the compute resources and the prize money. We finally thank all the participants.\n\n## References\n\nTobias Achterberg, Thorsten Koch, and Alexander Martin. Branching rules revisited. Operations Research Letters, 33(1):42-54, 2005.\n\nMaria-Florina Balcan, Travis Dick, Tuomas Sandholm, and Ellen Vitercik. Learning to branch. In International Conference on Machine Learning, pages 344-353. PMLR, 2018.\n\nLivio Bertacco, Matteo Fischetti, and Andrea Lodi. A feasibility pump heuristic for general mixed-integer problems. Discrete Optimization, 4(1):63-76, 2007.\n\nTimo Berthold. Rens. Mathematical Programming Computation, 6(1):33-54, 2014.\n2. https://www.ecole.ai/2021/m14co-competition/"
    },
    {
      "markdown": "Quentin Cappart, Thierry Moisan, Louis-Martin Rousseau, Isabeau Pr√©mont-Schwarz, and Andre A Cire. Combining reinforcement learning and constraint programming for combinatorial optimization. In AAAI Conference on Artificial Intelligence, volume 35, pages $3677-3687,2021$.\n\nAlexander I Cowen-Rivers, Wenlong Lyu, Rasul Tutunov, Zhi Wang, Antoine Grosnit, Ryan Rhys Griffiths, Hao Jianye, Jun Wang, and Haitham Bou Ammar. An empirical study of assumptions in bayesian optimisation. arXiv preprint arXiv:2012.03826, 2020.\n\nEmilie Danna, Edward Rothberg, and Claude Le Pape. Exploring relaxation induced neighborhoods to improve mip solutions. Mathematical Programming, 102(1):71-90, 2005.\n\nThomas G Dietterich. Ensemble methods in machine learning. In International workshop on multiple classifier systems, pages 1-15. Springer, 2000.\n\nMatteo Fischetti, Fred Glover, and Andrea Lodi. The feasibility pump. Mathematical Programming, 104(1):91-104, 2005.\n\nTommaso Furlanello, Zachary Lipton, Michael Tschannen, Laurent Itti, and Anima Anandkumar. Born again neural networks. In International Conference on Machine Learning, pages 1607-1616. PMLR, 2018.\n\nGerald Gamrath, Daniel Anderson, Ksenia Bestuzheva, Wei-Kun Chen, Leon Eifler, Maxime Gasse, Patrick Gemander, Ambros Gleixner, Leona Gottwald, Katrin Halbig, Gregor Hendel, Christopher Hojny, Thorsten Koch, Pierre Le Bodic, Stephen J. Maher, Frederic Matter, Matthias Miltenberger, Erik M√ºhmer, Benjamin M√ºller, Marc E. Pfetsch, Franziska Schl√∂sser, Felipe Serrano, Yuji Shinano, Christine Tawfik, Stefan Vigerske, Fabian Wegscheider, Dieter Weninger, and Jakob Witzig. The SCIP Optimization Suite 7.0. Technical report, Optimization Online, March 2020. URL http://www. optimization-online.org/DB_HTML/2020/03/7705.html.\n\nMaxime Gasse, Didier Ch√©telat, Nicola Ferroni, Laurent Charlin, and Andrea Lodi. Exact combinatorial optimization with graph convolutional neural networks. In Advances in Neural Information Processing Systems, 2019.\n\nPrateek Gupta, Maxime Gasse, Elias Khalil, Pawan Mudigonda, Andrea Lodi, and Yoshua Bengio. Hybrid models for learning to branch. 2020.\n\nFrank Hutter, Holger H Hoos, and Kevin Leyton-Brown. Sequential model-based optimization for general algorithm configuration. In International Conference on Learning and Intelligent Optimization, pages 507-523. Springer, 2011.\n\nElias Khalil, Pierre Le Bodic, Le Song, George Nemhauser, and Bistra Dilkina. Learning to branch in mixed integer programming. In AAAI Conference on Artificial Intelligence, volume 30, 2016.\n\nElias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and Le Song. Learning combinatorial optimization algorithms over graphs. In Advances in Neural Information Processing Systems, pages 6348-6358, 2017."
    },
    {
      "markdown": "≈Åukasz Kidzi≈Ñski, Sharada Prasanna Mohanty, Carmichael F Ong, Zhewei Huang, Shuchang Zhou, Anton Pechenko, Adam Stelmaszczyk, Piotr Jarosik, Mikhail Pavlov, Sergey Kolesnikov, et al. Learning to run challenge solutions: Adapting reinforcement learning methods for neuromusculoskeletal environments. In The NIPS'17 Competition: Building Intelligent Systems, pages 121-153. Springer, 2018.\n\nZhuwen Li, Qifeng Chen, and Vladlen Koltun. Combinatorial optimization with graph convolutional networks and guided tree search. In Advances in Neural Information Processing Systems, pages 537-546, 2018.\n\nAndrea Lodi and Giulia Zarpellon. On learning and branching: a survey. Top, 25(2): 207-236, 2017.\n\nVinod Nair, Sergey Bartunov, Felix Gimeno, Ingrid von Glehn, Pawel Lichocki, Ivan Lobov, Brendan O'Donoghue, Nicolas Sonnerat, Christian Tjandraatmadja, Pengming Wang, et al. Solving mixed integer programs using neural networks. arXiv preprint arXiv:2012.13349, 2020.\n\nMohammadreza Nazari, Afshin Oroojlooy, Martin Tak√°ƒç, and Lawrence V Snyder. Reinforcement learning for solving the vehicle routing problem. In Advances in Neural Information Processing Systems, pages 9861-9871, 2018.\n\nDimitri J Papageorgiou, George L Nemhauser, Joel Sokol, Myun-Seok Cheon, and Ahmet B Keha. Mirplib-a library of maritime inventory routing problem instances: Survey, core model, and benchmark results. European Journal of Operational Research, 235(2):350366, 2014.\n\nAntoine Prouvost, Justin Dumouchelle, Lara Scavuzzo, Maxime Gasse, Didier Ch√©telat, and Andrea Lodi. Ecole: A gym-like library for machine learning in combinatorial optimization solvers. arXiv preprint arXiv:2011.06069, 2020.\n\nSt√©phane Ross, Geoffrey Gordon, and Drew Bagnell. A reduction of imitation learning and structured prediction to no-regret online learning. In Proceedings of the fourteenth international conference on artificial intelligence and statistics, pages 627-635. JMLR Workshop and Conference Proceedings, 2011.\n\nFrancesca Rossi, Peter Van Beek, and Toby Walsh. Handbook of constraint programming. Elsevier, 2006.\n\nAntti Tarvainen and Harri Valpola. Mean teachers are better role models: Weightaveraged consistency targets improve semi-supervised deep learning results. arXiv preprint arXiv:1703.01780, 2017."
    }
  ],
  "usage_info": {
    "pages_processed": 13,
    "doc_size_bytes": 209045
  },
  "_metadata": {
    "model_version": "0.0.0",
    "llm_model": "mistral-ocr-2505",
    "query_data": {
      "pdf": "/Users/satyaortiz-gagne/CODE/paperext/data/cache/fulltext/deb4b39f4db1bfe145948f1503771c27/fulltext.pdf"
    },
    "model_id": "parsepdf"
  }
}