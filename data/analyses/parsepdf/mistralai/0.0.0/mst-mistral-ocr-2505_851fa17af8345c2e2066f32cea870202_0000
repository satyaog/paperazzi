{
  "pages": [
    {
      "markdown": "# Current State and Future Directions for Learning in Biological Recurrent Neural Networks: A Perspective Piece \n\nLuke Y. Prince ${ }^{1,2, *, \\dagger, \\ddagger}$ | Roy Henha Eyono ${ }^{1,2, \\ddagger}$ | Ellen<br>Boven $^{3, \\ddagger}$ | Arna Ghosh ${ }^{1,2, \\ddagger}$ | Joe Pemberton ${ }^{3, \\ddagger}$ |<br>Franz Scherr ${ }^{4, \\dagger}$ | Claudia Clopath ${ }^{5}$ | Rui Ponte Costa ${ }^{3, \\ddagger}$<br>| Wolfgang Maass ${ }^{4, \\S}$ | Blake A. Richards ${ }^{1,2,6, \\S}$ |<br>Cristina Savin ${ }^{7, \\S}$ | Katharina Anna Wilmes ${ }^{8, \\S}$\n\n[^0]We provide a brief review of the common assumptions about biological learning with findings from experimental neuroscience and contrast them with the efficiency of gradientbased learning in recurrent neural networks. The key issues discussed in this review include: synaptic plasticity, neural circuits, theory-experiment divide, and objective functions. We conclude with recommendations for both theoretical and experimental neuroscientists when designing new studies that could help bring clarity to these issues. ${ }^{a}$\n\nKEYWORDS\nrecurrent neural networks, backpropagation through time,\n\n[^1]\n[^0]:    ${ }^{1}$ School of Computer Science, McGill University, Montreal, Canada\n    ${ }^{2}$ Mila, Montreal, Canada\n    ${ }^{3}$ Bristol Computational Neuroscience Unit, University of Bristol, United Kingdom\n    ${ }^{4}$ Institute of Theoretical Computer Science, Graz University of Technology, Graz, Austria\n    ${ }^{5}$ Bioengineering Department, Imperial College London, London, United Kingdom\n    ${ }^{6}$ Department of Neurology and Neurosurgery, Montreal Neurological Institute, McGill University, Montreal, Canada\n    ${ }^{7}$ Center for Neural Science, New York University, New York, USA\n\n    Correspondence\n    Roy Henha Eyono\n    Email: roy.eyono@mila.quebec\n\n[^1]:    \"Equally contributing authors.\n    ${ }^{\\dagger}$ moderator\n    ${ }^{\\ddagger}$ co-organizer\n    ${ }^{\\S}$ panellist"
    },
    {
      "markdown": "# synaptic plasticity \n\n## 1 | INTRODUCTION\n\nBiological agents excel at learning tasks involving long-term temporal dependencies. One of the key challenges in learning such tasks is the problem of temporal credit assignment: reliably assigning importance to past neural states for error observed in present time. The tasks that animals have to solve on a daily basis depend on learning both short-term and long-term associations. Understanding how temporal credit assignment is implemented in biological recurrent neural networks (RNN) is important for understanding the brain [1].\n\nThe nervous systems of mammals, birds, and even many invertebrates are populated with recurrent networks, in which action potentials sent by neurons can often be returned via one or two hops to other local neurons. On a larger scale, whole brain regions form loops in long-range communication. These loops in communication present a challenge to learning, as credit assignment mechanisms must determine both when and where in the network a change must be made to improve future performance. In artificial RNNs, the credit assignment problem can be solved using backpropagation-through-time (BPTT) and an optimal choice of architecture [2]. However, the suite of operations and memory available to biological neurons are not considered sufficient to implement backpropagation-through-time. BPTT requires artificial neurons to constantly track the synaptic activity of neurons that they are not connected to, which is biologically problematic as it assumes perfect sequence recall [1]. Nevertheless, biological neural networks have a plethora of mechanisms for transmitting information amongst neurons across multiple spatiotemporal scales. Identifying these mechanisms, or alternatively, showing that biological networks have ways of sidestepping the temporal credit assignment problem, is one of the key challenges for neuroscientists over the next decade.\n\nAdditionally, animals possess an aptitude for learning throughout their lifetimes in which they can maintain a strong generalized ability over a diverse range of tasks. However, modern artificial recurrent neural networks lose their generalized ability partly due to catastrophic forgetting [3]. Hence one of the reasons why they struggle to match their biological counterparts and are typically specialized over a narrow task domain. As a result, the network's performance on previously learned tasks is diluted.\n\nIn this position piece, we present the perspectives of several experts in theoretical neuroscience to reconcile the gap between biological and artificial learning in recurrent neural networks. This will not be an exhaustive review of the literature on synaptic plasticity, temporal credit assignment, recurrent neural circuits, or continual learning, however we will guide the reader on reviews of these topics. This piece will be organised in four sections that broadly summarise the main points of discussion in the workshop:\n\n1. Bio-plausible approaches for solving temporal credit assignment using synaptic plasticity\n2. The role of neural circuits and architecture in temporal credit assignment\n3. The nature of objective functions in the recurrent circuits of the brain\n4. What can experiments tell us: the limitations in comparing computational models to experimental evidence\n\nAt the beginning of each section, we will outline, in broad terms, what our panellists had agreed upon, followed by where their opinions diverged. We will end this piece with practical recommendations for theoretical and experimental research on how we can collectively help to resolve these issues over the coming years."
    },
    {
      "markdown": "# 2 BIO-PLAUSIBLE APPROACHES FOR SOLVING TEMPORAL CREDIT ASSIGNMENT \n\nOur panellists were in agreement that temporal credit assignment must in some way be reliant on synaptic plasticity at recurrent synapses (see Citri and Malenka [4] and Magee and Grienberger [5] for reviews on synaptic plasticity). Furthermore there was a general consensus that recurrent plasticity is as important during early development (e.g., when learning to walk) as it is in adulthood (e.g., when learning to be a better dancer).\n\nExperimentally, we observe that synaptic strengths are highly plastic [6]. In early development the conditions for changing a synapse are far less strict than in adulthood. As an animal grows older, synaptic plasticity becomes more gated and dependent on the presence of additional factors such as neuromodulators (see Pawlak et al. [7] for review on neuromodulators) or the release of inhibition. Furthermore, synapses in sensory areas tend to be less plastic than in higher-order areas [8, 9], although plasticity at sensory recurrent synapses can still be observed under the right conditions $[10,8,9,11]$.\n\nTo date there have been few successful attempts at implementing a biologically-plausible temporal credit assignment mechanism that can solve non-trivial tasks, at the efficiency of backpropagation-through-time in deep recurrent networks. The most successful approaches approximate gradients using a combination of neuromodulators and local estimates of the interactions that neurons have on each other over time [12, 13]. Nevertheless, there is still a gap when it comes to their efficacy as a general-purpose replacement for back-propagation-through-time [14]. It is still unknown whether their efficacy is restricted to particular problem domains. It is plausible that different brain regions leverage different strategies for learning the temporal structure of sensory data and that the specific solutions offered by these algorithms are restricted to particular tasks for particular brain regions, in particular species. The algorithms discussed here do not, by any means, incorporate every possible method to spread local and non-local information about network activity across time (e.g., dendritic spikes [15], disinhibition [16], acetylcholine [17], synaptic cooperativity [18], extrasynaptic transmission [19], presynaptic inhibition [20]). As such the range of possible solutions to temporal credit assignment in biological RNNs remains vastly underexplored.\n\nAdditionally, the reason for the success of biological recurrent networks in lifelong learning remains a mystery. There are a few solutions to this problem that have been proposed in artificial neural networks (e.g. elastic weight consolidation [21], hypernetworks [22] and intelligent synapses [23]). A commonality amongst some of these approaches is in increasing the complexity of the synapse models beyond scalar $w_{i j}$ terms [24]. Indeed, synapses are themselves highly nonlinear and have multiple gating and memory mechanisms that could allow for rapid storage, recall, and preservation of parameter sets important for a particular task, but that does not contribute to or suffer from interference with other task solutions [25].\n\nOverall, the panellists acknowledge that current computational models of temporal credit assignment falls short on the capabilities of recurrent synapses in neural circuitry. It is however unclear if understanding the bio-complexity requires to reexamine the traditional set of synaptic learning rules (i.e. Hebbian plasticity) or rather to be more inclusive on what constitutes bio-plausibility when considering the current computational building blocks."
    },
    {
      "markdown": "# 3 | THE ROLE OF NEURAL CIRCUITS AND ARCHITECTURE IN TEMPORAL CREDIT ASSIGNMENT: ARE WE FOCUSING TOO MUCH ON SYNAPTIC PLASTICITY? \n\nIt's well established that some connectivity motifs and microcircuits are conserved across species and individuals (e.g., neocortical columns, the hippocampal-entorhinal formation, cortico-cerebellar loops, and striatal networks). Furthermore, a certain degree of functional specialization consistently emerges across brain regions in terms of hierarchies within visual, somatosensory, motor, or auditory cortices. This degree of conservation indicates that much of the information required to generate these architectures are stored genetically, as a consequence of animal evolution. While panellists agreed that it is likely too extreme to say (in mammals at least) that learning relies on pre-wired recurrent circuits (as in echo state networks or liquid state machines [26]), there are clearly constraints imposed by the genetic code that may offer useful inductive biases for self-organization and learning.\n\nDo these conserved microcircuit architectures support efficient temporal credit assignment, or potentially offer a strong inductive bias that need not be updated based on experience? Recent studies have shown that synaptic weight changes are selective and respect the prior architectural traits. One study mapped the key features of the cortical microcircuit onto state of the art gated-RNNs (e.g. LSTMs or GRUs) in machine learning [27]. Furthermore, two studies investigating the neural mechanisms underlying the transformation of sensory neuronal activity to associated motor actions have revealed that learning the auditory discrimination task preferentially potentiated synapses corresponding to high or low frequencies, depending on the reward structure [28, 29]. Furthermore, it was observed in a follow-up study that synaptic weights did not change if the task structure was altered after the animal had learned the old task [28]. Although the aforementioned experiments targeted projections from one region to another, they favour the conjecture that microcircuit architectures offer a strong inductive bias with limited plasticity in recurrent connections.\n\nNevertheless, it is difficult to show experimental evidence that supports whether fixed recurrent circuits play a part or not at all. All panellists agreed that designing an experiment, along the lines of those mentioned above, and studying synaptic plasticity in task-relevant recurrent connections during learning will offer a better insight to resolve this issue. Furthermore, the role of plasticity in recurrent circuits would be demystified if we can assess learning deficits when these specific synaptic weight changes are disrupted. Notably, a significant challenge could be designing a task that requires the agent to rely on good temporal credit assignment. It has often been observed in computational studies that performance in several associative learning tasks can be explained using a liquid state machine with fixed dynamics and plasticity only at feedforward readout weights. Arguably, typical behavioural tasks investigated by neuroscientists may not need a deep credit assignment mechanism [30].\n\n## 4 | WHAT'S THE BRAIN'S OBJECTIVE FUNCTION?\n\nOur panellists agree that good credit assignment likely requires synaptic plasticity to be at least a rough approximation of gradient descent along some objective function. Exploiting statistical temporal regularities is critical for survival, and even basic sensory tuning requires some form of credit assignment.\n\nThe nature of the objective function is largely unknown. Since animals are rarely given precise external feedback, it is likely that learning is driven by intrinsic signals, often referred to as self-supervised learning. One prevalent hypothesis is that a major driver of learning is prediction, in which microcircuits are trained to predict their own future activity and propagate prediction errors or surprise signals to neighbouring microcircuits [31,32]. In doing so, neurons learn to group together external features with similar characteristics, the fundamental basis for a world-model with"
    },
    {
      "markdown": "predictable causal interactions.\nWhile this form of predictive learning may be important in the brain, it is likely that the brain learns over multiple objectives in different brain regions that may cooperate or compete with each other. Indeed there is evidence that brain areas can compete for control (e.g., habit-based or goal-directed brain areas competing for action selection), and that brain areas can cooperate (feedback association cortices guide plasticity in sensory cortices). Multi-objective training is widespread in deep neural networks, with examples of adversarial (e.g. Variational Autoencoders [33] and Generative Adversarial Networks [34]) and co-operative (e.g. Decoupled Neural Interfaces [35] and Siamese Networks [36]) training. However, there is disagreement if from an experimental point of view competition versus coorperation is a testable hypothesis. This raises the question of how can we evaluate theory in experimental work.\n\n# 5 | WHAT CAN EXPERIMENTS TELL US: THE LIMITATIONS IN COMPARING COMPUTATIONAL MODELS TO EXPERIMENTAL EVIDENCE \n\nA hard question for both theoretical and experimental neuroscientists is How do you know when plasticity is due to learning? Fundamentally, the panellists agree that it is experimentally challenging to monitor a large number of synapses over time and relate their changes to behaviour. Synaptic strengths can change for a variety of reasons, e.g., homeostatic mechanisms that try to maintain constant degrees of neural activity at a single-cell and population level over time (see [37, 38, 39] for homeostatic mechanisms that increase or decrease weights for reasons other than any obvious learning). Furthermore, memory traces and neuronal assemblies that are formed and linked to behaviour continue changing over time.\n\nTo date, no technology exists that allows massive, direct, chronic monitoring of synaptic plasticity at a high temporal resolution (see Humeau and Choquet [40] and Tsutsumi and Hayashi-Takagi [41] for reviews on SoTA for measuring functional changes in synaptic strength related to learning). However, Tony Zador contributed to our discussion by outlining technological developments that could soon allow large-scale monitoring of some forms of plasticity [42, 43] (See video). The proposed technique relies on tagging glutamate receptors that are inserted into the post-synaptic membrane which can then be visualized post-mortem and associated with its parent neuron. In conjunction with a behavioural task, this allows observation of changes in synaptic strength that occurred over the course of learning and post-mortem in-vitro experiments could be used to interrogate the plasticity rules at synapses where changes have been recorded. While this does represent an advance over current experimental approaches, it is still far from observing the dynamics of synaptic strengths during the course of learning. Although it is yet to be realised, such a technology would likely have a transformational effect on the field in terms of our understanding of learning in neural circuits,\n\nHowever, the lack of tools for tracking synaptic weights over time across a network has not discouraged researchers from inferring plasticity mechanisms from observations of somatic or dendritic activity [44]. As such, it should be possible to glean some insights from experiments using techniques that are currently available. For example, Gillon et al (2021) demonstrate that unexpected event signals in individual neurons and distal apical dendrites of the visual cortex can differentially predict subsequent changes in responses to expected and unexpected stimuli over days [45]. At the same time, it can be shown in artificial neural networks that it is possible to decode which update rules are being employed based solely on node activations [46, 47]. This shows that it may be possible to infer some information about synaptic dynamics from neural dynamics, if model assumptions about how synaptic plasticity relates to neural dynamics and learning can be clearly stated."
    },
    {
      "markdown": "![img-0.jpeg](img-0.jpeg)\n\nFIGURE 1 Density plots illustrating the audience sentiment towards a series of questions regarding synaptic plasticity, gradient computation and evolutionary neural circuits. 58 respondents had participated in this questionnaire.\n\n# 6 | CONCLUSION \n\nMuch of the difficulty in resolving how temporal credit assignment is implemented in biological recurrent networks comes from limitations in linking changes in synapses to changes in behaviour. At the same time, biologically-inspired"
    },
    {
      "markdown": "solutions for learning in artificial recurrent neural circuits is vastly underexplored. What are the specific tasks, circuits, and species we can use to think about these issues?\n\nRecommendation Box 1 A priority for theoretical neuroscientists should be to expand the model space:\n\n- We need to propose concrete and experimentally testable approximate credit assignment mechanisms that respect the space and time complexity of operations in neural circuits.\n- Of crucial importance, a proposed algorithm has to solve a non-trivial task in silico.\n- We should analyse the commonalities and differences across these different computational approximations.\n\nAn effective grouping of different theories will make experimental predictions more feasible to test, and allow us to understand when and where these proposed credit assignment mechanisms are best deployed.\n\nRecommendation Box 2 Experimental neuroscientists should prioritise designing behavioural analogues for common machine learning tasks that exploit an animal's natural behaviour:\n\n- We need to design tasks that are complicated enough to require non-trivial credit assignment that cannot be achieved with a shallow feedforward network, i.e., should be non-linearly separable, yet still experimentally feasible.\n- We should concurrently record neural activity of somatic, and ideally, dendritic activity through imaging techniques to support the efforts of computational neuroscientists.\n\nGood examples of non-trivial tasks for credit assignment include motor control tasks, delayed non-match to sample tasks, and path integration tasks during natural foraging or fear behaviours. Similarly, recordings from somatic and dendritic activity could potentially be directly compared with the learned representations and observed dynamics in deep artificial neural networks, where the architecture, optimizer, and cost functions are fully specified. This data may help to reveal the most plausible temporal credit assignment strategies used by the brain.\n\nWe concluded our workshop with an audience poll in order to evaluate the audience's takeaway and alignment to the panelists' opinions. Figure 1 indicates the distribution of responses that were submitted.\n\n# Acknowledgements \n\nThe authors thank Surya Ganguli, Tony Zador, Guillaume Lajoie, and Alexandre Payeur for their active participation with panellists during the workshop. We would also like to thank all other audience members from around the world who participated on the day in the chat, and everybody else who has watched the replay since it was posted online. Finally, we'd like to that Megan Peters, Eric deWitt, Nicolas Kriegeskorte, and the rest of the team from CCN who made the workshop possible.\n\n## references\n\n[1] Lillicrap TP, Santoro A. Backpropagation through time and the brain. Current opinion in neurobiology 2019;55:82-89.\n[2] Jozefowicz R, Zaremba W, Sutskever I. An empirical exploration of recurrent network architectures. In: International conference on machine learning PMLR; 2015. p. 2342-2350."
    },
    {
      "markdown": "[3] Rolnick D, Ahuja A, Schwarz J, Lillicrap TP, Wayne G. Experience replay for continual learning. arXiv preprint arXiv:181111682 2018;\n[4] Citri A, Malenka RC. Synaptic plasticity: multiple forms, functions, and mechanisms. Neuropsychopharmacology 2008;33(1):18-41.\n[5] Magee JC, Grienberger C. Synaptic plasticity forms and functions. Annual review of neuroscience 2020;43:95-117.\n[6] Mongillo G, Rumpel S, Loewenstein Y. Intrinsic volatility of synaptic connections-a challenge to the synaptic trace theory of memory. Current opinion in neurobiology 2017;46:7-13.\n[7] Pawlak V, Wickens JR, Kirkwood A, Kerr JN. Timing is not everything: neuromodulation opens the STDP gate. Frontiers in synaptic neuroscience 2010;2:146.\n[8] Feldman DE. Synaptic mechanisms for plasticity in neocortex. Annual review of neuroscience 2009;32:33-55.\n[9] Martin S, Morris R. New life in an old idea: the synaptic plasticity and memory hypothesis revisited. Hippocampus 2002;12(5):609-636.\n[10] Dan Y, Poo MM. Spike timing-dependent plasticity: from synapse to perception. Physiological reviews 2006;86(3):10331048.\n[11] Holtmaat A, Svoboda K. Experience-dependent structural synaptic plasticity in the mammalian brain. Nature Reviews Neuroscience 2009;10(9):647-658.\n[12] Bellec G, Scherr F, Subramoney A, Hajek E, Salaj D, Legenstein R, et al. A solution to the learning dilemma for recurrent networks of spiking neurons. Nature communications 2020;11(1):1-15.\n[13] Liu YH, Smith S, Mihalas S, Shea-Brown E, Sümbül U. A solution to temporal credit assignment using cell-type-specific modulatory signals. bioRxiv 2021;p. 2020-11.\n[14] Marschall O, Cho K, Savin C. A unified framework of online learning algorithms for training recurrent neural networks. Journal of Machine Learning Research 2020;21(135):1-34.\n[15] Golding NL, Staff NP, Spruston N. Dendritic spikes as a mechanism for cooperative long-term potentiation. Nature 2002;418(6895):326-331.\n[16] Letzkus JJ, Wolff SB, Lüthi A. Disinhibition, a circuit mechanism for associative learning and memory. Neuron 2015;88(2):264-276.\n[17] de Sevilla DF, Núñez A, Buño W. Muscarinic receptors, from synaptic plasticity to its role in network activity. Neuroscience 2021;456:60-70.\n[18] Favero M, Castro-Alamancos MA. Synaptic cooperativity regulates persistent network activity in neocortex. Journal of Neuroscience 2013;33(7):3151-3163.\n[19] Syková E, Vargová L. Extrasynaptic transmission and the diffusion parameters of the extracellular space. Neurochemistry international 2008;52(1-2):5-13.\n[20] Wu LG, Saggau P. Presynaptic inhibition of elicited neurotransmitter release. Trends in neurosciences 1997;20(5):204212.\n[21] Kirkpatrick J, Pascanu R, Rabinowitz N, Veness J, Desjardins G, Rusu AA, et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences 2017;114(13):3521-3526.\n[22] Ha D, Dai A, Le QV. Hypernetworks. arXiv preprint arXiv:160909106 2016;."
    },
    {
      "markdown": "[23] Zenke F, Poole B, Ganguli S. Continual learning through synaptic intelligence. In: International Conference on Machine Learning PMLR; 2017. p. 3987-3995.\n[24] Costa RP, Froemke RC, Sjöström PJ, van Rossum MC. Unified pre-and postsynaptic long-term plasticity enables reliable and flexible learning. Elife 2015;4:e09457.\n[25] Kaplanis C, Shanahan M, Clopath C. Continual reinforcement learning with complex synapses. In: International Conference on Machine Learning PMLR; 2018. p. 2497-2506.\n[26] Verstraeten D, Schrauwen B, d'Haene M, Stroobandt D. An experimental unification of reservoir computing methods. Neural networks 2007;20(3):391-403.\n[27] Costa RP, Assael YM, Shillingford B, de Freitas N, Vogels TP. Cortical microcircuits as gated-recurrent neural networks. arXiv preprint arXiv:171102448 2017;.\n[28] Ghosh S, Zador AM. Corticostriatal Plasticity Established by Initial Learning Persists After Behavioral Reversal. Eneuro 2021;8(2).\n[29] Xiong Q, Znamenskiy P, Zador AM. Selective corticostriatal plasticity during acquisition of an auditory discrimination task. Nature 2015;521(7552):348-351.\n[30] Richards BA, Lillicrap TP, Beaudoin P, Bengio Y, Bogacz R, Christensen A, et al. A deep learning framework for neuroscience. Nature neuroscience 2019;22(11):1761-1770.\n[31] Spratling MW. A review of predictive coding algorithms. Brain and cognition 2017;112:92-97.\n[32] Lotter W, Kreiman G, Cox D. A neural network trained for prediction mimics diverse features of biological neurons and perception. Nature Machine Intelligence 2020;2(4):210-219.\n[33] Kingma DP, Welling M. Auto-encoding variational bayes. arXiv preprint arXiv:13126114 2013;.\n[34] Goodfellow I. Nips 2016 tutorial: Generative adversarial networks. arXiv preprint arXiv:170100160 2016;.\n[35] Jaderberg M, Czarnecki WM, Osindero S, Vinyals O, Graves A, Silver D, et al. Decoupled neural interfaces using synthetic gradients. In: International Conference on Machine Learning PMLR; 2017. p. 1627-1635.\n[36] Chen X, He K. Exploring simple siamese representation learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition; 2021. p. 15750-15758.\n[37] Stemmler M, Koch C. How voltage-dependent conductances can adapt to maximize the information encoded by neuronal firing rate. Nature neuroscience 1999;2(6):521-527.\n[38] Turrigiano GG, Nelson SB. Hebb and homeostasis in neuronal plasticity. Current opinion in neurobiology 2000;10(3):358-364.\n[39] Turrigiano GG, Nelson SB. Homeostatic plasticity in the developing nervous system. Nature reviews neuroscience 2004;5(2):97-107.\n[40] Humeau Y, Choquet D. The next generation of approaches to investigate the link between synaptic plasticity and learning. Nature neuroscience 2019;22(10):1536-1543.\n[41] Tsutsumi S, Hayashi-Takagi A. Optical interrogation of multi-scale neuronal plasticity underlying behavioral learning. Current Opinion in Neurobiology 2021;67:8-15.\n[42] Dore K, Pao Y, Lopez JS, Aronson S, Zhan H, Ghosh S, et al. SYNPLA, a method to identify synapses displaying plasticity after learning. Proceedings of the National Academy of Sciences 2020;117(6):3214-3219."
    },
    {
      "markdown": "[43] Perez-Alvarez A, Fearey BC, O'Toole RJ, Yang W, Arganda-Carreras I, Lamothe-Molina PJ, et al. Freeze-frame imaging of synaptic activity using SynTagMA. Nature communications 2020;11(1):1-16.\n[44] Bono J, Clopath C. Modeling somatic and dendritic spike mediated plasticity at the single neuron and network level. Nature communications 2017;8(1):1-17.\n[45] Gillon CJ, Pina JE, Lecoq JA, Ahmed R, Billeh Y, Caldejon S, et al. Learning from unexpected events in the neocortical microcircuit. bioRxiv 2021;.\n[46] Nayebi A, Srivastava S, Ganguli S, Yamins DL. Identifying Learning Rules From Neural Network Observables. arXiv preprint arXiv:201011765 2020;.\n[47] Lim S, McKee JL, Woloszyn L, Amit Y, Freedman DJ, Sheinberg DL, et al. Inferring learning rules from distributions of firing rates in cortical neurons. Nature neuroscience 2015;18(12):1804-1810."
    }
  ],
  "usage_info": {
    "pages_processed": 10,
    "doc_size_bytes": 483777
  },
  "_metadata": {
    "model_version": "0.0.0",
    "llm_model": "mistral-ocr-2505",
    "query_data": {
      "pdf": "/Users/satyaortiz-gagne/CODE/paperext/data/cache/fulltext/851fa17af8345c2e2066f32cea870202/fulltext.pdf"
    },
    "model_id": "parsepdf"
  }
}