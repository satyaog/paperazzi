{
  "pages": [
    {
      "markdown": "# Learning What You Need from What You Did: Product Taxonomy Expansion with User Behaviors Supervision \n\nSijie Cheng*, Zhouhong Gu*, Bang Liu ${ }^{\\| \\ddagger}$, Rui Xie ${ }^{\\S}$, Wei Wu ${ }^{\\text {® }}$ and Yanghua Xiao* ${ }^{\\text {I }}$ * Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China<br>${ }^{\\ddagger}$ Fudan-Aishu Cognitive Intelligence Joint Research Center, Shanghai, China<br>$\\|$ RALI \\& Mila, Université de Montréal, Montréal, Québec, Canada<br>${ }^{\\ddagger}$ Canada CIFAR AI Chair<br>${ }^{\\S}$ Meituan, Shanghai, China<br>${ }^{\\text {® }}$ Meituan, Beijing, China<br>$\\{$ sjcheng20, zhgu20, shawyh\\}@fudan.edu.cn<br>bang.liu@umontreal.ca, \\{rui.xie, wuwei30\\}@meituan.com\n\n\n#### Abstract\n\nTaxonomies have been widely used in various domains to underpin numerous applications. Specially, product taxonomies serve an essential role in the e-commerce domain for the recommendation, browsing, and query understanding. However, taxonomies need to constantly capture the newly emerged terms or concepts in e-commerce platforms to keep up-to-date, which is expensive and labor-intensive if it relies on manual maintenance and updates. Therefore, we target the taxonomy expansion task to attach new concepts to existing taxonomies automatically. In this paper, we present a self-supervised and user behavior-oriented product taxonomy expansion framework to append new concepts into existing taxonomies. Our framework extracts hyponymy relations that conform to users' intentions and cognition. Specifically, i) to fully exploit user behavioral information, we extract candidate hyponymy relations that match user interests from query-click concepts; ii) to enhance the semantic information of new concepts and better detect hyponymy relations, we model concepts and relations through both usergenerated content and structural information in existing taxonomies and user click logs, by leveraging Pre-trained Language Models and Graph Neural Network combined with Contrastive Learning; iii) to reduce the cost of dataset construction and overcome data skews, we construct a high-quality and balanced training dataset from existing taxonomy with no supervision. Extensive experiments on real-world product taxonomies in Meituan Platform, a leading Chinese vertical e-commerce platform to order take-out with more than 70 million daily active users, demonstrate the superiority of our proposed framework over state-of-the-art methods. Notably, our method enlarges the size of real-world product taxonomies from 39,263 to 94,698 relations with $88 \\%$ precision. Our implementation is available: https://github.com/AdaCheng/Product_Taxonomy_Expansion.\n\nIndex Terms—Taxonomy Expansion, User Behavior Oriented, Pre-trained Language Model, Contrastive Learning, Graph Neural Network, Self-supervision\n\n\n## I. INTRODUCTION\n\nWith the increasing importance of taxonomies in various applications, many taxonomies have been constructed in general and specific domains, such as lexical taxonomy (e.g., WordNet [1]), scientific taxonomies (e.g., MeSH [2]), and product tax-\nonomies built by Amazon [3]. Specially, product taxonomies have been widely used as an essential component to underpin various downstream applications in the e-commerce domain, including personalized recommendation [4]-[6], query understanding [7], [8] and web content tagging [9]-[11]. However, as new concepts constantly emerge, existing web-scale product taxonomies face an outdated problem. Manually maintaining or updating existing product taxonomies is labor-intensive and difficult to scale. As a result, the taxonomy expansion task, which automatically attaches new concepts to the existing taxonomy, has received increasing attention.\n\nExisting relevant methods are mainly designed for generalpurpose taxonomies paying great attention to feature extraction from an open domain corpus, having limited effects on product taxonomy. The reasons are as follows. First, the semantics of domain-specific concepts or new concepts might not be represented well. The concepts in the e-commerce domain rarely appear in general corpora, making corpus-based methods [12][16] infeasible. Graph-based methods [17]-[20] can slightly enrich the semantics by aggregating the neighbors' information in the existing taxonomy, but it does not work well for emerging concepts. Without sufficiently modeling the actual semantic of concepts, it is difficult to infer the hyponymy relations. Second, existing approaches neglect that e-commerce platforms are highly user-involved systems. Matching the shopping need of a user is one of the major functionalities of an e-commerce platform [21]. Thus, the selection of candidate concepts and the definition of appropriate hyponymy relations rely on user cognition. Non-user-centered taxonomy expansion introduces a huge gap between user needs and the product taxonomy, which further hurts the utility of taxonomies to serve downstream applications.\n\nThe aforementioned considerations motivate us to propose a novel taxonomy expansion method driven by user behavioral data. Such data contains rich effective signals to infer a hypernymy relation, which is the core task in taxonomy expansion."
    },
    {
      "markdown": "Specifically, we mainly use user click logs and user-generated content. From the user click logs, we can find many queries and corresponding clicked items. One observation is that the queries in many cases are coarse-grained hypernym concepts, such as \"Bread (面包)\", while the corresponding clicked items are quite likely fine-grained hyponym products, such as \"Cheese Bun (奶酪包)\". From the user-generated content, we can easily find some user comments such as \"Cheese Bun (奶酪包) is one of my favorite bread (面包)\", which strongly suggests the hypernymy relation between \"Cheese Bun (奶酪包)\" and \"Bread (面包)\". Therefore, user behavioral data in e-commerce platforms reflects users' search intention and their cognition about items in the platforms.\n\nIn addition, hyponymy relation inference in taxonomy expansion generally needs appropriate supervision. Selfsupervised strategy which constructs a training dataset automatically from existing taxonomy is popularly used in recent studies [16], [18]-[20], [22]. However, most existing taxonomies are semi-automatically constructed, which inevitably incurs data skews issues. For example, $96.56 \\%$ hyponymy relations in our existing taxonomy (in Section IV-A1) can be detected by headword (e.g., \"Rye Bread (黑麦面包)\" IsA \"Bread (面包)\"). In contrast, the proportion of other difficult cases of hypernymy relations (e.g., \"Cheese Bun (奶酪包)\" IsA \"Bread (面包)\") is tiny. Therefore, it is essential to rectify the bias inherent in a web sale taxonomy usually constructed by semi-automatic approaches, ensuring the quality of selfsupervised dataset generation.\n\nIn this paper, we propose a self-supervised user behaviororiented product taxonomy expansion framework. Different from prior work, we not only aim to attach the appropriate concepts to an existing taxonomy, but also further consider conforming to user intention and cognition by mining from user click logs and user-generated content. To generate labeled data without human effort and avoid error propagation, we utilize adaptive self-supervision to construct a high-quality training dataset constrained by user behaviors, focusing on keeping the appropriate balance among different pattern types. The most remarkable advantage is that our methods can continuously update the existing taxonomy as user behavior information grows day by day. Specifically, we make the following contributions in this paper:\n\nFirst, to the best of our knowledge, we propose the first product taxonomy expansion framework driven by user behavioral data. We fuse user click-through and comments into a heterogeneous graph to accomplish the taxonomy expansion task. The rich user behavioral data helps to prune the search space of candidate hyponymy relations and enrich the representations of concepts in a specific domain. The heterogeneous graph integrates various types of information from both existing taxonomies and user behavioral data. The heterogeneous graph-based framework is also extensible to incorporate more emerging user data in the e-commerce domain.\n\nSecond, we propose two effective representation learning strategies that are well tailored for the user behavior driven taxonomy expansion task. One is implicit relational representa-\ntions automatically derived from pre-trained language models fine-tuned on user-generated content. The other is structural representations extracted from both exiting taxonomies and user click logs via utilizing contrastive learning and graph neural networks. Both automatic and manual evaluations have shown that our representation learning method significantly outperforms other baselines.\n\nThird, we propose a novel self-supervised dataset construction method that explicitly addresses the data noise and data skew issues inherent in the supervision from a webscale product taxonomy. Our solution helps construct highquality datasets with above $95 \\%$ accuracy without human labor. The dataset is also adaptively refined so that the different patterns of samples are subtly balanced, alleviating the overfitting problem and improving the generalization ability of our hyponymy relation inference model.\n\nLast but not least, we conduct extensive experiments on real large-scale platforms, justifying the effectiveness of the proposed solution. Experimental results show that our proposed method significantly surpasses the previous state-of-the-art baselines on all the datasets by $74.92 \\%$ in accuracy and $77.56 \\%$ in edge-F1. We apply our solution to expand the product taxonomy of Meituan (美团). a leading Chinese vertical e-commerce platform for ordering take-outs with more than 70 million daily active users. Specifically, we significantly enlarge the size ( 39,263 to 94,698 relations) of Meituan product taxonomies with $88 \\%$ precision. Finally, an offline user study shows that query rewriting supported by the expanded taxonomy improves feed stream recommendation by $6 \\%$ precision. Although our framework is tested for this specific platform, the core idea to use user behavior data to expand a taxonomy can be easily adapted to any platform rich in user behavioral data.\n\n## II. Problem Formulation\n\nIn this section, we first give the definitions of the preliminary concepts and user behavioral data used in this paper, then formally define our taxonomy expansion problems, and further discuss the scope of our study.\n\n## A. Preliminaries\n\nDefinition 1. (Taxonomy.) A taxonomy $\\mathcal{T}=(\\mathcal{N}, \\mathcal{E})$ is a treestructured hierarchy. Each node $n \\in \\mathcal{N}$ denotes a concept and each directed edge $\\left\\langle n_{p}, n_{c}\\right\\rangle \\in \\mathcal{E}$ represents the hyponymy relation between the parent (hypernym) node $n_{p}$ and the child (hyponym) node $n_{c}$.\nDefinition 2. (Concept Vocabulary.) To assure the quality of candidate concepts extracted from user behavioral data, we firstly automatically collect a set of product concepts $\\mathcal{P}=\\left\\{p_{1}, p_{2}, \\cdots, p_{k}\\right\\}$ from menus in merchants. Then we ask experts to manually label them and finally obtain a clean product concept vocabulary $\\mathcal{C}=\\left\\{c_{1}, c_{2}, \\cdots, c_{m}\\right\\}$.\nDefinition 3. (User Click Logs.) User click logs $\\mathcal{U}_{l}=$ $\\left\\{\\left(q, I_{q}\\right)\\right\\}$ record each user query $q \\in \\mathcal{Q}$ and its corresponding clicked items $I_{q} \\in \\mathcal{I}$. Each item in $I_{q}$ is represented by its"
    },
    {
      "markdown": "![img-0.jpeg](img-0.jpeg)\n\nFig. 1. Our proposed framework mainly contains two major phases: Graph Construction and Hyponymy Detection. In graph construction module, we build a user click graph combining with existing taxonomy and user click logs. In hyponymy detection module, we firstly obtain the relational representation (bottom-left) and structural representation (top-right), then utilize them to detect the hyponymy relations between a query and its clicked items. In addition, we automatically construct the training and validation datasets via adaptively self-supervised generation.\ndescriptive text, which is usually defined by the merchant, such as \"Well-known Cheese Bun (网红奶酪包)\".\n\nUser click logs reflect user search intention and contain rich information about hyponymy relations. For example, when we query \"Bread (面包)\", \"Cheese Bun (奶酪包)\" is one of the typical clicked items. Such search and click behavior reveals that \"Cheese Bun (奶酪包)\" can be seen as an instance or a sub-concept of \"Bread (面包)\". Furthermore, as a hypernym of \"Cheese Bun (奶酪包)\", \"Bread (面包)\" also reveals the user's real search intention.\n\nDefinition 4. (User-generated Content.) User-generated content $\\mathcal{U}_{c}=\\left\\{t_{1}, t_{2}, \\cdots, t_{n}\\right\\}$ refers in particular to the corpus of $n$ texts generated by users, such as the reviews of products.\n\nUser-generated content (UGC) directly expresses user cognition of items and contains vast implicit domain-specific relational knowledge. Suppose we are given \"Bread (面包)\" and \"Toast (吐司)\" to predict whether there exists hyponymy relation between them. UGC might implicitly mention their relations. For example, it is pretty likely to find two sentences \"The toast in this bakery is delicious (这家面包店的吐司真美味)\" and \"The bakery sells all kinds of bread (面包店里卖各种各样的面包)\" from the whole UGC, which are enough to infer that \"Toast (吐司)\" is a kind of \"Bread (面包)\".\n\n## B. Problem Definition\n\nProblem 1. (Taxonomy Expansion.) Given an existing taxonomy $\\mathcal{T}^{0}=\\left(\\mathcal{N}^{0}, \\mathcal{E}^{0}\\right)$, the set of clean concept vocabulary $\\mathcal{C}$, the goal of taxonomy expansion task is to attach the appropriate concept $c \\in \\mathcal{C}$ to the existing taxonomy $\\mathcal{T}^{0}$ and expand it to obtain an enriched taxonomy $\\mathcal{T}^{*}=\\left(\\mathcal{N}^{0} \\cup \\mathcal{C}, \\mathcal{E}^{0} \\cup \\mathcal{R}\\right)$, where $\\mathcal{R}$ is a set of new hyponymy relations $\\langle n, c\\rangle, n \\in \\mathcal{N}^{0}, c \\in \\mathcal{C}$.\n\nFormally, we consider each node $n \\in \\mathcal{N}^{0}$ as a random variable and the taxonomy $\\mathcal{T}^{0}$ as a Bayesian network. The probability of taxonomy $\\mathcal{T}^{0}$ can be formulated as follows.\n\n$$\n\\mathbf{P}\\left(\\mathcal{T}^{0} \\mid \\Theta\\right)=\\mathbf{P}\\left(\\mathcal{N}^{0} \\mid \\mathcal{T}^{0} ; \\Theta\\right)=\\prod_{i=1}^{|\\mathcal{N}^{0}|} \\mathbf{P}\\left(n_{i} \\mid p\\left(n_{i}\\right) ; \\Theta\\right)\n$$\n\nwhere $\\Theta$ denotes model parameters, and $p\\left(n_{i}\\right)$ represents the parent node(s) of $n_{i}$. We then find the optimal taxonomy $\\mathcal{T}^{*}$ by maximizing the likelihood.\n\n$$\n\\begin{aligned}\n\\mathcal{T}^{*} & =\\underset{\\mathcal{T}^{0}}{\\arg \\max } \\mathbf{P}\\left(\\mathcal{T}^{0} \\mid \\Theta\\right) \\\\\n& =\\underset{\\mathcal{T}^{0}}{\\arg \\max } \\sum_{i=1}^{|\\mathcal{N}^{0} ; \\mathcal{C}|} \\log \\mathbf{P}\\left(n_{i} \\mid p\\left(n_{i}\\right) ; \\Theta\\right)\n\\end{aligned}\n$$\n\nHowever, for every node in the existing taxonomy, all concepts in $\\mathcal{C}$ can be taken as candidates of hyponym, thus the potential search space is incredibly enormous. Previous studies [16]-[19], [23] address the above problem via an assumption that the input set of new concepts contains only one element (i.e., $|\\mathcal{C}|=1$ ), and aims to find one single parent node in the existing taxonomy $\\mathcal{T}^{0}$ of this new concept (i.e., $|\\mathcal{R}|=1$ ). This simplification not only limits expansion in the depth of taxonomies, but also neglects the truth that a new concept has multiple parent nodes. In this paper, we discard this assumption and propose restricting this search space through strong prior hyponymy relations in user behaviors.\n\n## III. SOLUTIONS\n\nIn this section, we propose an adaptively self-supervised user-behavior oriented framework for product taxonomy expansion as illustrated in Figure 1. In our solutions, we model"
    },
    {
      "markdown": "the taxonomy expansion as an edge classification problem, which is different from previous methods [18], [19] that model taxonomy expansion task as a multi-class ranking problem or a shortest path finding problem. We first elaborate on our two key modules: graph construction and hyponymy detection, then discuss the process of model learning and inference.\n\n## A. Graph Construction\n\nGiven the set of clean concept vocabulary $\\mathcal{C}$, an existing taxonomy $\\mathcal{T}^{0}$ and user click logs $I_{0}$, here we need to construct a heterogeneous edge-weighted graph $\\mathcal{G}_{h}=\\left(\\mathcal{N}_{h}, \\mathcal{E}_{h}\\right)$ in the following four steps.\n\n1) Items Collection: Based on the existing taxonomy, we collect items through treating concepts in existing taxonomy as query concepts $\\mathcal{C}_{q}$ to find their clicked items. For example, there is a concept \"Bread (面包)\" in the existing taxonomy. If it is a query concept that appeared in the user click logs, its corresponding clicked items, such as \"Well-known Cheese Bun (网红奶酪包)\", are used as candidate nodes in the graph.\n2) Nodes Identification: As an item can be described by different names, we identify the clicked concept nodes $\\mathcal{C}_{i}$ in the clean concept vocabulary $\\mathcal{C}$ via longest common sub-string matching. For example, given the set of concept vocabulary $\\mathcal{C}=\\{$ \"Bun (包)\", Cheese Bun (奶酪包)\", $\\cdots\\}$, the concept node \"Cheese Bun (奶酪包)\" is identified from the clicked item \"Well-known Cheese Bun (网红奶酪包)\".\n3) Edge Connection: Next, we connect query concepts $\\mathcal{C}_{q}$ and item concepts $\\mathcal{C}_{i}$, representing their interactions in user behavioral data. In this way, we can acquire a new edge between \"Bread (面包)\" and \"Cheese Bun (奶酪包)\".\n4) Weight Assignment: Considering that the probabilities of different edges to be hyponymy relations should not be equal, and user click behavior can reflect confidences among edges, we use a variant of the Term Frequency - Inverse Document Frequency [24] to set our edge weights.\n\nOur Item Frequency (IF) denotes the clicked frequency of the item concept $c_{i} \\in \\mathcal{C}_{i}$ according to the query concept $c_{q} \\in \\mathcal{C}_{q}$, normalized by the total clicked frequencies of item concepts under the query concept. Intuitively, under the same query concept, IF indicates the importance of item concepts where the item concept with more clicked times is more likely to be the hyponym.\n\n$$\n\\mathrm{IF}_{c_{q}, c_{i}}=\\frac{\\operatorname{num}_{c_{q}, c_{i}}}{\\sum_{c_{k} \\in \\mathcal{C}_{i}} \\operatorname{num}_{c_{q}, c_{k}}}\n$$\n\nOur Inverse Query Frequency (IQF) denotes the total number of query concepts $\\mathcal{C}_{q}$ in the user click graph, divided by the total number of query concepts $c_{q}$ which click to the item concept $c_{i}$.\n\n$$\n\\mathrm{IQF}_{c_{i}}=\\log \\frac{\\left|\\mathcal{C}_{q}\\right|}{\\left|\\left\\{c_{q}: c_{q} \\rightarrow c_{i}\\right\\}\\right|}\n$$\n\nComprehensively considering importance and novelty factors, the attribute $a_{c_{q}, c_{i}}$ of edge $e_{c_{q}, c_{i}}=\\left\\langle c_{q}, c_{i}\\right\\rangle$ can be calculated by multiplying the two scores together. We adopt a square to balance these two factors and further normalize the attribute score to ensure it is between 0 and 1 , while the sum\nof weights under the same query concept is 1 . Meanwhile, the weights of edges from the existing taxonomy are all set to 1 .\n\n$$\na_{c_{q}, c_{i}}=\\operatorname{softmax}\\left(\\mathrm{IF}_{c_{q}, c_{i}} *\\left(\\mathrm{IQF}_{c_{i}}\\right)^{2}\\right)\n$$\n\nThrough this algorithm of weight assignment, we can also alleviate two types of noises in the user behavioral data:\n(i) Intention-drifted behavior: People click the items which are not consistent with their initial intention, which leads to semantic drift. For example, some people intend to buy \"Bread (面包)\" at first. However, there are some distractors such as \"Sweet Soup (甜汤)\" shown in the browsing page, because both \"Bread (面包)\" and \"Sweet Soup (甜汤)\" belong to \"Dessert (甜点)\". Due to these distractors, several of them end up buying \"Sweet Soup (甜汤)\" which does not have hyponymy relation with \"Bread (面包)\". With the critical factor IF, this type of noise will be assigned a lower weight.\n(ii) Common but non-sense behavior: Some common concepts that occurred in the click items to all queries without hyponymy relations. For instance, some Chinese users love to drink soup during mealtime, so they may order an extra \"Sweet Soup (甜汤)\" no matter what they intend to order. However, \"Sweet Soup (甜汤)\" is not a suitable hyponymy item concept for most query concepts, such as \"Bread (面包)\". The weight of common items that appeared under most query concepts will be punished through the novelty factor IQF.\n\n## B. Hyponymy Detection\n\nWe propose a hyponymy detection module to classify the edges in the heterogeneous graph. Unlike previous methods that manually design a set of shallow lexical or structural features [16], [18], we automatically capture two complementary representations of concepts via user behavioral information.\n\n1) Relational Representation from User-Generated Content: User-Generated Content, e.g., user reviews or comments on a platform, are the main text corpora in the e-commerce domain. They contain rich but noisy context information of domain-specific concepts. The hyponymy relations between concepts are usually implicitly expressed in UGC instead of explicitly stated. Therefore, directly extracting the exact hyponymy relations via pattern-based methods, such as Hearst patterns [25], [26], is infeasible. To solve this problem, we propose using Pre-trained Language Models to capture relational knowledge from UGC automatically.\n\nPretraining Stage. Due to the lack of domain knowledge in vanilla BERT-Chinese [27] that pretrained on general text corpora, we first pre-train a BERT-Chinese on User Generated Content. Considering that our target is to classify the hyponymy relation between two concepts, we adopt a conceptlevel masking strategy to better model the representations of concepts rather than following the token-level masking strategy in the vanilla BERT-Chinese. As shown in Figure 1, in the pre-training stage of relational representation, we first employ our internal word segmentation tool (which can be replaced by other off-the-shelf text segmentation tools such as Jieba) to segment the sentence. Then we select nouns and match them to the given concept vocabulary. After detecting"
    },
    {
      "markdown": "all the concepts in the sentence, we randomly mask the concepts mentioned in the sentence with [MASK] token and ask the model to recover all slots. Finally, we acquire an enhanced model called C(oncept)-BERT, modeling domainspecific concept knowledge.\n\nRepresentation Stage. Traditional expansion methods always concatenate the representations of two concepts or compute their similarity score. We argue that there exist several disadvantages: first, the representations only contain semantic information of each concept but neglect the relational information between them; second, the direction in the hyponymy relations are not reflected in the representations; third, empirical experiments have confirmed that BERT performs better in sentence-level representation than token-level and phrase-level representation.\n\nTo this end, we manually design a pre-defined template to capture the relational representation following [28]. Given a query concept $c_{q}$ and an item concept $c_{i}$, the input format to C-BERT is organized as below.\n\n$$\n\\text { Input }_{c_{q}, c_{i}}=\\left[\\langle\\mathrm{CLS}\\rangle \\oplus c_{q} \\oplus i s \\oplus a \\oplus c_{i} \\oplus\\langle\\mathrm{SEP}\\rangle\\right]\n$$\n\nwhere $\\oplus$ represents concatenation, $\\langle\\mathrm{CLS}\\rangle$ and $\\langle\\mathrm{SEP}\\rangle$ are the special tokens for classification and sentence separation respectively. We then encode $D_{u_{p}, u_{s}}$ by $\\operatorname{C}-\\operatorname{BERT}(\\cdot)$, and take the final layer representation of $\\langle\\mathrm{CLS}\\rangle$ as the relational representation of the concept pair $\\left\\langle c_{q}, c_{i}\\right\\rangle$.\n\n$$\nr_{c_{q}, c_{i}}=\\text { C-BERT }\\left(\\text { Input }_{c_{q}, c_{i}}\\right)[0]\n$$\n\n2) Structural Representation from Heterogeneous Graph: Given the weighted heterogeneous graph $\\mathcal{G}_{h}=\\left(\\mathcal{N}_{h}, \\mathcal{E}^{0}\\right)$, our goal is to capture the structural representation from both existing taxonomy and user click graph for each node. To achieve that, we leverage Graph Neural Networks combined with Contrastive Learning to finetune the whole graph and then represent the structural information.\n\nPretraining Stage. Since there exist strong hyponymy relations between neighbor node pairs and other node pairs are likely to be unrelated, inspired by the recent success of contrastive learning in graph learning [29], [30], we propose to adopt contrastive learning as our pre-training task to pull together the neighbor node pairs and push away others.\n\nFor each node $u \\in \\mathcal{N}_{h}$, the initial input representation $h_{u}^{0}$ of $u$ is produced by C-BERT.\n\n$$\nh_{u}^{0}=\\text { C-BERT }\\left(\\langle\\mathrm{CLS}\\rangle \\oplus u \\oplus\\langle\\mathrm{SEP}\\rangle\\right)[0]\n$$\n\nWe first compute the cosine similarity between the hidden representations of two nodes $u$ and $v$.\n\n$$\nS(u, v)=\\frac{h_{u}^{0} h_{v}^{0}}{\\left\\|h_{u}^{0}\\right\\|\\left\\|h_{v}^{0}\\right\\|}\n$$\n\nwhere $\\|\\cdot\\|$ is $L_{2}$-norm. Then we set node $u \\in \\mathcal{N}_{h}$ as an anchor node and define its neighbors as $N(u)$. The node pairs between $u$ and neighbors $N(u)$ are positive samples, and the node pairs between $u$ and all the other nodes in the heterogeneous graph are negative samples. For an anchor node\n$u$, the loss function is defined based on InfoNCE [31] as follows:\n\n$$\n\\mathcal{L}_{C L}=-\\log \\frac{\\sum_{v \\in N(u)} \\exp (S(u, v))}{\\sum_{v \\in \\mathcal{N}_{h}} \\exp (S(u, v))}\n$$\n\nRepresentation Stage. It is natural to leverage graph neural networks to update the representations of $u$ iteratively $\\in \\mathcal{N}_{h}$ by aggregating the representations of its neighbors $N(u)$ and itself in a heterogeneous graph $\\mathcal{G}_{h}$. For convenience, we define the neighbors $N(u)$ and itself $u$ as $\\widehat{N(u)}$. The structural representation updates information within its K-hop neighborhood after $K$ iterations. We formulate the hidden representation of $u$ with K-layer(hop).\n\n$$\nh_{u}^{k}=\\operatorname{AGG}^{k}\\left(\\left\\{h_{u}^{k-1} \\mid v \\in \\widehat{N(u)}\\right\\}\\right), k \\in\\{1, \\ldots, K\\}\n$$\n\nwhere the $\\mathrm{AGG}^{k}$ is an aggregation function in the k-th layer which we expressly adopt Graph Convolutional Network (GCN) [32] as follows.\n\n$$\nh_{u}^{k}=\\rho\\left(\\sum_{v \\in \\widehat{N(u)}} a_{u v}^{k-1} \\mathbf{W}^{(k-1)} h_{v}^{(k-1)}\\right)\n$$\n\nwhere $a_{u v}^{k-1}$ is the edge attribute in the heterogeneous graph between node $u$ and node $v$ which is same for all layers, $\\rho(\\cdot)$ denotes an activation function (e.g., ReLU), and $\\mathbf{W}^{(k-1)}$ is the learnable weight matrix.\n\nA significant flaw of the above GNN model is that it does not consider the direction of the hyponymy relation between two concepts. To solve this problem, given a query concept $c_{q}$ and an item concept $c_{i}$, we concatenate a position embedding $p_{\\text {parent }}$ to the former, and $p_{\\text {child }}$ to the later node. These two types of position embedding, $p_{\\text {parent }}$ and $p_{\\text {child }}$, indicate the node identity of the parent or child. We define the final structural representation of a node pair $\\left(c_{q}, c_{i}\\right)$ as follows.\n\n$$\ns_{c_{q}, c_{i}}=\\left[h_{c_{q}}^{k} \\oplus p_{\\text {parent }} \\oplus h_{c_{i}}^{k} \\oplus p_{\\text {child }}\\right]\n$$\n\n3) Edge Classification: For each edge $\\left\\langle c_{q}, c_{i}\\right\\rangle$ between a query concept $c_{q}$ and an item concept $c_{i}$, we concatenate the representations detailed above to the edge representation:\n\n$$\ne_{c_{q}, c_{i}}=\\left[r_{c_{q}, c_{i}} \\oplus s_{c_{q}, c_{i}}\\right]\n$$\n\nWe then feed the edge representation $e_{c_{q}, c_{i}}$ into a multilayer perception with one hidden layer to classify whether there is a hyponymy relation between a query concept $c_{q}$ and an item concept $c_{i}$.\n\n$$\nf^{\\mathrm{MLP}}\\left(c_{q}, c_{i}\\right)=\\gamma\\left(W_{2} \\sigma\\left(W_{1} e_{c_{q}, c_{i}}+B_{1}\\right)+B_{2}\\right)\n$$\n\nwhere $\\left\\{W_{1}, B_{1}, W_{2}, B_{2}\\right\\}$ are parameters; $\\gamma(\\cdot)$ is the Softmax function, and $\\sigma(\\cdot)$ is the Sigmoid activation function.\n\n## C. Model Learning and Inference\n\nTo learn the hyponymy detection module, we first introduce the self-supervised generation process using edges from existing taxonomies, and then discuss how to perform model training and inference."
    },
    {
      "markdown": "![img-1.jpeg](img-1.jpeg)\n\nFig. 2. Top-down strategy for updating the existing taxonomy.\n\n1) Self-supervised Data Generation: We prefer to generate self-supervision data from existing taxonomy $\\mathcal{T}^{0}=\\left(\\mathcal{N}^{0}, \\mathcal{E}^{0}\\right)$ with no human curation involved. However, there is a critical challenge that existing taxonomy is exceptionally unbalanced in terms of hyponymy relations: about $93 \\%$ of the hyponymy relations can be detected by headword, but other hyponymy relations are rarely contained. For example, \"xxx Bread\" is a kind of \"Bread (面包)\", while some concepts such as \"Toast (吐司)\" and \"Baguette (长粗面包)\" is also the hyponymy concepts of \"Bread (面包)\". Nevertheless, the set of hyponymy concepts under the concept \"Bread (面包)\" are almost \\{\"Red Bean Bread (红豆面包)\", \"Fried Bread (油炸面包)\", ...\\} in the existing taxonomy. We need to extract more hyponymy relations of diverse patterns that headwords or pattern-based methods can not easily detect.\n\nPositive Samples. To construct a new balanced supervision hyponymy relations data, we sample hyponymy relations that could not be detected with headword patterns. Specifically, for a specific $\\left\\langle c_{p}, c_{i}\\right\\rangle$ hyponymy relation in existing taxonomy $\\mathcal{T}^{0}$, if it can not be detected with headword, it is kept in the training data. Otherwise, it is selected into the dataset with a probability when the hyponymy reaction appears in the user click data. Through this way, we finally obtain a proportionally balanced taxonomy $\\overline{\\mathcal{T}^{0}}=\\left(\\mathcal{N}^{0}, \\overline{\\mathcal{E}^{0}}\\right)$.\n\nNegative Samples. Given an edge $\\left\\langle c_{q}, c_{i}\\right\\rangle$ in the filtered taxonomy as a positive sample, we construct $N$ negative samples alternatively with the following strategy:\n\n- Shuffle the order of the edge $c_{i}, c_{q}$;\n- Fix the query concept $c_{q}$ and replace the item concepts by sampling $N$ concepts $\\left\\{c_{0}^{1}, \\ldots, c_{0}^{N}\\right\\}$ from user click logs, which are nodes in the filtered taxonomy but neither parents nor descendants of $c_{q}$.\nIn this way, we collect training instances $X=$ $\\left\\{\\left\\langle c_{q}, c_{i}\\right\\rangle,\\left\\langle c_{i}, c_{q}\\right\\rangle,\\left\\langle c_{q}, c_{0}^{1}\\right\\rangle, \\ldots,\\left\\langle c_{q}, c_{0}^{N}\\right\\rangle\\right\\}$ and repeat the process for each edge in the filtered taxonomy $\\overline{\\mathcal{T}^{0}}$. Our generated full self-supervision training data is $\\mathbb{X}=\\left\\{X_{1}, X_{2}, \\ldots, X_{|\\overline{\\mathcal{E}^{0}}|}\\right\\}$.\n2) Model Training: At the training stage of edge classification, we learn our representations and adopt Binary CrossEntropy loss as the objective function of training data $\\mathbb{X}$.\n\n$$\n\\mathcal{L}=\\sum_{\\left\\langle c_{q}, c_{i}\\right\\rangle \\in \\mathbb{X}} \\operatorname{BCELoss}\\left(f^{\\mathrm{MLP}}\\left(c_{q}, c_{i}\\right), \\hat{f}^{\\mathrm{MLP}}\\left(c_{q}, c_{i}\\right)\\right)\n$$\n\nwhere $f^{\\mathrm{MLP}}\\left(c_{q}, c_{i}\\right)$ is the predicted label and $\\hat{f}^{\\mathrm{MLP}}\\left(c_{q}, c_{i}\\right)$ is the ground truth label.\n3) Model Inference: At the inference stage, to expand the existing taxonomy with hyponymy relations between new concepts rather than attach new concepts to existing nodes, we especially update the existing taxonomy by adopting a topdown strategy shown in Figure 2. We traverse the existing taxonomy in level-order. We apply the learned model for each node in the existing taxonomy to classify and attach the predicted hyponymy relation to the existing taxonomy. Considering the transitive property of taxonomy [33], we prune the expanded taxonomy to assure that there is no redundant edge that can infer from the path. The attached new nodes are also considered for further expanse when we process the next layer. Through this strategy, we traverse the existing taxonomy only once and expand the width as well as the depth.\n\n## IV. EXPERIMENTS\n\nIn this section, we first do a series of statistics in the graph construction phase to test whether the hypothesis of strong hyponymy relations exists for query-item interactions in user behavior information. Second, we compare our proposed approach with various baseline methods. Subsequently, we further analyze our performance through ablation and case studies. Finally, we deploy the extended taxonomy in a production environment to perform large-scale online A/B tests.\n\n## A. Evaluation on Term Extraction\n\n1) Datasets: Meituan platform is a leading Chinese vertical e-commerce platform that mainly serves for ordering take-out. In this paper, we take the Meituan Gourmet Food Taxonomy as the major testbed for all the following experiments. The depth of Meituan Gourmet Food Taxonomy is 16 layers. It contains about 195 thousand concepts and 585 thousand taxonomic relations. We sample three different domain taxonomies from Meituan Gourmet Food taxonomy: Snack, Fruits, and Prepared Food. The detailed statistics of taxonomies are shown in Table II. The taxonomy of Snack is 12 layers which is deeper than Fruits (6 layers) and Prepared Food (7 layers). In all taxonomies, the proportion of edges detected by headword is much more significant than others.\n2) Metrics: We design a set of metrics to prove the validity of the potential strong hyponymy relations in user click logs.\n\n- \\#Items denotes how many query-item records are extracted from user click logs given nodes as query concepts in the existing taxonomy.\n- \\#Nodes denotes how many nodes in the existing taxonomy have their clicked items in user click logs.\n- CNode calculates the proportion of \\#Nodes to the $|\\mathcal{N}|$ in the existing taxonomy.\n- \\#IEdge denotes how many query-item concept pairs contain the hyponymy relations in the existing taxonomy.\n- \\#Edges denotes how many hyponymy relations in the existing taxonomy emerged in user click logs as a queryitem concept pair."
    },
    {
      "markdown": "TABLE I\nStatistics of Term Extraction.\n\n| Taxonomy | \\#Items | Existing Taxonomy |  |  |  |  |  | New Concept <br> \\#NewEdge |  |  | \\#IOthers |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  |  | \\#Nodes | CNode | \\#IEdge | \\#Edges | CEdge |  |  |  |  |  |\n| Snack | 60628252 | 19422 | 65.27 | 2021148 | 16319 | 54.15 |  | 18956 | 15492911 | 12094952 | 43114193 |\n| Fruit | 20368790 | 3032 | 62.43 | 217309 | 2563 | 51.74 |  | 2639 | 8802659 | 3970631 | 11348822 |\n| Prepared Food | 17833703 | 2835 | 68.56 | 207284 | 2498 | 59.83 |  | 2130 | 8718102 | 1702385 | 8908317 |\n\nTABLE II\nTaxonomy Statistics. $|\\mathcal{D}|$ INDICATES THE DEPTH OF EACH TAXONOMY.\n\n| Taxonomy | $|\\mathcal{D}|$ | $|\\mathcal{N}|$ | $|\\mathcal{E}|$ | $\\left\\|\\mathcal{E}_{\\text {food }}\\right\\|$ | $\\left\\|\\mathcal{E}_{\\text {Others }}\\right\\|$ |\n| :--: | :--: | :--: | :--: | :--: | :--: |\n| Overall | 16 | 352940 | 381010 | 330902 | 50308 |\n| Snack | 12 | 29758 | 30134 | 28580 | 3626 |\n| Fruits | 6 | 4857 | 4954 | 4422 | 1241 |\n| Prepared Food | 7 | 4135 | 4175 | 3586 | 1374 |\n\n- CEdge calculates the proportion of \\#Edges to the $|\\mathcal{E}|$ in the existing taxonomy.\n- \\#Concepts denotes how many new concepts are contained in clicked items.\n- \\#INewEdge denotes how many query-item concept pairs can extract new potential hyponymy relations.\n- \\#NewEdge denotes how many new query-item concept pairs can be extracted from user click logs.\n- \\#IOthers denotes how many items contain neither nodes in existing taxonomy $\\mathcal{T}$ and concepts in concepts set $\\mathcal{C}$.\n- \\#CoNewEdge calculates the count of correct hyponymy relations in extracted potential hyponymy relations.\n- Accuracy calculates the proportion of the query-item pairs which have hyponymy relations.\n\n3) Implementation Details: Given the user click logs and 448,191 manually labeled concepts on the Meituan platform from January 1, 2021, to June 1, 2021, we first automatically compute a set of metrics to demonstrate a large number of potential strong hyponymy relations in user click logs. We further identify the reasons for not covering other nodes with hyponymy relations. In terms of accuracy, we randomly sample 10 or 20 query concepts and obtain their corresponding clicked item concepts. Specifically, we take three taxonomies to manually identify the accuracy of hyponymy relationships in query-item concept pairs.\n4) Evaluation Results: Table I shows the term extraction statistics. There are tens of millions of query-item concept pairs in six months of user click records. We can see that the average coverage of nodes and edges in the existing taxonomy is $64.11 \\%$ and $57.66 \\%$, respectively, indicating that user click logs contain rich hyponymy relationships. Also, it is worth noting that our user click logs are continuously growing, and thus the number of all potential hyponymy relations in the user click logs is much larger.\n\nFor the uncovered nodes, we take the Snack domain as an example. We find that $77.00 \\%$ of them are leaf nodes, and users are not interested in $18 \\%$ (no query logs). Other domains have similar distributions as shown in Figure 3. This phenomenon is reasonable because most leaf nodes tend to have no hyponym. In addition, the part of concepts that\n![img-2.jpeg](img-2.jpeg)\n\nFig. 3. Analysis of the proportion of uncovered nodes in user click logs in Snack domain.\nusers do not ask for is not urgent in our objectives, and our approaches will take them into consideration once they appear in the user click logs.\n\nGiven a set of concepts $\\mathcal{C}$, the number of new extracted concepts in Table 1 is nearly consistent with the nodes in the existing taxonomy, and the number of new extracted edges is 10 times larger than the edges, both show that our upper bound of potential search space to expand taxonomy is sufficient. Furthermore, there still remains multi-million items that may contain potential concepts that have not yet been explored. Because the high quality and numerous concept set are provided by merchants, we first try to attach these concepts to the existing taxonomy and leave automatically extracting concepts from user click logs in the future.\n\nFor manual evaluation of accuracy, the result shown in Table IV is that the accuracy of query-item concept pairs extracted from user click is around $10 \\%$ in three different domains. Although the proportion of data noise is not tiny, it is worth noting that the coverage of correct hyponymy relations is much more important in this graph construction phase. Considering that our base of query-item concept pairs is quite large, we can extract abundant potential hyponymy relations from user click logs. We also observe that the clicked items show a long-tail distribution according to clicked frequency, in \"Bread (面包)\" case, the top five clicked frequency concepts are \"Doughnut (甜甜圈)\" (45), \"Whole-wheat Toast (全麦吐司)\" (29), \"Caterpillar Bread (毛毛虫面包)\" (24), \"Meat Floss Buns (肉松包子)\" (21) and \"Baguette (面包棒)\" (20), which are all correct hyponymy relations. The noisy concepts are generally concentrated at the end of the distribution.\n\n## B. Evaluation on Hypernymy Detection\n\n1) Automatic Evaluation: Given the three different domain taxonomies mentioned above, we construct the datasets by the self-supervised strategy described in Section 4. We show the detailed statistics of the datasets in Table III, where the proportion of positive to negative samples is $1: 1$. In the positive samples, the proportion of headwords to other words that could be detected for relations is 3:7. Meanwhile, the proportion of shuffle to replace in the negative samples is $1: 1$. Then the"
    },
    {
      "markdown": "TABLE III\nSelf-SUPPERVISED GENERATED DATASETS STATISTICS. $|\\mathcal{E}|$ INDICATES THE TOTAL NUMBER OF THE SET $\\mathcal{E}$.\n\n| Dataset | $\\left\\|\\mathcal{E}_{\\text {All }}\\right\\|$ | $\\left\\|\\mathcal{E}_{\\text {All }}\\right\\|$ |  | $\\left\\|\\mathcal{E}_{\\text {Positive }}\\right\\|$ |  | $\\left\\|\\mathcal{E}_{\\text {Negative }}\\right\\|$ |  | $\\left\\|\\mathcal{E}_{\\text {All }}\\right\\|$ |  |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  |  | $\\left\\|\\mathcal{E}_{\\text {Positive }}\\right\\|$ | $\\left\\|\\mathcal{E}_{\\text {Negative }}\\right\\|$ | $\\left\\|\\mathcal{E}_{\\text {Head }}\\right\\|$ | $\\left\\|\\mathcal{E}_{\\text {Others }}\\right\\|$ | $\\left\\|\\mathcal{E}_{\\text {Shuffle }}\\right\\|$ | $\\left\\|\\mathcal{E}_{\\text {Replace }}\\right\\|$ | $\\left\\|\\mathcal{E}_{\\text {Train }}\\right\\|$ | $\\left\\|\\mathcal{E}_{\\text {Val }}\\right\\|$ | $\\left\\|\\mathcal{E}_{\\text {Test }}\\right\\|$ |\n| Snack | 10360 | 5180 | 5180 | 1554 | 3626 | 2599 | 2581 | 6216 | 2072 | 2072 |\n| Fruits | 3546 | 1773 | 1773 | 532 | 1241 | 885 | 888 | 2127 | 709 | 710 |\n| Prepared Food | 3926 | 1963 | 1963 | 589 | 1374 | 975 | 988 | 2355 | 785 | 786 |\n\nTABLE IV\nAccuracy of Term Extraction.\n\n| Taxonomy | \\#Nodes | \\#NewEdge | Accuracy |\n| :--: | :--: | :--: | :--: |\n| Snack | 20 | 6986 | 13.18 |\n| Fruits | 10 | 10129 | 8.46 |\n| Prepared Food | 10 | 10212 | 13.00 |\n\ndatasets are divided into the training set, validation set, and test set in the proportion of $60 \\% / 20 \\% / 20 \\%$. Then, we conduct a set of experiments on the test datasets to compare our proposed method with other baselines.\n\nIn the datasets constructed by the self-supervised strategy mentioned above, we randomly sample 1000 hyponymy relations and manually annotate them for accuracy to demonstrate that the adaptively self-supervised strategy can improve the quality of the datasets. We find that the accuracy of hyponymy relations detected by headwords in the training set increases to $96.3 \\%$, while the accuracy in the existing taxonomy is $90.1 \\%$. The hyponymy relations, which can not be detected by headwords, achieve pretty high accuracy ( $94.8 \\%$ ) because their source is a professional dictionary in the taxonomy construction phase.\n2) Manual Evaluation: Compared with models' performance in self-constructed datasets, verifying their effectiveness in the real scenario is much more important. To this end, we first employ different methods to extract the appropriate hyponymy relations from query-item pairs in user click logs. We then count the number of the predicted hyponymy relations (\\#Rel) and randomly sample 1000 pairs in the Snack domain from these models, respectively. Three taxonomists are then asked to annotate these samples to calculate the precision of different models. The predicted hyponymy relation is correct when two and above taxonomists approve.\n3) Metrics: Following the previous solutions [22], we adopt these metrics as evaluation criteria.\n\n- $\\operatorname{Accuracy}(\\mathbf{A c c})$ calculates the predicted edge $\\left(e_{\\text {pred }} \\in\\right.$ $\\mathcal{E}_{\\text {pred }}$ ) exactly matches the ground truth $\\left(e_{g t} \\in \\mathcal{E}_{g t}\\right)$.\n\n$$\n\\operatorname{Acc}=\\frac{1}{k} \\sum_{i=1}^{k} \\|\\left(e_{\\text {pred }}=e_{g t}\\right)\n$$\n\n- Edge-F1 measures based on the model predicted edges $\\left(\\mathcal{E}_{\\text {pred }}\\right)$ and golden edges $\\left(\\mathcal{E}_{g t}\\right)$.\n\n$$\n\\mathrm{P}=\\frac{\\left|\\mathcal{E}_{\\text {pred }} \\cap \\mathcal{E}_{g t}\\right|}{\\left|\\mathcal{E}_{\\text {pred }}\\right|}, \\quad \\mathrm{R}=\\frac{\\left|\\mathcal{E}_{\\text {pred }} \\cap \\mathcal{E}_{g t}\\right|}{\\left|\\mathcal{E}_{g t}\\right|}\n$$\n\n- Ancestor-F1 adopts a more relax way because it extends all the ancestor-child edges as ground truth edges $\\left(\\mathcal{E}_{g t}^{*}\\right)$\nof the model predicted edges $\\left(\\mathcal{E}_{\\text {pred }}\\right)$.\n\n$$\n\\mathrm{P}=\\frac{\\left|\\mathcal{E}_{\\text {pred }} \\cap \\mathcal{E}_{g t}^{*}\\right|}{\\left|\\mathcal{E}_{\\text {pred }}\\right|}, \\quad \\mathrm{R}=\\frac{\\left|\\mathcal{E}_{\\text {pred }} \\cap \\mathcal{E}_{g t}^{*}\\right|}{\\left|\\mathcal{E}_{g t}^{*}\\right|}\n$$\n\n4) Baselines: We compare our proposed method with several baselines. It is worth noting that the search space for all the baselines is the query-item concept pairs in user behavioral data as same as ours. On the one hand, we keep this setting the same to ensure fairness. On the other hand, using the whole search space is harmful to the F1-score of all the baselines.\n\n- Random randomly attaches new concepts to the existing taxonomy.\n- KB+Headword indicates that the hyponymy relation between A and B can be retrieved from relational knowledge bases (CNDBpedia [36] and CNProbase [37]), while A is also the headword of B .\n- Snowball [34] generates patterns and extracts relational tuples from our user-generated content.\n- Substr [35] regards A as B's hypernymy if A is a substring of B (e.g., \"Bread (面包)\" and \"Fried Bread (炸面包)\").\n- Vanilla-BERT simply adopts vanilla BERT pre-trained with web-scale data to classify the hyponymy relations.\n- Distance-Parent scores the cosine distance between query concept and item concept. The distance less than the threshold is chosen as a predicted hyponymy relation.\n- Distance-Neighbor scores the cosine distance with both query concept and its children. The distance less than the threshold is chosen as a predicted hyponymy relation.\n- TaxoExpan [18] is a self-supervised method for taxonomy expansion. Its main contribution is injecting the position information to graph neural networks. We adopt BERT embedding for TaxoExpan instead of the word embeddings as in the original paper to a fair comparison.\n- TMN [23] consists of one primal and multiple auxiliary scorers to discover hyponymy relations.\n- STEAM [19] is a self-supervised method that samples mini-paths from the existing taxonomy and extracts features for query-anchor from multiple views.\n\n5) Evaluation Results: We first conduct a set of automatic evaluations on different methods as shown in Table V. Because we set a proportion of $1: 1$ to the positive and negative samples, the baseline of random is close to $50 \\%$. The performances of both KB+Headword and Snowball on accuracy are better than random. However, their Edge-F1 is hugely terrible because their precision is perfect, while their recall is only about $2 \\%$ and $10 \\%$, respectively, due to the coverage of general"
    },
    {
      "markdown": "TABLE V\nAUTOMATIC ÉVALUATION.\n\n| Method | Snack |  |  | Fruits |  |  | Prepared Food |  |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  | Acc | Edge-F1 | Ancestor-F1 | Acc | Edge-F1 | Ancestor-F1 | Acc | Edge-F1 | Ancestor-F1 |\n| Random | 50.01 | 48.24 | 49.18 | 50.09 | 48.32 | 49.13 | 49.91 | 48.14 | 49.23 |\n| KB+Headword | 51.13 | 4.20 | 4.20 | 50.90 | 3.53 | 3.53 | 50.95 | 3.71 | 3.71 |\n| Snowball [34] | 53.00 | 11.32 | 11.32 | 56.51 | 23.01 | 23.01 | 53.08 | 18.18 | 18.18 |\n| Substr [35] | 60.65 | 61.28 | 68.01 | 60.48 | 62.47 | 67.43 | 62.47 | 63.57 | 67.32 |\n| Distance-Parent | 57.46 | 50.94 | 56.64 | 58.00 | 50.39 | 57.71 | 58.61 | 52.65 | 56.31 |\n| Distance-Neighbor | 60.19 | 53.39 | 59.83 | 60.60 | 53.62 | 60.74 | 61.24 | 56.38 | 61.41 |\n| Vanilla-BERT | 66.68 | 50.57 | 65.11 | 66.14 | 48.91 | 64.25 | 60.14 | 51.25 | 66.28 |\n| TaxoExpan [18] | 59.54 | 48.26 | 60.96 | 57.34 | 50.45 | 63.48 | 56.36 | 50.79 | 65.41 |\n| TMN [23] | 58.71 | 47.33 | 62.50 | 58.64 | 49.38 | 63.21 | 57.38 | 51.19 | 67.42 |\n| STEAM [19] | 60.33 | 53.48 | 68.84 | 60.51 | 54.17 | 71.76 | 61.66 | 54.86 | 70.71 |\n| Ours | 75.64 | 78.59 | 83.61 | 77.58 | 80.64 | 88.64 | 71.53 | 73.45 | 80.62 |\n\nTABLE VI\nAblATION STUDY OF RELATIONAL REPRESENTATION (R) AND STRUCTURAL REPRESENTATION ( $\\mathrm{S}_{\\text {Random }}$ AND $\\mathrm{S}_{\\text {C-BERT }}$ ).\n\n| Representation | Snack |  |  | Fruits |  |  | Prepared Food |  |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  | Acc | Edge-F1 | Ancestor-F1 | Acc | Edge-F1 | Ancestor-F1 | Acc | Edge-F1 | Ancestor-F1 |\n| $\\mathrm{S}_{\\text {Random }}$ | 57.05 | 50.02 | 67.18 | 58.34 | 56.63 | 71.56 | 57.36 | 52.53 | 64.53 |\n| $\\mathrm{~S}_{\\text {C-BERT }}$ | 57.89 | 50.43 | 67.91 | 58.48 | 57.91 | 72.34 | 58.18 | 53.39 | 65.71 |\n| R | 63.42 | 63.34 | 76.66 | 63.64 | 60.34 | 76.63 | 64.01 | 61.45 | 68.36 |\n| Overall | 75.64 | 78.59 | 83.61 | 76.35 | 79.69 | 84.34 | 71.53 | 73.45 | 80.62 |\n\nknowledge bases and constrained patterns. By contrast, Substr performs better, indicating that the headword is an essential feature in determining hyponymy relations. We observe that introducing children nodes brings remarkable improvement towards distance-based methods. This phenomenon proves that the children nodes can be considered complements to concepts' semantics. As for vanilla BERT, the result indicates that BERT performs much better on negative samples than positive samples. For three state-of-the-art methods, TaxoExpan and TMN, have comparable performances which underperform STEAM on all three datasets. The major drawback of TaxoExpan is that it only relies on the signal of propagation among neighbors in the taxonomy via graph neural networks, which are not sufficient. The primal and auxiliary scorers in TMN are limited to extracting various features to model hyponymy relations. STEAM achieves the most robust overall performance proves the mini-path-based prediction and the multi-view co-training designs are practical. Our proposed approach outperforms all baselines by a large margin on all three datasets, suggesting that the knowledge of domain relationships and structural information in user behavioral information is necessary.\n\nTABLE VII\nMANUAL EVALUATION.\n\n| Method | Snack | \\#Rel <br> Fruits | Prepared Food | Pre |\n| :--: | :--: | :--: | :--: | :--: |\n| Distance-Neighbor | 74583 | 14964 | 19583 | 80.3 |\n| TaxoExpan [18] | 1789554 | 80985 | 56981 | 72.3 |\n| STEAM [19] | 132453 | 658432 | 348595 | 76.3 |\n| Ours | 63819 | 13448 | 17431 | 88.0 |\n\nFor manual evaluation, as shown in Table VII, we care about the model precision of different models. Because in the real scenario, we mainly collect the positive relations to\nexpand the existing taxonomy while considering both positive and negative relations in self-constructed datasets. We find that the total number of predicted hyponymy relations of TaxoExpan and STEAM is large. However, their accuracy is much lower, significantly reducing the quality of the existing taxonomy. Our proposed method has a similar total number to Distance-Neighbor, and about 8 absolute points improve the performance in accuracy. In conclusion, our method can enlarge the size of real-world product taxonomies from 39,263 to 94,698 with $88 \\%$ precision.\n\n## C. Framework Analysis\n\n1) Feature Ablation: We detect the effectiveness of each representation respectively as shown in Table VI. $\\mathrm{S}_{\\text {Random }}$ represents only using structural representation initialized with random embedding, while $\\mathrm{S}_{\\text {C-BERT }}$ represents only using structural representation initialized with C-BERT embedding. The performance of $\\mathrm{S}_{\\text {C-BERT }}$ is slightly better than $\\mathrm{S}_{\\text {Random }}$, which means that the representations of C-BERT contain helpful information of concepts. Only using structural representation ( $\\mathrm{S}_{\\text {Random }}$ and $\\mathrm{S}_{\\text {C-BERT }}$ ) performs not well to identify the hyponymy relations while relational representation (R) works much better. The former indicates that the structure information in the graph does not suffice, and the latter can show that the pre-trained language model indeed captures in-domain relational knowledge. However, despite the bad performance of structural representation ( $\\mathrm{S}_{\\text {Random }}$ and $\\mathrm{S}_{\\text {C-BERT }}$ ), combining relational representation (R) with it can bring 5.90 absolute improvements in Accuracy and 7.33 in Edge-F1. This phenomenon strongly indicates that the two features can capture different information and are complementary.\n2) Relational Representation Ablation: We further conduct a series of ablation studies to detect the contributions of"
    },
    {
      "markdown": "TABLE VIII\nAblation STUDY OF VARIOUS DESIGN CHOICES.\n\n| Representation | Model | Snack |  |  | Fruits |  |  | Prepared Food |  |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  |  | Acc | Edge-F1 | Ancestor-F1 | Acc | Edge-F1 | Ancestor-F1 | Acc | Edge-F1 | Ancestor-F1 |\n|  | Overall | 75.64 | 78.59 | 83.61 | 76.35 | 79.69 | 84.34 | 71.53 | 73.45 | 80.62 |\n| Relational | - Template | 75.01 | 77.59 | 82.75 | 75.57 | 78.12 | 82.35 | 70.58 | 72.53 | 79.51 |\n|  | - Finetune | 73.45 | 76.58 | 81.34 | 73.53 | 75.12 | 78.53 | 68.53 | 68.89 | 74.24 |\n|  | - Concept-level Masking | 63.34 | 58.42 | 65.26 | 68.53 | 61.46 | 69.54 | 62.36 | 57.74 | 66.36 |\n| Structural | - Edge Attribute | 74.36 | 74.38 | 82.15 | 74.32 | 76.53 | 77.57 | 70.53 | 72.53 | 79.42 |\n|  | - User Click Graph | 70.34 | 71.23 | 79.35 | 72.75 | 63.64 | 65.89 | 70.16 | 70.26 | 73.14 |\n|  | - Contrastive Learning | 71.59 | 64.12 | 72.43 | 74.73 | 63.24 | 77.57 | 70.48 | 68.12 | 78.25 |\n|  | - Position Embedding | 71.93 | 54.72 | 73.84 | 73.02 | 56.42 | 71.59 | 68.19 | 63.57 | 70.92 |\n\nTABLE IX\nTHE INFLUENCE OF DIFFERENT VARIANTS IN GRAPH NEURAL NETWORK AND CONTRASTIVE LEARNING ON SNACK DATASET.\n\n| Design Choice |  | Snack |  |  |\n| :--: | :--: | :--: | :--: | :--: |\n|  |  | Acc | Edge-F1 | Ancestor-F1 |\n| Graph Neural Network |  |  |  |  |\n| Neighbors | One-hop | 75.64 | 78.59 | 83.61 |\n|  | Two-hop | 70.18 | 72.41 | 94.32 |\n| Aggregation | GCN [32] | 75.64 | 78.59 | 83.61 |\n|  | GAT [38] | 74.16 | 72.72 | 78.59 |\n|  | GraphSAGE [39] | 72.86 | 71.77 | 76.92 |\n| Contrastive Learning |  |  |  |  |\n| Negative Rate | 0.8 | 74.15 | 73.59 | 82.11 |\n|  | 1.0 | 73.82 | 74.61 | 80.32 |\n|  | 1.2 | 75.64 | 78.59 | 83.61 |\n|  | 1.5 | 71.96 | 72.33 | 78.41 |\n|  | 2.0 | 63.28 | 69.65 | 70.82 |\n\ndifferent components in both structural and relational representations as shown in Table VIII. We remove only one component and keep others the same to detect their corresponding contribution to controlling variables. Firstly, we examine the effectiveness of different design choices in our relational representation to capture relational knowledge automatically. The template does not have a massive effect on the model performance, and we find that it mainly contributes to distinguishing the correct order of two concepts. This phenomenon partly accounts that the representation in BERT already captures the relational knowledge but neglects the relative position knowledge. Fine-tuning on training datasets working well for our task means introducing additional relational knowledge in the fine-tuning phase. Injecting domain knowledge through concept-level masking strategy into a general pretrained language model improves model performance. This phenomenon shows that, on the one hand, there exists a vast knowledge gap between the general domain and specific domain; on the other hand, concept-level is better than token-level to handle the concept-level task.\n3) Structural Representation Ablation: For the structural representation shown in Table VIII, it is interesting to note that performance degradation is more pronounced than in the relational representations. More precisely, edge weights slightly contribute to model performance, demonstrating that higher frequency concepts play a more important role in structural representation. However, the most likely reason it\ndoes not work as expected is that the edge weights are not used as powerful features to facilitate prediction directly but as a weight matrix to propagate the representation. The information on user behavior contained in the user click graph can complement the lack of structural representation in existing taxonomies. The pre-training phase of contrastive learning brings a slight improvement in accuracy but a considerable improvement in Edge-F1, which suggests that it helps extract more positive hyponymy relationships. Meanwhile, expanding the distance between the forward and reverse samples is vital for model differentiation. Furthermore, considering that there is no relative positional information in the undirected graph in the setting of graphical convolutional networks, the importance of replenishing positional embedding for identifying hyponymy relations is self-evident.\n\nWe further explore the influence of different variants in graph neural networks and contrastive learning on the Snack dataset as an example. As shown in Table IX, one-hop relations (i.e., parents and children) is better than two-hop relations (i.e., grandparents and siblings) in both Accuracy and Edge-F1. The better performance in Ancestor-F1 of two-hop is reasonable because the primary concern metric to our proposed method is Edge-F1, and we especially pull away from the ancestors from anchor nodes. Two-hop relations reconsider the information from its grandparents and siblings, which boosts Ancestor-F1 but damages the performance in Edge-F1. For the aggregation function, we attempt two other typical graph neural networks, Graph attention network (GAT) [38] and GraphSAGE [39]. Graph attention network performs better than GraphSAGE, indicating that learning the weight by attention mechanism is helpful to predict hyponymy relations. The graph convolutional network with customized weights calculated from user behavior information achieves the best performance.\n\nThe results about contrastive learning in Table IX show that with different negative rates, which is the ratio of positive and negative samples, the model achieves the best result when the rate is 1.2 . It is worth noting that the performances as the ratios varying from 0.8 to 2.0 are still better than all the other baselines to prove the robustness of our method.\n4) Analysis of Self-supervision: In this part, we compare the influence of our adaptively self-supervised generation strategy (Ours) to model performance with a self-supervised setting in previous studies (Previous). We construct datasets from the"
    },
    {
      "markdown": "TABLE X\nCASE STUDY. BOLD IN CLICKED ITEM EXAMPLES INDICATE THE CORRECT CONCEPTS CONTAINED IN THE CLICKED ITEM NAMES. ✓AND ✗ PRESENT THE RESULTS OF HUMAN EVALUATIONS.\n\n| Query Concept | Bread (面包) | Watermelon (西瓜) | Coarse Cereals (杂粮) |\n| :--: | :--: | :--: | :--: |\n| Domain | Snack | Fruits | Prepared Food |\n| Clicked <br> Item <br> Examples | Croissant/bag (牛角包/袋) <br> Various Toasts (各式吐司) <br> Creamy Bread (奶霜面包) <br> Golden Carrot Cake Bread - 6 <br> in a bag (黄金萝卜饼面包-6个筒) <br> Turkey Black Sesame Bread - 4 <br> flavors (土耳其黑芝麻面包-4个口味) | Half A-level Hainan Sweet Kirin Melon (海南冰糖麒麟瓜A级-半个) <br> Delicious Heart-shaped Watermelon (好吃的心形西瓜) <br> Peeled and Diced Watermelon - about 500 g per box (去皮切块西瓜-约500克盒) <br> Iced Watermelon - 750 ml (冰镇西瓜-750ml) | Coarse Grains Oybeans 250 g (杂粮黄豆 250 g ) <br> Nutritious Oatmeal (营养燕麦片) <br> Bulk Adzuki Beans (散装赤小豆) <br> About half a kilo of Original Roasted Sweet Potato (原味烤山芋一斤左右一个) |\n| Hyponym <br> Relation <br> Prediction | ![img-3.jpeg](img-3.jpeg) | Kirin Melon (麒麟瓜) ✓ <br> Heart-shaped Watermelon (心形西瓜) ✓ <br> Watermelon Chunks (切块西瓜) ✓ <br> Iced Watermelon (冰镇西瓜) $\\boldsymbol{\\checkmark}$ | Soybeans (黄豆) $\\checkmark$ <br> Oatmeal (燕麦片) $\\checkmark$ <br> Adzuki Beans (赤小豆) $\\checkmark$ <br> Sweet Potatoes (山芋) $\\checkmark$ <br> Rice (大米) $\\checkmark$ |\n| Negative | Big Fried Dumpling (大锅贴) $\\checkmark$ <br> Lava Dark Chocolate <br> (细豆黑巧克力) $\\checkmark$ <br> Sweet Glutinous Rice Balls <br> (甜汤圆) $\\checkmark$ <br> Turnip Pancakes (萝卜煎饼) $\\boldsymbol{X}$ | Watermelon Sundae (西瓜圣代) $\\checkmark$ <br> Cantaloupe Sundae (哈密瓜圣代) $\\checkmark$ <br> Fruit Sundae (水果圣代) $\\checkmark$ <br> Lily Crisp (百合酵) $\\checkmark$ <br> Cold and dressed Sprout (凉拌芽菜) $\\checkmark$ | Original Toast Slices <br> (原味吐司片) $\\checkmark$ <br> Pickled Minced Vegetables <br> (碎米芽菜) $\\checkmark$ <br> Black Bean Sprouts <br> (黑豆芽) $\\checkmark$ |\n\nTABLE XI\nSELF-SUPERVISED GENERATED DATASET STATISTICS.\n\n| Method | $\\|E_{\\text {Head }} \\mid$ | $\\|E_{\\text {Others }} \\mid$ | $\\|E_{\\text {Train }} \\mid$ | $\\|E_{\\text {Val }} \\mid$ | $\\|E_{\\text {Test }} \\mid$ |\n| :--: | :--: | :--: | :--: | :--: | :--: |\n| Previous | 28580 | 3626 | 36161 | 12034 | 12073 |\n| Ours | 1554 | 3626 | 6216 | 2072 | 2072 |\n\n![img-4.jpeg](img-4.jpeg)\n\nFig. 4. The accuracy of two settings on positive samples.\nwhole taxonomy in the Snack domain and keep other settings the same as ours. The statistics of the two datasets are shown in Table XI. Considering our task targets extracting correct hyponymy relations, we analyze the accuracy of two settings on positive samples. As shown in Figure 4, the previous setting achieves higher accuracy than ours on overall positive samples. However, we observe that this accuracy is inflated because the hyponymy relations, which can be detected by headword, is nearly $100 \\%$ but only $39.40 \\%$ on others. Our setting can perform well on both relations with $99.94 \\%$ and $96.28 \\%$ accuracy, respectively.\n\nWe further compare the proportion of two types of predicted\n\nTABLE XII\nProportion of Predicted HYponymy Relations.\n\n| Method | $\\mathcal{E}_{\\text {All }}$ | $\\mathcal{E}_{\\text {Head }}$ | $\\mathcal{E}_{\\text {Others }}$ |\n| :--: | :--: | :--: | :--: |\n| Previous | 17385 | 17323 | 61 |\n| Ours | 63819 | 61624 | 2195 |\n\nhyponymy relations from user click logs in both settings as shown in Table XII. Notably, the previous setting predicted fewer total hyponymy relations than ours, and the proportion of other relations to all relations was $0.3 \\%$, much lower than our $3 \\%$. This phenomenon suggests that the previous setup suffers from data skews and overfitting problems, while our setup can alleviate both problems to some extent.\n\n## D. Case Studies\n\nWe can retrieve the corresponding clicked items from the users' click logs given the query concept. Some examples of clicked items are listed in the second row of Table X. After extracting the item concepts from the clicked items, our model will identify a hyponym relationship between the query concept and each item concept. The last row of Table X shows the prediction results for our selected cases.\n\nThe selected cases prove that our model is good at predicting hyponym relations. Here we take the query concept \"Bread (面包)\" as an example. Although the concept \"Toast (吐司)\" does not contain the headword \"Bread (面包)\", our model can still identify the hyponym relationship between them. However, our model still needs improvement, especially for concepts that do not contain headwords. The negative samples in the last row of Table X show that our model sometimes"
    },
    {
      "markdown": "incorrectly classifies concepts without headwords as hyponym of query concepts, such as \"Turnip Pancakes (夢卜照饼)\".\n\nIn addition, the selected cases also show that the classification granularity of our model is not satisfactory enough. For example, our model determines that \"Turkey Black Sesame Bread (土耳其黑芝麻面包)\" is a positive sample because it contains the headword \"Bread (面包)\". However, it is more suitable to be regarded as a hyponym of \"Black Sesame Bread (黑芝麻面包)\" rather than \"Bread (面包)\".\n\n## E. Offline User Study of Query Rewriting for Searching\n\nFollowing [9], we have conducted an offline user study to evaluate how hyponym relations can help improve the search engine through query rewriting. Our evaluation dataset consists of 100 queries selected from the Meituan take-out application, which is the largest take-out search engine in China. We rewrite each query $q$ with its hypernym $h$. Moreover, we also collect the top 10 search results returned by the Meituan application for each query.\n\nAfter collecting the search results, we ask three human judges to evaluate the relevance of the search results in the Meituan take-out search engine. For each search result, we recorded the majority vote of \"relevant\" or \"not relevant\" to calculate the percentage of relevant search results for the original query and the rewritten query, respectively. Our evaluation results show that the occurrences increase from $74 \\%$ to $80 \\%$ after rewriting the query because search engines do not recognize and understand most fine-grained concepts. To address this issue, our product taxonomy can help provide hypernym queries appropriately to expand the recall of search results and better match the users' intention.\n\n## V. RELATED WORK\n\n## A. Taxonomy Construction\n\nRecent studies related to taxonomy mainly focus on taxonomy construction from scratch. According to their differences in the hyponymy detection stage, existing methods can be divided into two categories: (1) pattern-based methods [25], [40]-[44] which leverage lexical-syntactic patterns to extract hyponymy relations between the co-occurrence of term pairs; (2) distributional methods [12], [45]-[52] which calculate pairwise similarity based on term embeddings to predict the hyponymy relations. Besides, some methods utilize advanced techniques such as transfer learning [53], reinforcement learning [54] and entity set expansion techniques [55], [56] to adaptively or incrementally construct a taxonomy.\n\n## B. Taxonomy Expansion\n\nMost existing works have designed features to capture abundant representations of concepts. Aly et al. [15] adopt hyperbolic embedding to capture hierarchical lexical-semantic relations. Fanceglia et al. [14] use a hybrid method to combine linguistic patterns, semantic web, and neural network for taxonomy expansion. Manzoor et al. [17] model the implicit edge semantics to score the hyponymy relevance between node pairs. To better maintain the structure of the existing\ntaxonomy, Shen et al. [18] propose position-enhanced graph neural networks to encode the relative position of terms and improve the overall quality of taxonomy. Song et al. [22] design a concept sorting model to extract hyponymy relations and sort their insertion order by utilizing the relationship between the newly mined concepts. Wang et al. [57] utilize the hierarchical information of the existing taxonomy by extracting tree-exclusive features in the taxonomy for better taxonomy coherence. One limitation of these approaches is that they mainly focus on the general-purpose taxonomies or utilize the general text corpora. Thus, they cannot be easily generalized to specific taxonomies. Mao et al. [16] leverage heterogeneous sources of signals such as lexical semantics and structural information to train an end-to-end online catalog taxonomy enrichment model. Compared with these methods, our proposed method designs relational and structural representations learned from user-generated content and user click logs to model the semantics of in-domain concepts.\n\nPrior studies like [58], [59] require manual training data to learn features. Self-supervised constructing training set from existing taxonomy is a common strategy considered to address this problem in recent works [16], [18], [19], [23]. In our work, we further propose an adaptively self-supervised generation strategy to avoid inheriting the adverse problems in the existing taxonomy.\n\n## VI. CONCLUSION\n\nIn this paper, we propose an adaptively self-supervised user behavior-oriented product taxonomy expansion framework. The user behavior information allows our model to learn the domain-specific relational and structural representations while matching the users' intention and cognition. The adaptively self-supervised generation strategy can construct a high-quality and balanced training dataset that avoids inheriting problems in the existing taxonomy. Comprehensive experiments conducted on three real-world product taxonomies have shown that the results achieved by our proposed framework improve considerably over state-of-the-art both in automatic and manual evaluations. We observe that much other information can be incorporated into the model, such as image and merchant information. In the future, we will further explore other means to determine the problematic cases which need commonsense knowledge or domain knowledge.\n\n## ACKNOWLEDGMENT\n\nThe authors would like to thank anonymous reviews for their helpful comments. Furthermore, we also thank Juntao Liu, Huaming Wang, and jingping Liu for their insightful discussions; Qianyu He for feedback on related work; Yumeng Shen for annotation; Zongyu Wang, Junjie Fu and Huimin Xu in Meituan team for their supports in experimental data. This work is supported by National Key Research and Development Project (No. 2020AAA0109302), Shanghai Science and Technology Innovation Action Plan (No.19511120400), and Shanghai Municipal Science and Technology Major Project (No.2021SHZDZX0103)."
    },
    {
      "markdown": "## REFERENCES\n\n[1] G. A. Miller, \"Wordnet: a lexical database for english,\" Communications of the ACM, vol. 38, no. 11, pp. 39-41, 1995.\n[2] C. E. Lipscomb, \"Medical subject headings (mesh),\" Bulletin of the Medical Library Association, vol. 88, no. 3, p. 265, 2000.\n[3] X. L. Dong, X. He, A. Kan, X. Li, Y. Liang, J. Ma, Y. E. Xu, C. Zhang, T. Zhao, G. Blanco Saldana et al., \"Autoknow: Self-driving knowledge collection for products of thousands of types,\" in Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \\& Data Mining, 2020, pp. 2724-2734.\n[4] G. Karamanolakis, J. Ma, and X. L. Dong, \"Txtract: Taxonomyaware knowledge extraction for thousands of product categories,\" arXiv preprint arXiv:2004.13852, 2020.\n[5] J. Huang, Z. Ren, W. X. Zhao, G. He, J.-R. Wen, and D. Dong, \"Taxonomy-aware multi-hop reasoning networks for sequential recommendation,\" in Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, 2019, pp. 573-581.\n[6] Y. Zhang, A. Ahmed, V. Josifovski, and A. Smola, \"Taxonomy discovery for personalized recommendation,\" in Proceedings of the 7th ACM international conference on Web search and data mining, 2014, pp. 243252.\n[7] C. Yang, J. Zhang, and J. Han, \"Co-embedding network nodes and hierarchical labels with taxonomy based generative adversarial networks.\" ICDM, 2020.\n[8] W. Hua, Z. Wang, H. Wang, K. Zheng, and X. Zhou, \"Understand short texts by harvesting and analyzing semantic knowledge,\" IEEE transactions on Knowledge and data Engineering, vol. 29, no. 3, pp. 499-512, 2016.\n[9] B. Liu, W. Guo, D. Niu, C. Wang, S. Xu, J. Lin, K. Lai, and Y. Xu, \"A user-centered concept mining system for query and document understanding at tencent,\" in Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \\& Data Mining, 2019, pp. 1831-1841.\n[10] B. Liu, W. Guo, D. Niu, J. Luo, C. Wang, Z. Wen, and Y. Xu, \"Giant: scalable creation of a web-scale ontology,\" in Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data, 2020, pp. 393-409.\n[11] H. Peng, J. Li, S. Wang, L. Wang, Q. Gong, R. Yang, B. Li, P. Yu, and L. He, \"Hierarchical taxonomy-aware and attentional graph capsule rcms for large-scale multi-label text classification,\" IEEE Transactions on Knowledge and Data Engineering, 2019.\n[12] J. Shen, Z. Wu, D. Lei, C. Zhang, X. Ren, M. T. Vanni, B. M. Sadler, and J. Han, \"Hixspan: Task-guided taxonomy construction by hierarchical tree expansion,\" in Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \\& Data Mining, 2018, pp. 21802189.\n[13] N. Vedula, P. K. Nicholson, D. Ajwani, S. Dutta, A. Sala, and S. Parthasarathy, \"Enriching taxonomies with functional domain knowledge,\" in The 41st International ACM SIGIR Conference on Research \\& Development in Information Retrieval, 2018, pp. 745-754.\n[14] N. R. Fanceglia, A. Gliozzo, S. Dash, M. F. M. Chowdhury, and N. Mihindukulasovitya, \"Automatic taxonomy induction and expansion,\" in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations, 2019, pp. 25-30.\n[15] R. Aly, S. Acharya, A. Ossa, A. Köhn, C. Biemann, and A. Panchenko, \"Every child should have parents: a taxonomy refinement algorithm based on hyperbolic term embeddings,\" arXiv preprint arXiv:1906.02002, 2019.\n[16] Y. Mao, T. Zhao, A. Kan, C. Zhang, X. L. Dong, C. Faloutsos, and J. Han, \"Octet: Online catalog taxonomy enrichment with selfsupervision,\" in Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \\& Data Mining, 2020, pp. 22472257.\n[17] E. Manzoor, R. Li, D. Shrouty, and J. Leskovec, \"Expanding taxonomies with implicit edge semantics,\" in Proceedings of The Web Conference 2020, 2020, pp. 2044-2054.\n[18] J. Shen, Z. Shen, C. Xiong, C. Wang, K. Wang, and J. Han, \"Taxoexpan: self-supervised taxonomy expansion with position-enhanced graph neural network,\" in Proceedings of The Web Conference 2020, 2020, pp. 486-497.\n[19] Y. Yu, Y. Li, J. Shen, H. Feng, J. Sun, and C. Zhang, \"Steam: Selfsupervised taxonomy expansion with mini-paths,\" in Proceedings of the\n\n26th ACM SIGKDD International Conference on Knowledge Discovery \\& Data Mining, 2020, pp. 1026-1035.\n[20] M. D. Ma, M. Chen, T.-L. Wu, and N. Peng, \"Hyperexpan: Taxonomy expansion with hyperbolic representation learning,\" arXiv preprint arXiv:2109.10500, 2021.\n[21] X. Luo, L. Liu, Y. Yang, L. Bo, Y. Cao, J. Wu, Q. Li, K. Yang, and K. Q. Zhu, \"Alicoco: Alibaba e-commerce cognitive concept net,\" in Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data, 2020, pp. 313-327.\n[22] X. Song, J. Shen, J. Zhang, and J. Han, \"Who should go first? a selfsupervised concept sorting model for improving taxonomy expansion,\" arXiv preprint arXiv:2104.03682, 2021.\n[23] J. Zhang, X. Song, Y. Zeng, J. Chen, J. Shen, Y. Mao, and L. Li, \"Taxonomy completion via triplet matching network,\" arXiv preprint arXiv:2101.01896, 2021.\n[24] J. Ramos et al., \"Using tf-idf to determine word relevance in document queries,\" in Proceedings of the first instructional conference on machine learning, vol. 242, no. 1. Citeseer, 2003, pp. 29-48.\n[25] M. A. Hearst, \"Automatic acquisition of hyponyms from large text corpora,\" in Coling 1992 volume 2: The 15th international conference on computational linguistics, 1992.\n[26] S. Roller, D. Kiela, and M. Nickel, \"Hearst patterns revisited: Automatic hypernym detection from large text corpora,\" arXiv preprint arXiv:1806.03191, 2018.\n[27] Y. Cui, W. Che, T. Liu, B. Qin, Z. Yang, S. Wang, and G. Hu, \"Pretraining with whole word masking for chinese bert,\" arXiv preprint arXiv:1906.08101, 2019.\n[28] C. Chen, K. Lin, and D. Klein, \"Inducing taxonomic knowledge from pretrained transformers,\" arXiv preprint arXiv:2010.12813, 2020.\n[29] J. Qiu, Q. Chen, Y. Dong, J. Zhang, H. Yang, M. Ding, K. Wang, and J. Tang, \"Gcc: Graph contrastive coding for graph neural network pre-training,\" in Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \\& Data Mining, 2020, pp. 11501160.\n[30] Y. You, T. Chen, Y. Sui, T. Chen, Z. Wang, and Y. Shen, \"Graph contrastive learning with augmentations,\" Advances in Neural Information Processing Systems, vol. 33, 2020.\n[31] A. v. d. Oord, Y. Li, and O. Vinyals, \"Representation learning with contrastive predictive coding,\" arXiv preprint arXiv:1807.03748, 2018.\n[32] T. N. Kipf and M. Welling, \"Semi-supervised classification with graph convolutional networks,\" arXiv preprint arXiv:1609.02907, 2016.\n[33] E. T. K. Sang, \"Extracting hypernym pairs from the web,\" in Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, 2007, pp. 165-168.\n[34] E. Agicbtein and L. Gravano, \"Snowball: Extracting relations from large plain-text collections,\" in Proceedings of the fifth ACM conference on Digital libraries, 2000, pp. 85-94.\n[35] G. Bordea, E. Lefever, and P. Buitelaar, \"Semeval-2016 task 13: Taxonomy extraction evaluation (texeval-2),\" in Proceedings of the 10th international workshop on semantic evaluation (semeval-2016), 2016, pp. 1081-1091.\n[36] B. Xu, Y. Xu, J. Liang, C. Xie, B. Liang, W. Cui, and Y. Xiao, \"Cndbpedia: A never-ending chinese knowledge extraction system,\" in International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems. Springer, 2017, pp. 428-438.\n[37] J. Chen, A. Wang, J. Chen, Y. Xiao, Z. Chu, J. Liu, J. Liang, and W. Wang, \"Cn-probase: a data-driven approach for large-scale chinese taxonomy construction,\" in 2019 IEEE 35th International Conference on Data Engineering (ICDE). IEEE, 2019, pp. 1706-1709.\n[38] P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio, \"Graph attention networks,\" arXiv preprint arXiv:1710.10903, 2017.\n[39] W. L. Hamilton, R. Ying, and J. Leskovec, \"Inductive representation learning on large graphs,\" in Proceedings of the 31st International Conference on Neural Information Processing Systems, 2017, pp. 10251035.\n[40] Z. Kozareva and E. Hovy, \"A semi-supervised method to learn and construct taxonomies using the web,\" in Proceedings of the 2010 conference on empirical methods in natural language processing, 2010, pp. 1110-1118.\n[41] N. Nakashole, G. Weikum, and F. Suchanek, \"Patty: A taxonomy of relational patterns with semantic types,\" in Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, 2012, pp. 1135-1145."
    },
    {
      "markdown": "[42] A. Panchenko, S. Faralli, E. Ruppert, S. Remus, H. Naets, C. Fairon, S. P. Ponzetto, and C. Biemann, \"Taxi at semeval-2016 task 13: a taxonomy induction method based on lexico-syntactic patterns, substrings and focused crawling,\" in Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016), 2016, pp. 1320-1327.\n[43] R. Snow, D. Jurafsky, and A. Y. Ng, \"Learning syntactic patterns for automatic hypernym discovery,\" Advances in Neural Information Processing Systems 17, 2004.\n[44] M. Jiang, J. Shang, T. Cassidy, X. Ren, L. M. Kaplan, T. P. Hanratty, and J. Han, \"Metapad: Meta pattern discovery from massive text corpora,\" in Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2017, pp. 877-886.\n[45] D. Lin et al., \"An information-theoretic definition of similarity.\" in Icml, vol. 98, no. 1998, 1998, pp. 296-304.\n[46] R. Fu, J. Guo, B. Qin, W. Che, H. Wang, and T. Liu, \"Learning semantic hierarchies via word embeddings,\" in Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2014, pp. 1199-1209.\n[47] L. Rimell, \"Distributional lexical entailment by topic coherence,\" in Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, 2014, pp. 511-519.\n[48] V. Shwartz, Y. Goldberg, and I. Dagan, \"Improving hypernymy detection with an integrated path-based and distributional method,\" arXiv preprint arXiv:1603.06076, 2016.\n[49] A. T. Luu, Y. Tay, S. C. Hui, and S. K. Ng, \"Learning term embeddings for taxonomic relation identification using dynamic weighting neural network,\" in Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, 2016, pp. 403-413.\n[50] Z. Yu, H. Wang, X. Lin, and M. Wang, \"Learning term embeddings for hypernymy identification,\" in Twenty-Fourth International Joint Conference on Artificial Intelligence, 2015.\n[51] A. Cocos, M. Apidianaki, and C. Callison-Burch, \"Comparing constraints for taxonomic organization,\" in Proceedings of the 2018 Con-\nference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), 2018, pp. 323-333.\n[52] G. Bernier-Colborne and C. Barriere, \"Crim at semeval-2018 task 9: A hybrid approach to hypernym discovery,\" in Proceedings of the 12th international workshop on semantic evaluation, 2018, pp. 725-731.\n[53] C. Shang, S. Dash, M. F. M. Chowdhury, N. Mihindukulassooriya, and A. Gliozzo, \"Taxonomy construction of unseen domains via graph-based cross-domain knowledge transfer,\" in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020, pp. 2198-2208.\n[54] Y. Mao, X. Ren, J. Shen, X. Gu, and J. Han, \"End-to-end reinforcement learning for automatic taxonomy induction,\" arXiv preprint arXiv:1805.04044, 2018.\n[55] J. Shen, Z. Wu, D. Lei, J. Shang, X. Ren, and J. Han, \"Setexpan: Corpusbased set expansion via context feature selection and rank ensemble,\" in Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 2017, pp. 288-304.\n[56] X. Zhang, Y. Chen, J. Chen, X. Du, K. Wang, and J.-R. Wen, \"Entity set expansion via knowledge graphs,\" in Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2017, pp. 1101-1104.\n[57] S. Wang, R. Zhao, X. Chen, Y. Zheng, and B. Liu, \"Enquire one's parent and child before decision: Fully exploit hierarchical structure for self-supervised taxonomy expansion,\" arXiv preprint arXiv:2101.11268, 2021.\n[58] D. Jurgens and M. T. Pilehvar, \"Semeval-2016 task 14: Semantic taxonomy enrichment,\" in Proceedings of the 10th international workshop on semantic evaluation (SemEval-2016), 2016, pp. 1092-1102.\n[59] M. Schlichtkrull and H. M. Alonso, \"Msejrku at semeval-2016 task 14: Taxonomy enrichment by evidence ranking,\" in Proceedings of the 10th international workshop on semantic evaluation (SemEval-2016), 2016, pp. 1337-1341."
    }
  ],
  "usage_info": {
    "pages_processed": 14,
    "doc_size_bytes": 1152851
  },
  "_metadata": {
    "model_version": "0.0.0",
    "llm_model": "mistral-ocr-2505",
    "query_data": {
      "pdf": "/Users/satyaortiz-gagne/CODE/paperext/data/cache/fulltext/9ecbf96a3cab60b06cc6900041130bfd/fulltext.pdf"
    },
    "model_id": "parsepdf"
  }
}