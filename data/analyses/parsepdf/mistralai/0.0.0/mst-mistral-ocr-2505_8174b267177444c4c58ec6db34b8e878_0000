{
  "pages": [
    {
      "markdown": "# Bayesian Latent Multi-State Modeling for Non-Equidistant Longitudinal Electronic Health Records \n\nYu Luo ${ }^{1, *}$, David A. Stephens ${ }^{1, * *}$, Aman Verma ${ }^{2, * * *}$, David L. Buckeridge ${ }^{2, * * * *}$<br>${ }^{1}$ Department of Mathematics and Statistics<br>${ }^{2}$ Department of Epidemiology, Biostatistics and Occupational Health<br>McGill University, Quebec, Canada<br>*email: yu.t.luo@mail.mcgill.ca<br>**email: david.stephens@mcgill.ca<br>***email: aman.verma.mtl@gmail.com<br>****email: david.buckeridge@mcgill.ca\n\nSummary: Large amounts of longitudinal health records are now available for dynamic monitoring of the underlying processes governing the observations. However, the health status progression across time is not typically observed directly: records are observed only when a subject interacts with the system, yielding irregular and often sparse observations. This suggests that the observed trajectories should be modeled via a latent continuous-time process potentially as a function of time-varying covariates. We develop a continuous-time hidden Markov model to analyze longitudinal data accounting for irregular visits and different types of observations. By employing a specific missing data likelihood formulation we can construct an efficient computational algorithm. We focus on Bayesian inference for the model: this is facilitated by an expectation-maximization algorithm and Markov chain Monte Carlo methods. Simulation studies demonstrate that these approaches can be implemented efficiently for large data sets in a fully Bayesian setting. We apply this model to a real cohort where patients suffer from chronic obstructive pulmonary disease with the outcome being the number of drugs taken, using healthcare utilization indicators and patient characteristics as covariates.\nKey words: Bayesian inference, Continuous-time hidden Markov models, COPD, Health trajectories, MCMC, Non-equidistant longitudinal data analysis\n\nThis paper has been submitted for consideration for publication in Biometrics"
    },
    {
      "markdown": "# 1. Introduction \n\nLarge amounts of longitudinal health records are now collected in private and public healthcare systems. Data from sources such as electronic health records (EHRs), healthcare administrative databases and mobile health applications are available to inform clinical and public health decision-making. In many situations, such data-enabled dynamic monitoring of the underlying disease process that governs the observations. However, this process is not observed directly and so inferential methods are needed to ascertain progression. Typically, records are only updated when a subject interacts with the system, resulting in irregularly spaced longitudinal observations, and patterns of interactions that vary from subject to subject. For example, in healthcare claim databases, chronic disease patients do not make intensive use of resources while in the early stages of their disease, and therefore their records may be sparse. Patients might also seek care outside the healthcare system, which means that only a segment of the trajectory might be observed. These facts suggest that trajectories should be modeled as a continuous-time process as the observations are not collected at equidistant time intervals and may be sparse.\n\nMulti-state models capture the status of individuals longitudinally as a discrete-time realization of a continuous-time Markov process (Kalbfleisch and Lawless, 1985). A hidden Markov model (HMM, Baum and Petrie, 1966) assumes that an unobserved stochastic sequence governs the observations and the assumptions of the Markov property are imposed on the unobserved sequence. Bartolucci et al. $(2007,2012)$ used a time-binning step for irregularly spaced longitudinal data, leading to artificially equidistant data that could be modeled with discrete-time HMMs. However, continuous-time Markov models can accommodate discretely observed, multi-state processes when the visit time is irregular. Much work on continuoustime HMMs has been devoted to frequentist approaches, with inference via the EM algorithm (Jackson and Sharples, 2002; Jackson et al., 2003; Wang et al., 2014; Lange et al., 2015;"
    },
    {
      "markdown": "Bartolucci and Farcomeni, 2019). Alaa and van der Schaar (2018) used a semi-Markov model, allowing the distribution of the holding time to be more flexibly modeled. Few studies have explored the Bayesian approach. Recently, Williams et al. (2019) constructed a Bayesian continuous-time HMM to study dementia progression, using restrictions on the parameter space to identify the parameters in the HMM. In a discrete-time framework, Altman (2007) developed a HMM under the generalized linear mixed effect model (GLMM) framework, making it possible to incorporate covariates associated with each observation as fixed and random effects, and Raffa and Dubin (2015) extended this work to a fully Bayesian setting. In this paper, we develop a continuous-time hidden Markov model (CTHMM) and an observation generalized linear model (GLM) to draw inference in a fully Bayesian setting. The Bayesian approach has not been widely used for the analysis of such data due to computational scale and complexity, and yet it provides a more complete representation of inferential uncertainty. Our approach allows us to identify the individual characteristics of the identifiable latent process without further constraining the infinitesimal generator, which permits the estimation of population-level effects, as well as individual analysis. We have developed a computational strategy based on Markov chain Monte Carlo (MCMC) methods that facilitates a comprehensive analysis. Our Bayesian approach is appealing because it adopts a different likelihood function for the CTHMM which improves the performance of MCMC methods. To our knowledge, no such fully Bayesian approach has been presented for this type of CTHMM using this likelihood function, nor has it been been implemented at scale (in our example, around one million observations from 33,000 patients).\n\nThe remainder of this paper is organized as follows. In Section 1.1, we describe an example that motivates the development of the methodology. Development of the CTHMM-GLM is described in Section 2. Section 3 presents fully Bayesian inference via MCMC. Simulation examples to examine the performance of the model are presented in Section 5. Finally, we"
    },
    {
      "markdown": "present the results from applying this method to a cohort from an administrative data set (described in Section 1.1) in Section 6, and discuss these results in Section 7.\n\n# 1.1 A Motivating Example \n\nThe development of our method and corresponding software was motivated by the need to model latent disease progression within a large chronic obstructive pulmonary disease (COPD) cohort. COPD is a highly prevalent chronic disease, and the associated burden of care is among the highest in terms of the annual rate of hospitalization, especially among older patients. In Canada, COPD is the fourth most common cause of hospitalization among men and the sixth among women and it is one of the seven most prevalent ambulatory care sensitive conditions (Centre for Chronic Disease Prevention and Control, 2001). COPD, therefore, places a considerable burden on the healthcare system and there are extensive records of encounters between patients with COPD and the healthcare system. Currently it is typical to rely on aggregate cross-sectional indicators to measure healthcare provision for patients with COPD: such indicators are well-suited to measuring acute events that result in easily measurable healthcare encounters (Broemeling et al., 2007; Betancourt et al., 2014). However, they provide little insight into underlying disease progression, which is critical as healthcare systems struggle to transition in focus from acute care to chronic disease management (Gold et al., 2011; Shaban-Nejad et al., 2017).\n\nIt is widely believed that the progression of COPD can be well-modeled as a progression through a small number of discrete states which approximate severity (GOLD Executive Committee, 2017). The GOLD staging system posits four COPD stages based on lung function as measured by the forced expiratory volume during the first second (FEV1): Stage 1 (Very mild COPD, FEV1 at least 80 percent of normal), Stage 2 (Moderate COPD, FEV1 between 50 and 80 percent of normal), Stage 3 (Severe emphysema, FEV1 between 30 and 50 percent of normal), Stage 4 (Very severe COPD, lower FEV1 than Stage 3, or those"
    },
    {
      "markdown": "with Stage 3 FEV1 and low blood oxygen levels). We will interpret these as the states in our discrete state model, a formulation which underpins current clinical practice. We are interested in modeling the rate of transition between these discrete states, as well as understanding how individual patient characteristics modify the rate of transition, which reflects the performance of the healthcare system over time.\n\nIn our example, an open, dynamic cohort was established, consisting of a $25 \\%$ random sample of Montreal residents. In 1998, a $25 \\%$ random sample was drawn from the Régie de l'assurance maladie du Québec (RAMQ)-registered population with a residential postal code in the census metropolitan area of Montreal. At the start of every following year, $25 \\%$ of those who were born in Montreal or moved to Montreal within the past year were sampled to maintain a representative cohort. Follow-up ended when people died or changed their residential address to outside of Montreal. This administrative database includes outpatient diagnoses and procedures submitted through billing claims to the RAMQ, and procedures and diagnoses from inpatient claims. Drug dispensing data are available for people who have drug insurance through RAMQ (which includes approximately half the population and all those over 65 years of age). All data are linked through an anonymized version of the RAMQ identification number. Between 1998 and 2014, 81,580 COPD patients were enrolled into this cohort, starting from the time of their first diagnosis, and were followed until the end of 2014. Physicians only observed these patients during medical visits, which occurred when patients chose to interact with the healthcare system. When patients undergo physician visits, relevant medical information is collected and from the observed information we aim to infer the patients' unobserved disease status, which we represent using a discrete disease state model. In this study, their disease status was indirectly measured through a proxy: the number of prescribed medications at the time of observation. The number of drug dispensations has been shown, in these data, to be a good predictor of 30 -day hospital"
    },
    {
      "markdown": "readmission, which is in turn a good proxy for severity-of-illness (Verma, 2015): indeed it is an even better predictor of 30 -day hospital readmissions than other data typically available in healthcare administrative databases, such as diagnosis codes or procedure codes. However, this information was only available for patients with drug insurance. Therefore, we focus on patients over 65 years of age ( 33,876 patients) as the study population for the analysis in this paper. At each observation time, the number of prescribed medications was observed, along with several time-dependent covariates. Using these data, we wish to estimate the rate of transition between the discrete latent disease states as a function of some fixed covariates. Figure 1 shows one patient trajectory from the COPD data set.\n[Figure 1 about here.]\nDuring follow-up, the number of drugs prescribed for this patient was increasing over time and we believe that the disease status of this patient was becoming more severe. Our goal is to develop inference procedures to detect this unobserved disease progression and study the individual transition features of this process with the information of the observed informative (surrogate) outcomes and some time-dependent and individual-level fixed covariates.\n\n# 1.2 Notation \n\nLet $O_{t}$ represent the outcome observations at visit time $t$, regarded as indicative of the unobserved disease status. In this example, $O_{t}$ is the number of prescribed medications recorded, which is informative of the disease progression as the more drugs are prescribed, the more severe the disease tends to be. Let $Z_{t}$ be time-dependent covariates that feature in the outcome model; the types of healthcare utilization - hospitalization (HOSP), specialist visit (SPEC), general practitioner visit (GP) and emergency department visit (ED) - were recorded in the COPD example. Let $W$ be the individual-level fixed covariates assumed to influence the transition rate between latent states: the gender and age when a patient entered the cohort are normally available in administrative databases."
    },
    {
      "markdown": "# 2. Model Development \n\nWe consider the modeling of data for a single individual. Assume a sequence $\\left\\{O_{1}, \\ldots, O_{T}\\right\\}$ is observed with its associated observation time points $\\left\\{\\tau_{1}, \\ldots, \\tau_{T}\\right\\}$, and the latent health status process $\\left\\{X_{s}\\right\\}\\left(s \\in \\mathbb{R}^{+}\\right)$is a homogeneous continuous-time Markov process taking values on the finite integer set $\\{1,2, \\ldots, K\\}$ on the filtered probability space $\\left(\\Omega, \\mathcal{F},\\left\\{\\mathcal{F}_{s}\\right\\}_{s \\geqslant 0}, \\mathbb{P}\\right)$. We index the observations using an integer index $(t)$, and the latent process using a continuousvalued index (that is, $\\tau_{t}$ ). The following diagram provides a schematic of the presumed data generating structure for one subject.\n![img-0.jpeg](img-0.jpeg)\n\nIn the example, data are observed over the time interval $s=0$ to $s=10$ (months, say), during which there are eight recorded observations $O_{s}$ at $s=\\tau_{1}=0, \\tau_{2}, \\ldots, \\tau_{8}$. Note that the time origin coincides with the first observation for each individual. Underlying the observed data is a continuous-time hidden Markov process $\\left\\{X_{s}\\right\\}$ with three states; at time $s=0$, the subject is in state 1 , and then undergoes a series of state changes $1 \\longrightarrow 2 \\longrightarrow 3 \\longrightarrow 2 \\longrightarrow 1$ at unobserved times in the interval according to a homogeneous continuous-time Markov model with transition matrix determined by individual-level covariates according to a model described in more detail below. Thus we have that the observations $O_{1}, \\ldots, O_{8}$ are made while the latent process is in states $1,1,1,2,3,2,2$ and 1 , respectively. Although the observation times are recorded, the latent states are unobserved, which motivates the construction of a hidden Markov model.\n\n### 2.1 A hidden Markov model for disease progression\n\nConventionally, using standard arguments based on the Chapman-Kolmogorov and Kolmogorov equations, the transition probability from state $i$ to state $j$ in the time interval of"
    },
    {
      "markdown": "length $\\Delta_{t}=\\tau_{t+1}-\\tau_{t}$ between observation times $t$ and $t+1$ takes the form\n\n$$\np_{k j}\\left(\\Delta_{t}\\right)=\\mathbb{P}\\left(X_{\\tau_{t+1}}=j \\mid X_{\\tau_{t}}=k, \\tau_{t+1}-\\tau_{t}=\\Delta_{t}\\right)=\\exp \\left(\\Delta_{t} Q\\right)_{(k j)}\n$$\n\nwhere $t=1, \\ldots, T-1, Q=\\left(q_{k j}\\right)$ for $1 \\leqslant k, j \\leqslant K$ is the infinitesimal generator for the continuous-time Markov process $\\left\\{X_{s}\\right\\}$ and $\\sum_{j \\neq k} q_{k j}=-q_{k k}>0$ for $1 \\leqslant i \\leqslant K$, and $\\exp (A)$ is the matrix exponential of matrix $A$. To incorporate baseline subject-level covariates $\\mathbf{W} \\in \\mathbb{R}^{M}$ into this generator $Q$, we define the log-rate parameters via a linear predictor such that for $1 \\leqslant k \\neq j \\leqslant K, \\log q_{k j}=\\mathbf{W}^{\\top} \\xi_{k j}$ where $\\xi_{k j}$ is the coefficient vector for $q_{k j}$, assuming that the rate in any interval is determined by the values of covariates at the start of the interval. The initial state distribution $\\pi$ for $\\left\\{X_{s}\\right\\}$ is $\\pi_{k}=\\mathbb{P}\\left(X_{0}=k\\right)$ for $k=1, \\ldots, K$.\n\n# 2.2 Observation model \n\nThe observation process assumes that the observed data are drawn from an exponential family conditional on the hidden state. Specifically, given $X_{\\tau_{t}}=k$, observation $O_{t}$ is independent of the other observed data, with\n\n$$\nf\\left(O_{t} \\mid X_{\\tau_{t}}=k\\right)=\\exp \\left[\\left\\{O_{t} \\theta_{t, k}-b\\left(\\theta_{t, k}\\right)\\right\\} / \\phi^{2}+c\\left(O_{t}, \\phi\\right)\\right]\n$$\n\nIf there are time-varying explanatory variables $\\mathbf{Z} \\in \\mathbb{R}^{D}$, a GLM with link function specified as $g\\left(u\\left(\\theta_{t, k}\\right)\\right)=\\mathbf{Z}_{t}^{\\top} \\beta_{k}$ can be adopted, where $u\\left(\\theta_{t, k}\\right)=\\mathbb{E}\\left(O_{t} \\mid X_{\\tau_{t}}=k\\right)$ and $\\beta_{k}$ is a coefficient vector for state $k$. If $S_{t}=\\left(S_{t, 1}, \\ldots, S_{t, K}\\right)^{\\top}$ is an indicator random vector with $S_{t, k}=1$ if $X_{\\tau_{t}}=k$ and 0 otherwise, then using coefficient matrix, $B=\\left(\\beta_{d, k}\\right)$ for $d=1, \\ldots, D$ and $k=1, \\ldots, K$, the linear predictor can be rewritten as $g\\left(u\\left(\\theta_{t, k}\\right)\\right)=\\mathbf{Z}_{t}^{\\top} B S_{t}$. The model is thus parameterized by $\\Theta=\\left\\{\\xi_{k j}, 1 \\leqslant k, j \\leqslant K, \\pi, B, \\phi\\right\\}$.\n\n### 2.3 Likelihood\n\nIf there are $N$ subjects, let $O_{n, t}\\left(t=1, \\ldots, T_{n}\\right)$ be the $t^{\\text {th }}$ observation for subject $n$ with the associated observation time $\\tau_{n, t}$. For each individual, $\\left\\{X_{s}\\right\\}$ is a time-homogeneous Markov process with finite state space $\\{1, \\ldots, K\\}$ with infinitesimal generator $Q$. If $\\left\\{X_{s}\\right\\}$ has been"
    },
    {
      "markdown": "observed continuously in the time interval $[0, \\tau]$, the likelihood contribution from an individual subject is (Bladt and Sørensen, 2005)\n\n$$\n\\prod_{l=1}^{K} \\prod_{m \\neq l} q_{l, m}{ }^{N_{l, m}(\\tau)} \\exp \\left\\{-q_{l, m} R_{l}(\\tau)\\right\\}\n$$\n\nwhere $N_{l, m}(\\tau)$ is the number of transitions from state $l$ to state $m$ in the time interval $[0, \\tau]$ and $R_{l}(\\tau)=\\int_{0}^{\\tau} \\mathbb{1}\\left(X_{s}=l\\right) d s$ is the total time that the process has spent in state $l$ in $[0, \\tau]$. In our algorithm, we reconstruct the complete trajectory of $\\left\\{X_{s}\\right\\}$ via a missing data formulation. The quantities, $N_{l, m}(\\tau)$ and $R_{l}(\\tau)$, are unobserved, but can be computed given a realization of the latent process on $[0, \\tau]$. The complete-data likelihood derived from $\\left\\{O_{n}\\right\\}$ and $\\left\\{X_{n, \\tau_{n}}\\right\\}$ can be factorized $L(\\Theta) \\equiv L(\\mathbf{O}, \\mathbf{X} \\mid \\Theta)=L(\\mathbf{X} \\mid \\Theta) L(\\mathbf{O} \\mid \\mathbf{X}, \\Theta)$ where $\\mathbf{O}=\\left\\{O_{n, t}\\right\\}$ and $\\mathbf{X}=\\left\\{X_{n, \\tau_{n, t}}\\right\\}$ for $n=1, \\ldots, N, t=1, \\ldots, T_{n}$ and\n\n$$\n\\begin{aligned}\n& L(\\mathbf{O} \\mid \\mathbf{X}, \\Theta)=\\prod_{n=1}^{N} \\prod_{t=1}^{T_{n}} f\\left(O_{n, t} \\mid X_{n, \\tau_{n, t}}\\right) \\\\\n& L(\\mathbf{X} \\mid \\Theta)=\\prod_{n=1}^{N} \\pi_{X_{n, 0}}\\left[\\prod_{t=1}^{T_{n}-1} \\prod_{l=1}^{K} \\prod_{m \\neq l} q_{n, l, m}^{N_{n, l, m}\\left(\\Delta_{n, t}\\right)} \\exp \\left\\{-q_{n, l, m} R_{n, l}\\left(\\Delta_{n, t}\\right)\\right\\}\\right]\n\\end{aligned}\n$$\n\nThe log-likelihood written in terms of the latent state indicator random vectors $\\left\\{S_{k}\\right\\}_{k=1}^{K}$ is\n\n$$\n\\begin{gathered}\n\\ell(\\Theta)=\\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}} \\sum_{k=1}^{K} S_{n, t, k} \\log f\\left(O_{n, t} \\mid S_{n, t, k}\\right)+\\sum_{n=1}^{N} \\sum_{k=1}^{K} S_{n, 1, k} \\log \\left(\\pi_{k}\\right) \\\\\n+\\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}-1} \\sum_{k=1}^{K} \\sum_{j=1}^{K} S_{n, t, k} S_{n, t+1, j} r_{n, t}^{k, j}\n\\end{gathered}\n$$\n\nwhere\n\n$$\nr_{n, t}^{k, j}=\\sum_{l=1}^{K} \\sum_{m \\neq l}\\left\\{N_{n, l, m}^{k, j}\\left(\\Delta_{n, t}\\right) \\mathbf{W}_{\\mathbf{n}}^{\\top} \\xi_{l m}-\\exp \\left(\\mathbf{W}_{\\mathbf{n}}^{\\top} \\xi_{l m}\\right) R_{n, l}^{k, j}\\left(\\Delta_{n, t}\\right)\\right\\}\n$$\n\nrecords the probability of transition from state $k$ to state $j$ in the interval $\\Delta_{n, t}=\\tau_{n, t+1}-\\tau_{n, t}$, and $N_{n, l, m}^{k, j}\\left(\\Delta_{n, t}\\right)$ and $R_{n, l}^{k, j}\\left(\\Delta_{n, t}\\right)$ respectively are the number of jumps from state $l$ to state $m$, and time spent in state $l$, for a Markov chain initiated at state $k$ at time $\\tau_{n, t}$ and ending in state $j$ at time $\\tau_{n, t+1}$."
    },
    {
      "markdown": "# 3. Bayesian Inference for the CTHMM-GLM \n\nWe perform a fully Bayesian analysis of the observed data adopting the likelihood function in (2) and the complete-data log-likelihood in (3). In the Web Appendix A, the parameter estimation for the CTHMM-GLM based on the EM algorithm is derived, and this algorithm is used to provide starting values for the Bayesian procedure, as well as to assist in identifying a suitable number of states for the Markov chain model. The Bayesian approach is appealing in this case as the simulation-based method can be easily applied to make inference for each individual (shown in Section 6) and is more effective when more complexity is incorporated into the model. The Bayesian method also produces posterior samples of the full unobserved state sequences, which allows inferences to be made for individual-level trajectories. We can write the Bayesian hierarchical model for the CTHMM-GLM as follows:\n\n- Prior: $\\Theta \\sim \\pi(\\Theta)$, where $\\Theta=(\\pi, \\xi, B)$. In a Bayesian analysis, an informative prior may be adopted, and is especially important when sample size per subject is small. We discuss the choice of priors in the sections below.\n- Hidden Markov Process: $X_{s} \\mid Q, \\pi \\sim$ Continuous-time Markov chain $(\\pi, Q)$ with $Q \\equiv Q_{n}$ having off diagonal elements $q_{n, l, m}$ specified by $\\log q_{n, l, m}=\\mathbf{W}_{\\mathbf{n}}{ }^{\\top} \\xi_{l m}$ for $n=1, \\ldots, N$, and $1 \\leqslant l, m \\leqslant K, l \\neq m$.\n- Latent Variables: $S_{n, t}$ for each $n, t$, determined by $X_{n, \\tau_{t}}$.\n- Observation Process: $O_{n, t} \\mid S_{n, t} \\sim$ Exponential Family $(B)$\n\nWe now sketch the structure of a Metropolis-Hastings-within-Gibbs algorithm: note that in each case we are sampling the full conditional distribution of the relevant model component. Starting with initial values $\\pi^{(0)},\\left\\{\\xi_{l m}\\right\\}_{1 \\leqslant l \\neq m \\leqslant K}^{(0)}$, $B^{(0)}$ and $\\phi^{(0)}$, and then given those initial values, the 'forward' and 'backward' values $a_{n, t, k}$ and $b_{n, t, k, j}$ (see the Web Appendix A for the full definition of $a_{n, t, k}$ and $b_{n, t, k, j}$ ) are calculated using the forward-backward algorithm. At"
    },
    {
      "markdown": "iteration $i$, the MCMC algorithm simulates the posterior sample in the following way based on the full conditional posterior distributions:\n\n- Update latent state indicators: For each $n$ and $t$, generate the random vector $S_{n, t}^{(i)}$ from the multinomial distribution with parameters $a_{n, t}^{(i)}=\\left(a_{n, t, 1}^{(i)}, \\ldots, a_{n, t, K}^{(i)}\\right)$.\n- Update $B$ and $\\phi$ : Sample coefficient matrix $B^{(i)}$ and scale parameter $\\phi^{(i)}$ given $S_{n, t}^{(i)}$ via the Metropolis-Hastings (M-H) algorithm as there are no standard distributional forms for the conditional posteriors of $B$ and $\\phi$. Proposals are made using a standard Metropolis update from a Normal density for elements of $B$, and using a Gamma proposal for $\\phi$. Starting values are obtained using an initial GLM fit to the observed data.\n- Update $\\pi$ : Sample $\\pi^{(i)}$ from a Dirichlet $\\left(\\sum_{n=1}^{N} S_{n, 1,1}^{(i)}+1, \\ldots, \\sum_{n=1}^{N} S_{n, 1, K}^{(i)}+1\\right)$ distribution.\n- Update $\\xi$ : This update is achieved by augmenting the sample space by simulating a path for the latent process. For each $n$ and $t$,\n- Sample the current state and next state $\\left(X_{n, \\tau_{n, t}}, X_{n, \\tau_{n, t+1}}\\right)$ from a multinomial distribution with the parameter matrix containing the $b_{n, t, k, j}$. Since the likelihood for $Q$ requires a continuously observed Markov chain, we first simulate the full path before updating $\\xi$.\n- Simulate $N_{n, l, m}\\left(\\Delta_{n, t}\\right)$ and $R_{n, l}\\left(\\Delta_{n, t}\\right)$ from the Markov jump processes step-by-step with infinitesimal generator $Q_{n}^{(i-1)}$ (obtained by $e^{\\mathbf{W}_{\\mathbf{n}}{ }^{\\top} \\xi^{(i-1)}}$ ) through the intervals $\\left[\\tau_{n, t}, \\tau_{n, t+1}\\right)$ initiated at $X_{n, \\tau_{n, t}}$ and end point $X_{n, \\tau_{n, t+1}}$ sampled previously. Simulating sample paths conditional on the endpoints can be achieved efficiently by using modified rejection sampling when it is known that at least one state change must take place (see Hobolth and Stone, 2009), and hence $\\left\\{X_{s}\\right\\}$ is recovered and the jump time points are generated. Then sample the $\\left\\{\\xi_{l m}\\right\\}_{1 \\leqslant l \\neq m \\leqslant K}^{(i)}$ given the recovered trajectories for all subjects using the M-H algorithm. This algorithm produces an exact sample for the latent process from its full conditional distribution for each subject, which facilitates a straightforward M-H update for the transition parameters."
    },
    {
      "markdown": "# 4. Prior Specification \n\nDespite the intricacy of the model, the number of parameters it contains is relatively small: in a $K$-state homogeneous HMM, there are $K(K-1)$ free parameters in $Q$, plus $K-1$ free parameters in the initial state distribution vector $\\pi$. In addition, there are $K \\times D$ coefficients in the matrix $B$. In the time-inhomogeneous version of the model, each offdiagonal element in $Q$ is parameterized by an $M$-dimensional coefficient vector $\\xi_{i j}$. Thus a genuinely subjective prior specification is not a demanding task, if suitable information is available. In this paper, we use mildly informative, but independent priors on the regression parameters: typically, we use Normal priors with small variances on the original or log scale. In the pure likelihood sense, the prior acts as a form of regularization that can provide legitimate results even if there is a paucity of data when considering specific parameters in the model. For example, transitions between two states may occur in the HMM only with low frequency; an informative prior effectively regularizes the inference in this case to yield a posterior distribution that does not enlarge a variance. Results appear stable when varying the variance of the prior across a reasonable range. See Sections 5 and 6 for details.\n\nA standard prior specification to adopt is exchangeable in form with respect to the state labels. In principle, this renders the model non-identifiable with respect to the state labels, mimicking the phenomenon of permutation non-identifiability encountered in the analysis of finite mixture models. In this case, the posterior distribution also suffers from this nonidentifiability: effectively, we have no absolute interpretation of State 1, State 2 etc. In the resulting MCMC algorithm, therefore, it is possible that the algorithm would suffer from the label-switching phenomenon, where on successive iterations the interpretation of State $i$ may change from iteration to iteration. This may be overcome in practice, by post-sampling re-labelling of states according an ordering, say, on the intercept parameters in the outcome model. The label-switching problem, and some solutions, are discussed in Jasra et al. (2005)"
    },
    {
      "markdown": "and Frühwirth-Schnatter (2006). For our real data analysis, however, we have sufficient prior information to avoid non-identifiability. For the COPD data, we regard the different states as corresponding to the GOLD stages, and therefore utilize priors that reflect the fact that more severe COPD stages require different amounts of dispensed drugs (see Section 6).\n\n# 5. Simulation Study \n\nIn this section we demonstrate the performance of the proposed EM algorithm and the MCMC approach for non-equidistant observations generated by the latent state model. We use model selection criteria to infer the number of latent states required.\n\n### 5.1 Example 1\n\nIn the first example, we demonstrate the performance of the EM algorithm (see the Web Appendix A) and MCMC to estimate the parameters of interest, and to discover how performance degrades when the problem becomes more challenging. We consider a four-state model with one baseline covariate $W_{1} \\sim \\mathcal{N}(-1,0.5)$ and associated coefficients\n\n$$\n\\xi_{0}=\\left(\\begin{array}{rrrrr}\n0 & 0.29 & -0.63 & -0.70 \\\\\n0.90 & 0 & -0.32 & 0.02 \\\\\n-0.26 & -0.31 & 0 & -0.47 \\\\\n-0.18 & -0.08 & 0.24 & 0\n\\end{array}\\right) \\quad \\xi_{1}=\\left(\\begin{array}{lllll}\n0.0 & 2.0 & 1.0 & 0.0 \\\\\n1.0 & 0.0 & 1.0 & 0.5 \\\\\n1.0 & 2.0 & 0.0 & 0.5 \\\\\n0.5 & 0.5 & 0.5 & 0.0\n\\end{array}\\right)\n$$\n\nand with two time-varying covariates $Z_{1} \\sim \\mathcal{N}(-1,1)$ and $Z_{2} \\sim \\operatorname{Binomial}(1,0.6)$, with\n\n$$\nB=\\left(\\begin{array}{rrrrr}\n1.28 & 0.05 & 1.05 & 0.99 \\\\\n-0.88 & 1.15 & 1.36 & 1.73 \\\\\n0.70 & -0.68 & -1.12 & -2.20\n\\end{array}\\right)\n$$\n\nThe initial distribution $\\pi$ is set to be $(0.35,0.25,0.2,0.2)^{\\top}$. We first constructed the continuous time Markov process from the generator $Q_{i}=e^{\\xi_{0}+\\xi_{1} W_{1, i}}$ for subject $i$, a continuoustime realization of the latent sequence $\\left\\{X_{s}, 0 \\leqslant s \\leqslant 20\\right\\}$, and uniformly at random extracted"
    },
    {
      "markdown": "$T-1$ observation time points between 0 and 20 . We assumed that the first observation was made at time 0 . Therefore, each subject had $T$ observations in total and we generated the data for 1000 subjects. In our simulation we observed performance improvement when $T$ is increased. The prior distributions for the $\\xi$ parameters were specified as independent normal distributions with mean 0 and 1.5 respectively and standard deviation 0.5 . Noninformative priors were imposed for $B$ and $\\pi$. In terms of MCMC starting values, $\\pi$ was specified with equal probability in any state; the $B, \\xi_{0}$ and $\\xi_{1}$ parameters were drawn from normal distributions with variances ranging from 0.5 to 1.5 .\n[Table 1 about here.]\n\nThe simulation results are shown in Table 1. Trace plots were checked and convergence confirmed in the MCMC samples; as starting values in MCMC were given by the parameter estimates in the EM algorithm, convergence was achieved fast. The reconstruction rate (the proportion of times that the correct latent state is recovered at each observation time) measures the accuracy with which we can recover the true latent states: the recovered latent state at each observation was taken as the maximum estimated probability state calculated using the forward-backward algorithm in the EM algorithm and posterior mean in the MCMC approach. From the parameter configuration, each data set consists of roughly $33 \\%, 15 \\%$, $32 \\%$ and $20 \\%$ observations in State 1 to 4 respectively, and there are frequent transitions between states. Both the EM and Bayesian approaches perform well in parameter estimation and reconstruction, as most cases have much high reconstruction rates that increase as the number of samples increases or the signal to noise ratio decreases. The only exception is for the Bernoulli distribution with $T \\leqslant 100$ : here the outcome is either 0 or 1 , which does not carry much information about the latent states. When we increased the number of observations per subject to 500 , the reconstruction rate improved considerably. Here, we have more frequent observations in each latent state, which can improve the accuracy in"
    },
    {
      "markdown": "estimating state-dependent parameters - however only certain modern health data sets (such as mobile health applications, and some imaging data) will lead to $T$ close to 500. MCMC outperformed the EM algorithm in the Bernoulli and Binomial cases in terms of parameter estimation. The EM algorithm has a slightly better reconstruction rate than MCMC: this is in part a product of having to account for the posterior uncertainty.\n\n# 5.2 Example 2 \n\nIn this example, we conducted a simulation study to evaluate model selection criteria for choosing the number of hidden states given the correct time-varying covariates. The purpose of this example is to show that how different values of $\\sigma$ compromise on the different number of states in the simulation study. We assumed that there were no baseline covariates, so the rate matrix in this example was the same across all the subjects. The simulation is configured with three latent states and the associated population generator and the coefficient matrix\n\n$$\nQ=\\left(\\begin{array}{rrr}\n-2.5 & 2.0 & 0.5 \\\\\n0.5 & -1.5 & 1.0 \\\\\n0.5 & 0.5 & -1.0\n\\end{array}\\right) \\quad B=\\left(\\begin{array}{rrr}\n-0.3 & 1.2 & 0.3 \\\\\n-0.9 & 2.2 & -1.6\n\\end{array}\\right)\n$$\n\nand with one time-varying covariate $Z \\sim \\mathcal{N}(-1,0.5)$ and a Gaussian distribution as the observation process. The initial distribution $\\pi$ for the continuous-time Markov process is set to be $(0.3,0.4,0.3)^{\\top}$, and the variance (scale) parameter $\\sigma$ is set to be the same for all three latent states with the following cases: Case 1: $\\sigma=0.5$, Case 2: $\\sigma=0.75$, Case 3: $\\sigma=1$. As in the first example, we constructed the continuous-time Markov process from the generator $Q$, a continuous-time realization of the latent state process $\\left\\{X_{s}, 0 \\leqslant s \\leqslant 3\\right\\}$, and randomly extracted 11 observation time points between 0 and 3 , with the first observation at time 0 in order to estimate the initial probability $\\pi$. Each subject had 12 observations which were generated from a Gaussian distribution and we generated data for 500 subjects. In each simulation, we varied the number of hidden states from 2 to 4 with one time-varying covariate"
    },
    {
      "markdown": "and chose the best model fit using the EM algorithm for the smallest AIC and BIC, and the MCMC approach with 300 iterations and 200 burn-in iterations for the smallest WAIC (Watanabe, 2010) and DIC (Spiegelhalter et al., 2002). We repeated the simulation 100 times to compare the model selection criteria. The observed (incomplete) data likelihood was used to calculate the model selection criteria. The results are shown in Table 2: AIC tends to choose the four-state model in all cases. In Case 1 with the smallest $\\sigma$, BIC, WAIC and DIC selected the correct model with frequency over $90 \\%$, but accuracy decreased as $\\sigma$ increased. For the EM results, the BIC had a higher accuracy than AIC in choosing the three-state model in all cases. The performances of WAIC and DIC were similar.\n[Table 2 about here.]\n\n# 5.3 Example 3: Comparison with alternative approach \n\nThe third simulated example is drawn from the paper by Bartolucci and Farcomeni (2019), which introduces a continuous time latent multi-state model and a computational strategy based on a discrete-time approximation where the time-discretization can be arbitrarily fine-scale. Although Bartolucci and Farcomeni (2019) considered equidistant longitudinal data in their examples, the model can be used with observation time points that are not equally spaced. As the approach by Bartolucci and Farcomeni (2019) is likelihood-based, we compare results between the algorithm from that paper and our EM approach. This example allows us to study the potential advantage of using an exact continuous time formulation over a fine discrete approximation. We ran a Monte Carlo study with 1000 replications of a four-state model for several different sample sizes and different numbers of per-subject observations (see the Web Appendix C). The Bartolucci and Farcomeni (2019) algorithm requires a specification of the time-discretization, and we specified two different values. The data are generated according to the scheme described in Sections 3.1 and 4 of Bartolucci and Farcomeni (2019). First, a continuous-time Markov chain is generated and"
    },
    {
      "markdown": "the longitudinal observation times are selected uniformly at random over the time interval (in Bartolucci and Farcomeni (2019), the observation times are taken equally spaced). Given the latent state, longitudinal outcomes are generated with two time-varying covariates from two independent $\\operatorname{AR}(1)$ processes. We ignore survival aspects when using our approach. The results are presented in the Web Table 2. We compare the norm differences of the estimates and true values for the infinitesimal generator $Q$ as our primary target was to estimate the latent process. Our exact EM algorithm appears to offer more accurate results (as measured by root mean square error in the estimation of the elements of $Q$ ) and shorter computation time (as measured by the average computation time per EM implementation).\n\n# 6. Real Data Analysis \n\n### 6.1 Data\n\nIn this application, we apply our method to the data described in Section 1.1. The data set consists of 33,876 COPD patients over 65 years old, and includes the number of prescribed medications at the time when patients visited the physician. The types of healthcare utilization (HOSP, SPEC, GP and ED) were also recorded, and used as a time-dependent covariate, with a Poisson model for the observation process. The age of the patients when they were first diagnosed with COPD is also recorded and is used as a baseline covariate to model the effect of individual generator matrices. Although we suspect that patients suffering COPD have only worsening health state, we allow transitions between all pairs of states in order to verify this rather than constraining elements of $Q$ to be zero. However, since the observed number of dispensed drugs could include drugs for conditions other than COPD, the discovered latent states may be indicative of more general health status."
    },
    {
      "markdown": "# 6.2 Results: Inferring the number of states \n\nTo infer an appropriate number of states for the Bayesian analysis, we use the EM algorithm. The AIC and BIC values for models with 2,3 and 4 states are (AIC) 3148125,2708166 and 2955429 and (BIC) 3148153, 2708463 and 2955921 respectively. The three-state model has the smallest AIC and BIC and the residual plot (see the Web Figure 1) confirms the fit adequacy of the three-state model. The GOLD staging system posits four stages of COPD: however, our data set is collected from the general population and does not include data from the most severely affected Stage 4 patients, who are likely to be hospitalized. Therefore, a three-state model is plausible. Table 3 contains the exponential of the $B$ coefficients for the three-state model. On average, from State 1 to 3 the number of drugs taken increases; however, within each state, the numbers of drugs across the different healthcare utilizations are approximately the same, except for State 1 where there are significant differences in the numbers of drugs utilized across healthcare utilizations.\n[Table 3 about here.]\nFor the initial distribution, $27.48 \\%$ of patients started in State 1: these patients had very mild COPD and who did not need prescription drugs, or potentially were improperly diagnosed. Approximately $44 \\%$ of patients started from State 2: these patients were likely to be at Stage 2 COPD. Finally, $28.29 \\%$ of patients began from State 3: these patients likely have end-stage COPD, as on average they were prescribed over 10 different drugs and so the COPD is likely to be severe. Overall $12.78 \\%$ of patients remained in State $1,17.21 \\%$ remained in State 2 and $15.82 \\%$ remained in State 3 throughout their entire follow-up period.\n\n### 6.3 Results: Bayesian analysis\n\nWe fit the three-state Poisson model using the MCMC approach with 2000 iterations and 1000 burn-in iterations using the EM estimates as starting values. The trace plots were checked and convergence confirmed (trace plots and a table of the effective sample sizes of the"
    },
    {
      "markdown": "posterior samples are given in the Web Appendix D). The specification of prior distributions is also given in the Web Appendix D. According to Verma (2015), hospital readmission is four times higher for patients with over 10 drugs prescribed than those no drugs prescribed, and the patients are considered to be very severely affected. The prior distribution for the components of $B$ is set to be a normal distribution with mean number of drugs as $0.1,5$, 10 for three states respectively, but with no difference among type of encounters. The prior distributions for $\\xi_{0}$ are selected such that on average patients are likely to transition from State 1 to State 2 and stay in the most severe state, State 3 . The prior distributions for $\\xi_{1}$ assume no effect of the baseline age of the patients. As indicated in Section 4, the prior for $\\xi$ is informative, with standard deviation 1 and 0.5 , respectively.\n\nTable 4 shows the posterior mean of the fixed effect coefficients for the rate matrix associated with $95 \\%$ credible interval. A figure in the Web Appendix D (Web Figure 5) shows the transition probability over time for patients at age 66 and 80: in general, older patients are more likely to progress from State 1 to State 3 and from State 2 to State 3. In addition, patients are more likely to stay in the more severe state than transition to the less severe states. We observed that patients tend to transition to State 2 with high probability from State 1, and most likely to progress to more severe states. This result confirms that with no restriction on the transitions, we are still able to identify the parameters in the HMM.\n[Table 4 about here.]\n\nFor an analysis at the individual level, Figure 2 shows the posterior simulated trajectories of the latent processes for these two patients chosen from the cohort (entering aged 66 and 80 respectively) as well as the observed number of prescribed drugs. It is evident from the posterior samples of the trajectories - note the dark gray regions (this figure appears in color in the electronic version of this article, and any mention of color refers to that version) where transitions from one state to another occur. From the simulated trajectories, patients"
    },
    {
      "markdown": "are more likely to transition to State 1 than to State 3 when the patients are in State 2. Moreover, older patients tend to stay longer in the most severe State 3.\n[Figure 2 about here.]\n\nNext, we compare the expected number of drugs prescribed to these two patients. The expected number of drugs prescribed for the entire trajectory is calculated by\n\n$$\n\\int_{0}^{t_{\\max }} \\mu(X(t)) d X_{t}\n$$\n\nwhere $\\mu(x(t))$ is the modeled expectation for the outcome variable. This integral can be easily approximated using the Monte Carlo samples for the individual trajectories. The calculation used the simulated trajectories in Figure 2 and for each trajectory, the expected number of prescribed drugs was calculated by multiplying the time spent in each state and the mean of the number of prescribed drugs on each state given the type of healthcare service. The estimated average number of drugs prescribed per year for older patients is 5.47 ( $95 \\%$ credible interval, $(5.21,5.76)$ ), which is $1.61(95 \\%$ credible interval, $(1.46,1.78))$ times more than that of the average of the younger patient (see the Web Figure 6).\n\n# 7. Discussion \n\nWe have developed a latent continuous time model for health trajectories and implemented it in a fully Bayesian framework. This model can deal with challenges typically encountered in latent multi-state modeling, in particular, irregular visits that vary from patient to patient. Our approach uses a complete-data likelihood function with subject-specific rate matrix that is influenced by covariates. Simulation studies demonstrated that both the EM algorithm and an MCMC approach could estimate the parameters of interest accurately. In terms of identifying the number of latent states, we used information criteria, and demonstrated that BIC performs better than AIC for the EM algorithm and WAIC and DIC perform well for the MCMC approach. Analysis of real data demonstrated that the model could identify the"
    },
    {
      "markdown": "meaningful latent states and individual transition patterns. We were able to implement the developed methods for a very large real data set from Quebec, Canada, comprising more than thirty thousand patients tracked over twenty years.\n\nThe fully Bayesian approach is attractive since the simulation-based method can be easily adopted to make inference for individual-level analysis and is more efficient when more complex settings are incorporated. This model is also flexible, and can easily accommodate new sources of data and domain knowledge such as time-dependent covariates. Our model employs a GLM framework, which could be extended to the GLMM framework using Monte Carlo EM (Altman, 2007) or a fully Bayesian setting (Raffa and Dubin, 2015). The Bayesian procedure can also easily incorporate healthcare expertise in the form of prior information. Patients with COPD over the age of 65 are at high risk of death as a result of their disease. Death is not incorporated explicitly in the analysis as the current data set does not contain such information: in the context of the COPD analysis, we can regard the most 'severe' COPD state as a proxy for death, in that death due to COPD is usually presaged by an increase in healthcare utilization. Our model can also be extended to incorporate death if the relevant data are available. There are other possible alternative extensions, including the use of a joint modeling framework (Wulfsohn and Tsiatis, 1997) which models the joint behavior of a sequence of longitudinal measurements and an associated sequence of event times simultaneously. Another way is to use separate regressions to model death and other relevant outcomes but correlated random effects are included among them to account for the correlation (Raffa and Dubin, 2015). A third approach is to consider death as an informative censoring: in Lange et al. (2015), a Markov-modulated Poisson process can be included to account for the informative censoring.\n\nIn our proposed model, the number of states has to be pre-specified, and in this study we infer the number of states using information criteria. One extension is to use a Bayesian"
    },
    {
      "markdown": "nonparametric or transdimensional approach to allow the number of states to be inferred (Robert et al., 2000). We did not explore this approach in this paper since the progression of COPD is widely considered to occur across a fixed number of stages (GOLD Executive Committee, 2017); it is reasonable to fix the number of states for these types of data. However, we have extended our algorithm to allow the number of states to be inferred using transdimensional methods, and will report on this elsewhere. More generally, there may be health conditions that necessitate the use of a continuous latent process; Bayesian formulations for diffusion or jump processes have been studied in the context of financial data, although such formulations are not common in the analysis of health data. Latent Gaussian processes and state space models are more widely used in the context of healthcare and biomedical monitoring, and Bayesian procedures are well-established for such models (see for example West and Harrison, 1997).\n\nAnalysis based on our proposed model also has limitations. First, as shown in the simulation, when the observations are binary and sparse, this model cannot easily recover much information from the observations. Also, in general there is no guarantee that the latent states will directly correspond to the underlying biological processes or disease states. However, the inferred states may generate hypotheses about how the subjects in the data set are being managed, and what kinds of interventions may be effective at different points in their trajectories. Finally, we did not model the observation process itself, but it is possible that the timing of healthcare utilization is informative in the assessment of health status progression - this would be possible in our framework by introducing a state-specific transition rate, and assuming that the observation times are independent of the outcomes given the latent process. In this case the Poisson observation process $\\left\\{N_{s}\\right\\}_{s \\geqslant 0}$ (observed discretely at $\\tau_{t}$ ) and the CTHMM can be viewed as a Markov renewal process (Rydén, 1996). Then the likelihood contribution for $\\left\\{N_{s}\\right\\}_{s \\geqslant 0}, L(\\mathbf{N} \\mid \\mathbf{X}, \\Theta)\\left(\\mathbf{N}=\\left\\{N_{n, \\tau_{n, t}}\\right\\}\\right)$, should be included in (3),"
    },
    {
      "markdown": "and we simply need modify the calculation of $a_{n, t, k}$ and $b_{n, t, k, j}$ to incorporate this likelihood contribution, and add an additional step to estimate the state-dependent intensity parameter. We describe such a model extension in the Web Appendix B, and present a simulated example with an informative data generating process that is ignored in the inference: the simulation demonstrates that modeling the observation process may not alter the inference for the latent process to a large degree. We also did not model mechanisms for individuals leaving the cohort or being lost to follow-up, and this may be informative also, however, in the case of a chronic condition such as COPD the information contained in censoring or drop-out times may not be as critical in other settings.\n\n# ACKNOWLEDGMENTS \n\nThe authors gratefully acknowledge the Co-Editor, the Associate Editor and two referees for their constructive comments which have improved this paper. This research has been supported by the Canadian Institutes of Health Research.\n\n## Data Availability Statement\n\nData used in this paper to illustrate our findings are not shared as restrictions apply to the availability of these data, which were used under license for this study. Data related to the simulated examples are generated by the code supplied in the Supporting Information.\n\n## REFERENCES\n\nAlaa, A. M. and van der Schaar, M. (2018). A hidden absorbing semi-Markov model for informatively censored temporal data: learning and inference. Journal of Machine Learning Research 19, 1-62.\n\nAltman, R. M. (2007). Mixed hidden Markov models: An extension of the hidden Markov"
    },
    {
      "markdown": "model to the longitudinal data setting. Journal of the American Statistical Association 102, 201-210.\n\nBartolucci, F. and Farcomeni, A. (2019). A shared-parameter continuous-time hidden Markov and survival model for longitudinal data with informative dropout. Statistics in Medicine 38, 1056-1073.\n\nBartolucci, F., Farcomeni, A., and Pennoni, F. (2012). Latent Markov models for longitudinal data. Chapman and Hall/CRC.\n\nBartolucci, F., Pennoni, F., and Francis, B. (2007). A latent Markov model for detecting patterns of criminal activity. Journal of the Royal Statistical Society: Series A (Statistics in Society) 170, 115-132.\n\nBaum, L. and Petrie, T. (1966). Statistical inference for probabilistic functions of finite state Markov chains. The Annals of Mathematical Statistics 37, 1554-1563.\n\nBetancourt, M., Roberts, K., Bennett, T., Driscoll, E., Jayaraman, G., and Pelletier, L. (2014). Monitoring chronic diseases in Canada: the chronic disease indicator framework. Maladies Chroniques et Blessures au Canada 34, 1-30.\n\nBladt, M. and Sørensen, M. (2005). Statistical inference for discretely observed Markov jump processes. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 67, $395-410$.\n\nBroemeling, A.-M., Watson, D. E., and Prebtani, F. (2007). Population patterns of chronic health conditions, co-morbidity and healthcare use in Canada: implications for policy and practice. Healthcare Quarterly 11, 70-76.\n\nCentre for Chronic Disease Prevention and Control (2001). Editorial Board for Respiratory Disease in Canada. Health Canada, Ottawa.\n\nFrühwirth-Schnatter, S. (2006). Finite Mixture and Markov Switching Models. Springer Series in Statistics. Springer."
    },
    {
      "markdown": "Gold, M., Beitsch, L., Essien, J., Fleming, D., Getzen, T., Gostin, L., Isham, G., Kaplan, R., Lopez, W., and Mays, G. (2011). For the public's health: The role of measurement in action and accountability. Washington, DC: National Academies Press.\n\nGOLD Executive Committee (2017). Pocket guide to COPD diagnosis, management and prevention: A guide for health care professionals 2017 report.\n\nHobolth, A. and Stone, E. A. (2009). Simulation from endpoint-conditioned, continuoustime Markov chains on a finite state space with applications to molecular evolution. The Annals of Applied Statistics 3, 1204-1231.\n\nJackson, C. H. and Sharples, L. D. (2002). Hidden Markov models for the onset and progression of bronchiolitis obliterans syndrome in lung transplant recipients. Statistics in Medicine 21, 113-128.\n\nJackson, C. H., Sharples, L. D., Thompson, S. G., Duffy, S. W., and Couto, E. (2003). Multistate Markov models for disease progression with classification error. Journal of the Royal Statistical Society: Series D (The Statistician) 52, 193-209.\n\nJasra, A., Holmes, C. C., and Stephens, D. A. (2005). Markov chain Monte Carlo methods and the label switching problem in Bayesian mixture modeling. Statistical Science 20, $50-67$.\n\nKalbfleisch, J. and Lawless, J. F. (1985). The analysis of panel data under a Markov assumption. Journal of the American Statistical Association 80, 863-871.\n\nLange, J., Hubbard, R., Inoue, L., and Minin, V. (2015). A joint model for multi-state disease processes and random informative observation times, with applications to electronic medical records data. Biometrics 71, 90-101.\n\nRaffa, J. and Dubin, J. (2015). Multivariate longitudinal data analysis with mixed effects hidden Markov models. Biometrics 71, 821-831.\n\nRobert, C. P., Ryden, T., and Titterington, D. M. (2000). Bayesian inference in hidden"
    },
    {
      "markdown": "Markov models through the reversible jump Markov chain Monte Carlo method. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 62, 57-75.\n\nRydén, T. (1996). An EM algorithm for estimation in Markov-modulated Poisson processes. Computational Statistics \\& Data Analysis 21, 431-447.\n\nShaban-Nejad, A., Lavigne, M., Okhmatovskaia, A., and Buckeridge, D. L. (2017). PopHR: a knowledge-based platform to support integration, analysis, and visualization of population health data. Annals of the New York Academy of Sciences 1387, 44-53.\n\nSpiegelhalter, D., Best, N., Carlin, B., and Van Der Linde, A. (2002). Bayesian measures of model complexity and fit. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 64, 583-639.\n\nVerma, A. (2015). Hospital Readmissions: Prediction and Inference. PhD thesis, McGill University.\n\nWang, X., Sontag, D., and Wang, F. (2014). Unsupervised learning of disease progression models. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 85-94.\n\nWatanabe, S. (2010). Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory. Journal of Machine Learning Research 11, 3571-3594.\n\nWest, M. and Harrison, J. (1997). Bayesian forecasting and dynamic models. Springer, New York, 2nd edition.\n\nWilliams, J. P., Storlie, C. B., Therneau, T. M., Jack Jr, C. R., and Hannig, J. (2019). A Bayesian approach to multistate hidden Markov models: Application to dementia progression. Journal of the American Statistical Association pages 1-21.\n\nWulfsohn, M. S. and Tsiatis, A. A. (1997). A joint model for survival and longitudinal data measured with error. Biometrics 53, 330-339."
    },
    {
      "markdown": "# SUPPORTING INFORMATION \n\nWeb Appendices, Tables, and Figures referenced in Sections 3, 5 and 6 are available with this paper at the Biometrics website on Wiley Online Library. The package cthmmg1m to implement the proposed EM algorithm and MCMC is provided along with the instruction to install the package and run the example data."
    },
    {
      "markdown": "Figure 1. A COPD patient observed trajectory. Different symbols indicate the specific healthcare utilization that generated the observation: hospitalization (HOSP), specialist visit (SPEC), general practitioner visit (GP) and emergency department visit (ED). This figure appears in color in the electronic version of this article, and any mention of color refers to that version.\n![img-1.jpeg](img-1.jpeg)"
    },
    {
      "markdown": "Figure 2. Fully Bayesian analysis: Posterior Individual Patients Trajectories. The solid blue dots represent the time of the observations. The gray lines are the sampled posterior latent processes representing the severity of the COPD. Uncertainty about the time of transition from one state to another is indicated by the dark gray patches. This figure appears in color in the electronic version of this article, and any mention of color refers to that version.\n![img-2.jpeg](img-2.jpeg)"
    },
    {
      "markdown": "Table 1\nSimulation Study with 4 Latent States: Reconstruction rate is the proportion of times that the correct latent state is recovered at each observation time.\n\n| $T$ | Generative Process | $\\|\\pi-\\hat{\\pi}\\|_{2}$ | $\\|B-\\hat{B}\\|_{2}$ | $\\left\\|\\zeta_{0}-\\hat{\\zeta}_{0}\\right\\|_{2}$ | $\\left\\|\\xi_{1}-\\hat{\\xi}_{1}\\right\\|_{2}$ | Reconstruction Rate |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n| EM algorithm with tolerance 0.05 |  |  |  |  |  |  |\n| 20 | Gaussian | 0.05 | 0.07 | 0.73 | 1.09 | $75.69 \\%$ |\n| 50 | Gaussian | 0.04 | 0.05 | 1.33 | 0.96 | $81.34 \\%$ |\n| 100 | Gaussian | 0.02 | 0.04 | 0.98 | 0.62 | $87.04 \\%$ |\n| 20 | Bernoulli | 0.06 | 0.71 | 1.82 | 2.96 | $42.56 \\%$ |\n| 50 | Bernoulli | 0.03 | 0.74 | 2.01 | 1.89 | $44.58 \\%$ |\n| 100 | Bernoulli | 0.06 | 1.53 | 1.73 | 1.42 | $47.56 \\%$ |\n| 500 | Bernoulli | 0.15 | 0.45 | 1.87 | 1.24 | $62.07 \\%$ |\n| 20 | Binomial (size=5) | 0.09 | 0.73 | 1.73 | 2.79 | $52.26 \\%$ |\n| 50 | Binomial (size=5) | 0.12 | 0.50 | 1.89 | 1.49 | $57.82 \\%$ |\n| 100 | Binomial (size=5) | 0.17 | 0.37 | 1.65 | 1.57 | $67.40 \\%$ |\n| 20 | Poisson | 0.03 | 0.04 | 1.14 | 0.67 | $90.08 \\%$ |\n| 50 | Poisson | 0.06 | 0.04 | 0.81 | 0.86 | $93.54 \\%$ |\n| 100 | Poisson | 0.03 | 0.01 | 0.25 | 0.23 | $96.25 \\%$ |\n| MCMC with 2000 iterations and 1000 burn-in iterations |  |  |  |  |  |  |\n| 20 | Gaussian | 0.03 | 0.15 | 0.42 | 0.06 | $69.96 \\%$ |\n| 50 | Gaussian | 0.04 | 0.05 | 0.22 | 0.09 | $76.78 \\%$ |\n| 100 | Gaussian | 0.02 | 0.04 | 0.33 | 0.26 | $83.95 \\%$ |\n| 20 | Bernoulli | 0.16 | 0.86 | 1.03 | 0.14 | $41.17 \\%$ |\n| 50 | Bernoulli | 0.13 | 0.47 | 0.95 | 0.36 | $45.28 \\%$ |\n| 100 | Bernoulli | 0.09 | 0.58 | 1.23 | 0.22 | $47.70 \\%$ |\n| 500 | Bernoulli | 0.07 | 0.09 | 0.39 | 0.29 | $64.06 \\%$ |\n| 20 | Binomial (size=5) | 0.09 | 0.14 | 0.15 | 0.15 | $54.30 \\%$ |\n| 50 | Binomial (size=5) | 0.04 | 0.11 | 0.21 | 0.08 | $59.81 \\%$ |\n| 100 | Binomial (size=5) | 0.08 | 0.09 | 0.20 | 0.20 | $64.85 \\%$ |\n| 20 | Poisson | 0.05 | 0.02 | 0.59 | 0.28 | $87.47 \\%$ |\n| 50 | Poisson | 0.02 | 0.03 | 0.22 | 0.17 | $92.13 \\%$ |\n| 100 | Poisson | 0.04 | 0.02 | 0.11 | 0.12 | $95.25 \\%$ |"
    },
    {
      "markdown": "Table 2\nModel Selection Criterion Comparison (\\% of times the correct number of latent states is selected)\n\n|  | Case 1 |  |  | Case 2 |  |  | Case 3 |  |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n| \\# of Hidden States | 2 | 3 | 4 | 2 | 3 | 4 | 2 | 3 | 4 |\n| EM Algorithm |  |  |  |  |  |  |  |  |  |\n| AIC | $0.0 \\%$ | 16.0\\% | $84.0 \\%$ | $0.0 \\%$ | 9.0\\% | $91.0 \\%$ | $0.0 \\%$ | 5.0\\% | $95.0 \\%$ |\n| BIC | $0.0 \\%$ | 93.0\\% | $7.0 \\%$ | $0.0 \\%$ | 90.0\\% | $10.0 \\%$ | $0.0 \\%$ | 76.0\\% | $24.0 \\%$ |\n| MCMC |  |  |  |  |  |  |  |  |  |\n| WAIC | $0.0 \\%$ | 96.0\\% | $4.0 \\%$ | $0.0 \\%$ | 87.0\\% | $13.0 \\%$ | $3.0 \\%$ | 68.0\\% | $29.0 \\%$ |\n| DIC | $0.0 \\%$ | 96.0\\% | $4.0 \\%$ | $0.0 \\%$ | 92.0\\% | $8.0 \\%$ | $3.0 \\%$ | 69.0\\% | $28.0 \\%$ |"
    },
    {
      "markdown": "Table 3\nEM Analysis: Exponential of B Coefficients (Parameters in the GLM for each state.)\n\n| Variables | State 1 | State 2 | State 3 |\n| :--: | :--: | :--: | :--: |\n| Intercept | 0.11 | 4.22 | 10.22 |\n| (95\\% CI) | $(0.10,0.11)$ | $(4.20,4.24)$ | $(10.19,10.25)$ |\n| GP | 3.14 | 0.98 | 0.96 |\n| (95\\% CI) | $(3.04,3.27)$ | $(0.97,0.98)$ | $(0.96,0.96)$ |\n| HOSP | 1.20 | 0.96 | 0.96 |\n| (95\\% CI) | $(1.14,1.27)$ | $(0.95,0.96)$ | $(0.96,0.97)$ |\n| SPEC | 1.85 | 0.95 | 0.96 |\n| (95\\% CI) | $(1.76,1.94)$ | $(0.95,0.96)$ | $(0.96,0.97)$ |"
    },
    {
      "markdown": "Table 4\nResults of the fully Bayesian analysis: Posterior Mean and 95\\% Credible Interval for coefficients $\\xi_{0}$ (intercept) and $\\xi_{1}$ (age) for each element of the rate individualized rate matrix.\n\n| Parameter | Posterior <br> Mean | $95 \\%$ Credible Interval |\n| :--: | :--: | :--: |\n| $\\xi_{0,12}$ | -1.303 | $(-1.492,-1.117)$ |\n| $\\xi_{0,13}$ | -5.956 | $(-6.237,-5.714)$ |\n| $\\xi_{0,21}$ | -3.769 | $(-3.966,-3.574)$ |\n| $\\xi_{0,23}$ | -4.891 | $(-5.081,-4.714)$ |\n| $\\xi_{0,31}$ | -5.817 | $(-6.042,-5.604)$ |\n| $\\xi_{0,32}$ | -4.375 | $(-4.647,-4.100)$ |\n| $\\xi_{1,12}$ | 0.001 | $(-0.002,0.003)$ |\n| $\\xi_{1,13}$ | 0.043 | $(0.039,0.047)$ |\n| $\\xi_{1,21}$ | 0.023 | $(0.021,0.026)$ |\n| $\\xi_{1,23}$ | 0.040 | $(0.037,0.042)$ |\n| $\\xi_{1,31}$ | 0.045 | $(0.043,0.048)$ |\n| $\\xi_{1,32}$ | 0.029 | $(0.026,0.033)$ |"
    },
    {
      "markdown": "# Supporting Information for \"Bayesian Latent Multi-State Modeling for Non-Equidistant Longitudinal Electronic Health Records\" \n\nby\n\nYu Luo ${ }^{1}$, David A. Stephens ${ }^{1}$, Aman Verma ${ }^{2}$, David L. Buckeridge ${ }^{2}$<br>${ }^{1}$ Department of Mathematics and Statistics<br>${ }^{2}$ Department of Epidemiology, Biostatistics and Occupational Health<br>McGill University, Quebec, Canada\n\nThis paper has been submitted for consideration for publication in Biometrics"
    },
    {
      "markdown": "# 1. Web Appendix A: The EM algorithm \n\nThe CTHMM-GLM model is characterized by the initial distribution and infinitesimal generator of the continuous-time Markov process and the GLM parameters. To obtain maximum likelihood estimators, we develop an expectation-maximization (EM) algorithm (Dempster et al., 1977) by treating the complete trajectory of latent Markov process $\\left\\{X_{s}\\right\\}$ as missing data. The likelihood computation, and hence implementation of Bayesian inference, is facilitated by this data augmentation approach. The EM approach is relatively straightforward to implement, and is useful for obtaining starting values for the MCMC algorithm. We have made our R package cthmmglm to implement the proposed method available on GitHub, with both the EM and Bayesian choices.\n\nRecall that the likelihood relating to the CTHMM component can be written\n\n$$\nL(\\mathbf{X} \\mid \\Theta)=\\prod_{n=1}^{N} \\pi_{X_{n, 0}}\\left[\\prod_{t=1}^{T_{n}-1} \\prod_{l=1}^{K} \\prod_{m \\neq l} q_{n, l, m}^{N_{n, l, m}\\left(\\Delta_{n, t}\\right)} \\exp \\left\\{-q_{n, l, m} R_{n, l}\\left(\\Delta_{n, t}\\right)\\right\\}\\right]\n$$\n\nwhere $N_{l, m}(\\tau)$ is the number of transitions from state $l$ to state $m$ in the time interval $[0, \\tau]$ and $R_{l}(\\tau)=\\int_{0}^{\\tau} \\mathbb{1}\\left(X_{s}=l\\right) d s$ is the total time that the process has spent in state $l$ in $[0, \\tau]$. The quantities $N_{l, m}(\\tau)$ are unobserved, but can be computed given a realization of the latent process on $[0, \\tau]$. The R package msm (Jackson, 2011) uses numerical optimization algorithms (e.g. Nelder-Mead or quasi-Newton approaches) to maximize the likelihood. We propose an EM algorithm which involves calculating the conditional expectation of $N$ and $R$, which can be achieved via an eigendecomposition of $Q$. This leads to an analytic solution to the maximization step for $Q$ in the absence of covariates.\n\nThe log-likelihood written in terms of the latent state indicator random vectors $\\left\\{S_{k}\\right\\}_{k=1}^{K}$ is\n\n$$\n\\begin{aligned}\n& \\ell(\\Theta)=\\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}} \\sum_{k=1}^{K} S_{n, t, k} \\log f\\left(O_{n, t} \\mid S_{n, t, k}\\right)+\\sum_{n=1}^{N} \\sum_{k=1}^{K} S_{n, 1, k} \\log \\left(\\pi_{k}\\right) \\\\\n&+\\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}-1} \\sum_{k=1}^{K} \\sum_{j=1}^{K} S_{n, t, k} S_{n, t+1, j} r_{n, t}^{k, j}\n\\end{aligned}\n$$"
    },
    {
      "markdown": "where\n\n$$\nr_{n, l}^{k, j}=\\sum_{l=1}^{K} \\sum_{m \\neq l}\\left\\{N_{n, l, m}^{k, j}\\left(\\Delta_{n, t}\\right) \\mathbf{W}_{\\mathbf{n}}{ }^{\\top} \\xi_{l m}-\\exp \\left(\\mathbf{W}_{\\mathbf{n}}{ }^{\\top} \\xi_{l m}\\right) R_{n, l}^{k, j}\\left(\\Delta_{n, t}\\right)\\right\\}\n$$\n\nrecords the probability of transition from state $k$ to state $j$ in the interval $\\Delta_{n, t}=\\tau_{n, t+1}-\\tau_{n, t}$, and $N_{n, l, m}^{k, j}\\left(\\Delta_{n, t}\\right)$ and $R_{n, l}^{k, j}\\left(\\Delta_{n, t}\\right)$ are the number of jumps from state $l$ to state $m$ and time spent in state $l$ for a Markov chain initiated at state $k$ and ended at state $j$.\n\n# 1.1 Expectation Step \n\nFor $1 \\leqslant k \\leqslant K$, let\n\n$$\na_{n, t, k}^{\\mathrm{old}}=\\mathbb{E}\\left[S_{n, t, k} \\mid O ; \\Theta^{\\mathrm{old}}\\right]=\\mathbb{P}\\left(S_{n, t, k}=1 \\mid O ; \\Theta^{\\mathrm{old}}\\right)=\\sum_{j=1}^{K} b_{n, t, k, j}^{\\mathrm{old}}\n$$\n\nsay, since $S_{n, t, k}$ is an indicator variable, where $b_{n, t, k, j}^{\\mathrm{old}}=\\mathbb{P}\\left(S_{n, t, k}=S_{n, t+1, j}=1 \\mid O ; \\Theta^{\\mathrm{old}}\\right)$. Let\n\n$$\nU\\left(\\Theta, \\Theta^{\\mathrm{old}}\\right)=\\mathbb{E}_{S \\mid O ; \\Theta^{\\mathrm{old}}}\\left[\\ell(\\Theta) \\mid O ; \\Theta^{\\mathrm{old}}\\right]\n$$\n\nbe the expected complete data likelihood. The conditional expectation is then\n\n$$\n\\begin{aligned}\n& U\\left(\\Theta, \\Theta^{\\mathrm{old}}\\right)=\\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}} \\sum_{k=1}^{K} a_{n, t, k}^{\\mathrm{old}}\\left(\\Theta^{\\mathrm{old}}\\right) \\log f\\left(O_{n, t} \\mid S_{n, t, k}\\right)+\\sum_{n=1}^{N} \\sum_{k=1}^{K} a_{n, 1, k}^{\\mathrm{old}} \\log \\left(\\pi_{k}\\right) \\\\\n&+\\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}-1} \\sum_{k=1}^{K} \\sum_{j=1}^{K} \\mathbb{E}\\left(S_{n, t, k} S_{n, t+1, j} r_{n, t}^{k, j} \\mid O ; \\Theta^{\\mathrm{old}}\\right) \\\\\n&=\\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}} \\sum_{k=1}^{K} a_{n, t, k}^{\\mathrm{old}} \\log f\\left(O_{n, t} \\mid S_{n, t, k}\\right)+\\sum_{n=1}^{N} \\sum_{k=1}^{K} a_{n, 1, k}^{\\mathrm{old}} \\log \\left(\\pi_{k}\\right) \\\\\n&+\\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}-1} \\sum_{k=1}^{K} \\sum_{j=1}^{K} b_{n, t, k, j}^{\\mathrm{old}} \\mathbb{E}\\left(r_{n, t}^{k, j} \\mid I_{n, t, k, j}=1 ; \\Theta^{\\mathrm{old}}\\right)\n\\end{aligned}\n$$\n\nwhere $I_{n, t, k, j}=S_{n, t, k} S_{n, t+1, j}$ is an indicator random variable, and $b_{n, t, k, j}^{\\text {old }}=\\mathbb{P}\\left(I_{n, t, k, j}=\\right.$ $1 \\mid O ; \\Theta^{\\text {old }}$ ) is its expectation. Therefore,\n\n$$\n\\begin{aligned}\nU\\left(\\Theta, \\Theta^{\\mathrm{old}}\\right) & =\\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}} \\sum_{k=1}^{K} a_{n, t, k}^{\\mathrm{old}} \\log f\\left(O_{n, t} \\mid S_{n, t, k}\\right)+\\sum_{n=1}^{N} \\sum_{k=1}^{K} a_{n, t, k}^{\\mathrm{old}} \\log \\left(\\pi_{k}\\right) \\\\\n& +\\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}-1} \\sum_{k=1}^{K} \\sum_{j=1}^{K} b_{n, t, k, j}^{\\mathrm{old}} \\times \\mathbb{E}\\left(p_{n, t}^{k, j} \\mid S_{n, t, k}=S_{n, t+1, j}=1 ; \\Theta^{\\mathrm{old}}\\right)\n\\end{aligned}\n$$"
    },
    {
      "markdown": "# 1.2 Maximization Step \n\nThe goal of M-step is to achieve the maximization\n\n$$\n\\max _{\\Theta} U\\left(\\Theta, \\Theta^{\\mathrm{old}}\\right)\n$$\n\nHowever $\\left(B, \\phi^{2}\\right)$ and $\\left(\\xi_{l m}, \\pi\\right)$ are separable in $U\\left(\\Theta, \\Theta^{\\text {old }}\\right)$, then the maximization can be separated into the following sub-problems.\n\n$$\n\\begin{aligned}\n& \\max _{B} \\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}} \\sum_{k=1}^{K} a_{n, t, k}^{\\mathrm{old}} \\log f\\left(O_{n, t} \\mid S_{n, t, k}\\right) \\\\\n& \\max _{B} \\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}} \\sum_{k=1}^{K} a_{n, t, k}^{\\mathrm{old}}\\left[\\left\\{O_{n, t} \\theta_{X_{n, \\tau_{n, t}}}-b\\left(\\theta_{X_{n, \\tau_{n, t}}}\\right)\\right\\} / \\phi^{2}+c\\left(O_{n, t}, \\phi\\right)\\right]\n\\end{aligned}\n$$\n\nThis procedure is identical to that used in obtaining the maximum likelihood estimate (MLE) of coefficients in GLM except for that the weighting parameter $a_{n, t, k}^{\\text {old }}$ and the procedure of parameter estimation, for example Newton-Raphson method and Fisher scoring, can be applied.\n\n$$\n\\max _{\\xi_{l m}} \\sum_{n=1}^{N} \\sum_{t=1}^{T_{n-1}} \\sum_{k=1}^{K} \\sum_{j=1}^{K} b_{n, t, k, j}^{\\mathrm{old}} \\times \\mathbb{E}\\left(\\tau_{n, t}^{k, j} \\mid S_{n, t, k}=S_{n, t+1, j}=1 ; \\Theta^{\\mathrm{old}}\\right)\n$$\n\n$\\xi_{l m}$ cannot be solved analytically but numerical algorithms, like Newton's method and quasi-Newton's method, can be applied to find the maximizers. The conditional expectation of the random quantities $N_{n, l, m}^{k, j}\\left(\\Delta_{n, t}\\right)$ and $R_{n, l}^{k, j}\\left(\\Delta_{n, t}\\right)$ can be expressed as\n\n$$\n\\begin{aligned}\n& \\mathbb{E}\\left[N_{n, l, m}^{k, j}\\left(\\Delta_{n, t}\\right) \\mid S_{n, t, k}=S_{n, t+1, j}=1\\right] \\\\\n& =\\frac{q_{n, l, m}}{p_{n, k j}\\left(\\Delta_{n, t}\\right)} \\int_{\\tau_{n, t}}^{\\tau_{n, t+1}} p_{n, k l}\\left(s-\\tau_{n, t}\\right) p_{n, m j}\\left(\\tau_{n, t+1}-s\\right) d s \\\\\n& \\mathbb{E}\\left[R_{n, l}^{k, j}\\left(\\Delta_{n, t}\\right) \\mid S_{n, t, k}=S_{n, t+1, j}=1\\right] \\\\\n& =\\frac{1}{p_{n, k j}\\left(\\Delta_{n, t}\\right)} \\int_{\\tau_{n, t}}^{\\tau_{n, t+1}} p_{n, k l}\\left(s-\\tau_{n, t}\\right) p_{n, l j}\\left(\\tau_{n, t+1}-s\\right) d s\n\\end{aligned}\n$$\n\nAn eigendecomposition of the generator $Q$ can lead to closed form expressions of the"
    },
    {
      "markdown": "integrals (Metzner et al., 2007). Let $Q$ have an eigendecomposition $Q=U \\Lambda U^{-1}$, where the columns of the matrix $U$ consist of all eigenvectors to the corresponding eigenvalues of $Q$ in the diagonal matrix of eigenvalues $\\Lambda=\\operatorname{diag}\\left(\\lambda_{1}, \\ldots, \\lambda_{K}\\right)$. The integrals have closed form solutions:\n\n$$\n\\begin{aligned}\n& \\int_{\\tau_{n, t}}^{\\tau_{n, t+1}} p_{k l}\\left(s-\\tau_{n, t}\\right) p_{m j}\\left(\\tau_{n, t+1}-s\\right) d s=\\sum_{p=1}^{K} \\frac{u_{k p}}{u_{p l}} \\sum_{q=1}^{K} \\frac{u_{m q}}{u_{q j}} \\psi_{p q}\\left(\\Delta_{n, t}\\right) \\\\\n& \\int_{\\tau_{n, t}}^{\\tau_{n, t+1}} p_{k l}\\left(s-\\tau_{n, t}\\right) p_{l j}\\left(\\tau_{n, t+1}-s\\right) d s=\\sum_{p=1}^{K} \\frac{u_{k p}}{u_{p l}} \\sum_{q=1}^{K} \\frac{u_{m q}}{u_{q j}} \\psi_{p q}\\left(\\Delta_{n, t}\\right)\n\\end{aligned}\n$$\n\nwhere\n\n$$\n\\psi_{p q}\\left(\\Delta_{n, t}\\right)= \\begin{cases}\\Delta_{n, t} e^{\\Delta_{n, t} \\lambda_{p}} & \\lambda_{p}=\\lambda_{q} \\\\ \\frac{e^{\\Delta_{n, t} \\lambda_{p}}-\\frac{\\Delta_{n, t} \\lambda_{q}}{\\lambda_{p}-\\lambda_{q}}}{\\lambda_{p} \\neq \\lambda_{q}} & \\lambda_{p} \\neq \\lambda_{q}\\end{cases}\n$$\n\nTherefore,\n\n$$\n\\begin{aligned}\n\\mathbb{E}\\left[N_{n, l, m}^{k, j}\\left(\\Delta_{n, t}\\right)\\left|S_{n, t, k}=S_{n, t+1, j}=1, Q_{n}^{\\text {old }}\\right|=\\right. & \\frac{q_{n, l, m}^{\\text {old }}}{e^{\\Delta_{n, t}}} q_{n, k, j}^{\\text {old }} \\sum_{p=1}^{K} \\frac{u_{n, k p}}{u_{n, p l}} \\sum_{q=1}^{K} \\frac{u_{n, m q}}{u_{n, q j}} \\psi_{n, p q}\\left(\\Delta_{n, t}\\right) \\\\\n\\mathbb{E}\\left[R_{n, l}^{k, j}\\left(\\Delta_{n, t}\\right)\\left|S_{n, t, k}=S_{n, t+1, j}=1, Q_{n}^{\\text {old }}\\right|=\\right. & \\frac{1}{e^{\\Delta_{n, t}} q_{n, k, j}^{\\text {old }}} \\sum_{p=1}^{K} \\frac{u_{n, k p}}{u_{n, p l}} \\sum_{q=1}^{K} \\frac{u_{n, l q}}{u_{n, q j}} \\psi_{n, p q}\\left(\\Delta_{n, t}\\right)\n\\end{aligned}\n$$\n\n(3) Initial probabilities:\n\n$$\n\\begin{aligned}\n& \\max _{\\pi} \\sum_{n=1}^{N} \\sum_{k=1}^{K} a_{n, 1, k}^{\\text {old }} \\log \\left(\\pi_{k}\\right) \\\\\n& \\text { s.t. } \\sum_{k=1}^{K} \\pi_{k}=1 \\quad 0 \\leqslant \\pi_{k} \\leqslant 1, \\quad k=1, \\ldots, K\n\\end{aligned}\n$$\n\nTherefore,\n\n$$\n\\pi_{k}=\\frac{\\sum_{n=1}^{N} a_{n, 1, k}^{\\text {old }}}{\\sum_{n=1}^{N} \\sum_{i=1}^{K} a_{n, 1, i}^{\\text {old }}}\n$$\n\n(4) Finally, the $\\left(a_{n, t, k}, b_{n, t, k, j}\\right)$ can be obtained by the forward-backward algorithm (Baum and Eagon, 1967; Baum and Sell, 1968). The forward variable $\\alpha_{n, t, k}$ is defined as $\\alpha_{n, t, k}=$ $\\mathbb{P}\\left(O_{n, 1}, \\ldots, O_{n, t}, X_{n, \\tau_{n, t}}=k\\right)$."
    },
    {
      "markdown": "Let $O_{n}^{(t)}=\\left(O_{n, 1}, \\ldots, O_{n, t}\\right)$. Then\n\n$$\n\\begin{aligned}\n& \\mathbb{P}\\left(O_{n, 1}, \\ldots, O_{n, t}, X_{n, \\tau_{n, t}}=k\\right) \\\\\n& =\\mathbb{P}\\left(O_{n, t} \\mid X_{n, \\tau_{n, t}}=k, O_{n}^{(t-1)}\\right) \\mathbb{P}\\left(O_{n}^{(t-1)}, X_{n, \\tau_{n, t}}=k\\right) \\\\\n& =f\\left(O_{n, t} \\mid X_{n, \\tau_{n, t}}=k\\right) \\times \\sum_{i=1}^{K} \\mathbb{P}\\left(O_{n}^{(t-1)}, X_{n, \\tau_{n, t}}=k, X_{n, \\tau_{n, t-1}}=i\\right) \\\\\n& =f\\left(O_{n, t} \\mid X_{n, \\tau_{n, t}}=k\\right) \\\\\n& \\times \\sum_{i=1}^{K} \\mathbb{P}\\left(O_{n}^{(t-1)}, X_{n, \\tau_{n, t-1}}=i\\right) \\mathbb{P}\\left(X_{n, \\tau_{n, t}}=k \\mid X_{n, \\tau_{n, t-1}}=i\\right) \\\\\n& =f\\left(O_{n, t} \\mid X_{n, \\tau_{n, t}}=k\\right) \\times \\sum_{i=1}^{K} \\alpha_{n, t-1, i} p_{n, t k}\\left(\\Delta_{n, t-1}\\right)\n\\end{aligned}\n$$\n\nThe initialized value $\\alpha_{n, 1, k}=\\pi_{k} \\times f\\left(O_{n, 1} \\mid X_{n, \\tau_{n, 1}}=k\\right)$. The backward variable $\\gamma_{n, t, k}$ is defined as $\\gamma_{n, t, k}=\\mathbb{P}\\left(O_{n, T}, \\ldots, O_{n, t+1} \\mid X_{\\tau_{n, t}}=k\\right)$.\n\nLet $\\overleftarrow{O}_{n}^{(t)}=\\left(O_{n, T}, \\ldots, O_{n, t+1}\\right)$. Then\n\n$$\n\\begin{aligned}\n& \\mathbb{P}\\left(O_{n, T}, \\ldots, O_{n, t+1} \\mid X_{\\tau_{n, t}}=k\\right) \\\\\n& =\\sum_{i=1}^{K} \\mathbb{P}\\left(\\overleftarrow{O}_{n}^{(t)}, X_{\\tau_{n, t+1}}=i \\mid X_{\\tau_{n, t}}=k\\right) \\\\\n& =\\sum_{i=1}^{K} \\mathbb{P}\\left(\\overleftarrow{O}_{n}^{(t)} \\mid X_{\\tau_{n, t+1}}=i, X_{\\tau_{n, t}}=k\\right) \\times \\mathbb{P}\\left(X_{\\tau_{n, t+1}}=i \\mid X_{\\tau_{n, t}}=k\\right) \\\\\n& =\\sum_{i=1}^{K} \\mathbb{P}\\left(O_{n, t+1} \\mid X_{\\tau_{n, t+1}}=i\\right) \\mathbb{P}\\left(\\overleftarrow{O}_{n}^{(t+1)} \\mid X_{\\tau_{n, t+1}}=i\\right) \\times p_{n, k t}\\left(\\Delta_{n, t}\\right) \\\\\n& =\\sum_{i=1}^{K} f\\left(O_{n, t+1} \\mid X_{\\tau_{n, t+1}}=i\\right) \\times \\gamma_{n, t+1, i} p_{n, k t}\\left(\\Delta_{n, t}\\right)\n\\end{aligned}\n$$\n\nThe first backward value $\\gamma_{n, T, k}$ is initialized to 1 for all $n$ and $k$. Then, for $t=$ $1, \\ldots, T_{n}-1$, define\n\n$$\nb_{n, t, k, j}=\\mathbb{P}\\left(S_{n, t, k}=S_{n, t+1, j}=1 \\mid O\\right)\n$$"
    },
    {
      "markdown": "Define $\\vec{O}_{n}^{(t)}=\\left(O_{n, t}, \\ldots, O_{n, T}\\right)$. Then\n\n$$\n\\begin{aligned}\nb_{n, t, k, j} & =\\mathbb{P}\\left(X_{n, \\tau_{n, t}}=k, X_{n, \\tau_{n, t+1}}=j \\mid O\\right) \\\\\n& =\\frac{\\mathbb{P}\\left(X_{n, \\tau_{n, t}}=k, X_{n, \\tau_{n, t+1}}=j, \\vec{O}_{n}^{(1)}\\right)}{\\sum_{l=1}^{K} \\sum_{m=1}^{K} \\mathbb{P}\\left(X_{n, \\tau_{n, t}}=m, X_{n, \\tau_{n, t+1}}=l, \\vec{O}_{n}^{(1)}\\right)} \\\\\n& =\\frac{\\mathbb{P}\\left(\\vec{O}_{n}^{(t+1)}, X_{n, \\tau_{n, t+1}}=j \\mid X_{n, \\tau_{n, t}}=k, O_{n}^{(t)}\\right) \\mathbb{P}\\left(X_{n, \\tau_{n, t}}=k, O_{n}^{(t)}\\right)}{\\sum_{l=1}^{K} \\sum_{m=1}^{K} \\mathbb{P}\\left(\\vec{O}_{n}^{(t+1)}, X_{n, \\tau_{n, t+1}}=l \\mid X_{n, \\tau_{n, t}}=m, O_{n}^{(t)}\\right) \\mathbb{P}\\left(X_{n, \\tau_{n, t}}=m, O_{n}^{(t)}\\right)} \\\\\n& =\\frac{f\\left(O_{n, t+1} \\mid X_{n, \\tau_{n, t+1}}=j\\right) \\times \\gamma_{n, t+1, j} \\times p_{n, k j}\\left(\\Delta_{n, t}\\right) \\alpha_{n, t, k}}{\\sum_{l=1}^{K} \\sum_{m=1}^{K} f\\left(O_{n, t+1} \\mid X_{n, \\tau_{n, t+1}}=l\\right) \\times \\gamma_{n, t+1, l} \\times p_{n, m j}\\left(\\Delta_{n, t}\\right) \\alpha_{n, t, m}}\n\\end{aligned}\n$$\n\nwith $a_{n, t, k}=\\sum_{j=1}^{K} b_{n, t, k, j}$. For $t=T_{n}$,\n\n$$\na_{n, T_{n}, k}=\\mathbb{P}\\left(X_{\\tau_{n, T_{n}}}=k \\mid O\\right)=\\frac{\\mathbb{P}\\left(X_{\\tau_{n, T_{n}}}=k, O_{n}^{\\left(T_{n}\\right)}\\right)}{\\sum_{j=1}^{K} \\mathbb{P}\\left(X_{\\tau_{n, T_{n}}}=j, O_{n}^{\\left(T_{n}\\right)}\\right)}=\\frac{\\alpha_{n, T_{n}, k}}{\\sum_{j=1}^{K} \\alpha_{n, T_{n}, j}}\n$$\n\n# 2. Web Appendix B: Incorporating informative observation visit time \n\nOne limitation of the proposed model is that it assumed that the observation process (that is, the times that the observations are made) are uninformative in relation to the latent health trajectory. To incorporate informative observation times and assuming that the observation times are conditionally independent of the outcomes given the latent process, the observation process, denoted $N_{s}$ having state space $\\{0,1, \\ldots, \\infty\\}$, and the CTHMM can be viewed as a Markov renewal process (Rydén, 1996). We need modify the calculation of $a_{n, t, k}$ and $b_{n, t, k, j}$ to incorporate the likelihood contribution of the observation process and add an additional step to estimate the state-dependent intensity parameter.\n\nIf a state-dependent homogeneous Poisson process is chosen to model the observation process, then a bivariate time-homogeneous continuous-time Markov chain (Mark and Ephraim, 2013), $Y_{s}=\\left(X_{s}, N_{s}\\right)$, is defined with state process\n\n$$\n\\{(1,0),(2,0), \\ldots,(K, 0),(1,1), \\ldots,(K, 1), \\ldots,(1, \\infty), \\ldots,(K, \\infty)\\}\n$$\n\nSpecifically, we are interested in the first passage time $W_{i 0, j 1}$ as this has the same distribution"
    },
    {
      "markdown": "of the absorption time of an auxiliary process $Y_{s}^{\\prime}$, with rate matrix (Lange et al., 2015)\n\n$$\n\\left(\\begin{array}{cc}\nQ-\\Lambda & \\Lambda \\\\\n0 & 0\n\\end{array}\\right)\n$$\n\nwhere $\\Lambda=\\operatorname{diag}\\left(\\lambda_{1}, \\ldots, \\lambda_{K}\\right)$ and $\\lambda_{i}$ is the rate of the point process when $X_{s}=i$. Therefore, the likelihood contribution of $W_{i 0, j 1}$ for interval $\\left[\\tau_{t}, \\tau_{t+1}\\right]$ is\n\n$$\nv_{i 0, j 1}\\left(\\Delta_{t}\\right):=\\exp \\left\\{(Q-\\Lambda) \\Delta_{t}\\right\\}_{i j} \\times \\lambda_{j}\n$$\n\nTherefore, the forward variable $\\alpha_{n, t, k}$ is modified as\n\n$$\n\\alpha_{n, t, k}=\\mathbb{P}\\left(O_{n}^{(t)}, N_{n}^{(t)}, X_{n, \\tau_{n, t}}=k\\right)=f\\left(O_{n, t} \\mid X_{n, \\tau_{n, t}}=k\\right) \\times \\sum_{i=1}^{K} \\alpha_{n, t-1, i} p_{n, i k}\\left(\\Delta_{n, t-1}\\right) v_{i 0, k 1}\\left(\\Delta_{n, t-1}\\right)\n$$\n\nSimilarly, the backward variable $\\gamma_{n, t, k}$ is modified as\n\n$$\n\\gamma_{n, t, k}=\\mathbb{P}\\left(\\overleftrightarrow{O}_{n}^{(t)}, \\overleftrightarrow{N}_{n}^{(t)} \\mid X_{\\tau_{n, t}}=k\\right)=\\sum_{i=1}^{K} f\\left(O_{n, t+1} \\mid X_{\\tau_{n, t+1}}=i\\right) \\times \\gamma_{n, t+1, i} p_{n, k i}\\left(\\Delta_{n, t}\\right) v_{k 0, i 1}\\left(\\Delta_{n, t}\\right)\n$$\n\nFinally, with the modified $\\alpha_{n, t, k}$ and $\\gamma_{n, t, k}$, the $b_{n, t, k, j}$ is redefined in the same fashion,\n\n$$\n\\begin{aligned}\nb_{n, t, k, j} & =\\mathbb{P}\\left(X_{n, \\tau_{n, t}}=k, X_{n, \\tau_{n, t+1}}=j \\mid O, N\\right) \\\\\n& =\\frac{f\\left(O_{n, t+1} \\mid X_{n, \\tau_{n, t+1}}=j\\right) \\times v_{k 0, j 1}\\left(\\Delta_{n, t}\\right) \\gamma_{n, t+1, j} p_{n, k j}\\left(\\Delta_{n, t}\\right) \\alpha_{n, t, k}}{\\sum_{l=1}^{K} \\sum_{m=1}^{K} f\\left(O_{n, t+1} \\mid X_{n, \\tau_{n, t+1}}=l\\right) \\times v_{m 0, l 1}\\left(\\Delta_{n, t}\\right) \\gamma_{n, t+1, l} p_{n, m j}\\left(\\Delta_{n, t}\\right) \\alpha_{n, t, m}}\n\\end{aligned}\n$$\n\n# 3. Web Appendix C: Simulations \n\n### 3.1 $N \\sim \\operatorname{Uniform}(10,90)$\n\nWe used the same configuration in the Example 1 from the paper, and performed a simulation study where the number of observations per subject is uniformly generated between 10 and 90 to connect with the real data analysis. A Gaussian distribution is used as the observation process with a standard deviation of 1 . The tolerance for the EM algorithm is 0.005 , and MCMC is implemented with 2000 and 9000 iterations and 1000 burn-in iterations.\n\nThe results are shown in Table 1. As the number of observations per subject varies with mean 50.62 , the results are similar to the Example 1 when $N=50$ (Gaussian case) in the"
    },
    {
      "markdown": "main paper. The reconstruction rates are around $80 \\%$ demonstrating that both the EM algorithm and the Bayesian approach perform well.\n\n# 3.2 State-dependent Poisson process for informative visit time \n\nIn this example, we assume that the observations are triggered according to a state-dependent Poisson process with the rates for State 1 to 4 at $2,3,2.5,3.5$, respectively. This leads to the simulated data with on average 40 observations per subject. A Gaussian distribution is used as the observation process with a standard deviation of 1 . We fit the model without accounting for the informative observation time using the EM algorithm and MCMC.\n\nThe simulation results are shown in Table 1. The MCMC algorithm is implemented with 2000 and 9000 iterations, respectively, and both with 1000 burn-in iterations. The results between EM and MCMC are similar, and overall performance of the algorithm is good as norm differences between the estimates and true values are small. The results for $B$ and $\\pi$ are similar to Example 3.1. However, we notice that estimation performance for $\\xi_{0}$ and $\\xi_{1}$ is slightly worse than the previous example as the effect of the state-dependent Poisson process was ignored in the algorithm.\n\n### 3.3 $\\pi$ depends on $W$\n\nAdditionally, based on Example 3.1, we added coefficients that the initial distribution $\\pi$ depends on $W$, where a multinomial logistic regression is fit with coefficients\n\n$$\n\\mathbf{C}=\\left(\\begin{array}{cc}\n-0.8 & 0.0 \\\\\n-0.5 & 0.0 \\\\\n1.0 & 0.5\n\\end{array}\\right)\n$$\n\nwith State 1 chosen as the reference category.\nThe simulation results are shown in Table 1. The MCMC algorithm is implemented with 2000 and 9000 iterations, respectively, and both with 1000 burn-in iterations. As extra parameters are added in, the discrepancies between estimated $\\mathbf{C}$ and true $\\mathbf{C}$ are greater than"
    },
    {
      "markdown": "those of original parameterization $\\pi$. The results obtained for 3000 and 10000 iterations are similar.\n[Table 1 about here.]\n\n# 3.4 EM comparison between our method and Bartolucci and Farcomeni (2019) \n\nBartolucci and Farcomeni (2019) proposed a shared-parameter approach for jointly modeling longitudinal and survival data, where the random effect follows a time-continuous Markov process. For estimation, the authors introduced a method based on a discretization of the time scale in a certain number of windows, $M$, of a certain length and on an extension of the Baum-Welch recursions (Baum et al., 1970) using the EM algorithm. Although Bartolucci and Farcomeni (2019) considered equidistant longitudinal data, their model can also be used with time points that are not equally spaced. We compare our EM method based on exact continuous time formulation with their discrete approximation EM algorithm. The data are generated according to the scheme described in Section 4 of Bartolucci and Farcomeni (2019), and the observation times are generated uniformly at random over the time interval. All the parameters are set the same as the configuration in Bartolucci and Farcomeni (2019)'s simulation study, except that we fix the number of hidden state as four and the separation parameter, $\\omega=3$. In our study, we vary the number of individuals, $n$, the maximum number of follow-up occasions, $T_{\\max }$, the number of equally spaced time windows $M$ used in the Bartolucci and Farcomeni (2019) discrete approximation, and the separation parameter for the random effect.\n\nAs our primary target was to estimate the latent process, we compare the norm differences of the estimates and true values for the infinitesimal generator $Q$, using both methods with EM convergence tolerance $10^{-3}$. Table 2 shows the simulation results averaged over 1000 replicates.\n[Table 2 about here.]"
    },
    {
      "markdown": "Our method has smaller norm difference compared with Bartolucci and Farcomeni (2019)'s calculation when $M=20$. When we increased $T_{\\max }$, as we found in the main paper, the norm differences decreased since we have more observations per subject. However, Bartolucci and Farcomeni (2019)'s method was not affected too much by this factor, and the difference did not change much. In addition, the standard errors over 1000 replicates of our method are much smaller, with similar consequent difference in root mean square errors. As Bartolucci and Farcomeni (2019) noticed in their simulation study, the parameter estimates are more dependent on the choice of the grid density as the discrete approximation for the likelihood is used. We also compared the computation time. For case when $n=50$ and $T_{\\max }=10$, the average computation time per replicate over 100 replicates for our method is 12 seconds while Bartolucci and Farcomeni (2019)'s method took on average 13 and 16 seconds for $M=20,100$ respectively on a 12 -core $\\operatorname{Intel}(\\mathrm{R}) \\operatorname{Xeon}(\\mathrm{R}) \\mathrm{CPU}(\\mathrm{X} 5690,3.47 \\mathrm{GHz})$. When $n=50$ and $T_{\\max }=60$, the average computation time per replicate is $33,37,41$ seconds for our method and Bartolucci and Farcomeni (2019)'s approach of $M=20,100$ respectively.\n\n# 4. Web Appendix D: Real data analysis \n\n### 4.1 EM Analysis\n\n[Figure 1 about here.]\n\n### 4.2 Fully Bayesian analysis\n\n4.2.1 Prior distributions.\n\n$$\n\\begin{aligned}\n\\pi & \\sim \\text { Dirichlet }(1,1,1) \\\\\n\\beta_{i j} & \\sim \\mathcal{N}\\left(\\left(\\mathbf{B}_{\\mathbf{0}}\\right)_{i, j}, 2\\right), i=1,2,3,4 ; j=1,2,3 \\\\\n\\xi_{0, l m} & \\sim \\mathcal{N}\\left(\\left(\\mathbf{M}_{\\mathbf{0}}\\right)_{i, j}, 1\\right), 1 \\leqslant l \\neq m \\leqslant 3 \\\\\n\\xi_{1, l m} & \\sim \\mathcal{N}(0,0.5), 1 \\leqslant l \\neq m \\leqslant 3\n\\end{aligned}\n$$"
    },
    {
      "markdown": "where\n\n$$\n\\mathbf{B}_{0}=\\left(\\begin{array}{ccc}\n\\log (0.1) & \\log (5) & \\log (10) \\\\\n0.0 & 0.0 & 0.0 \\\\\n0.0 & 0.0 & 0.0 \\\\\n0.0 & 0.0 & 0.0\n\\end{array}\\right) \\quad \\mathbf{M}_{0}=\\left(\\begin{array}{ccc}\n0 & -1 & -5 \\\\\n-3 & 0 & -4 \\\\\n-6 & -5 & 0\n\\end{array}\\right)\n$$\n\n4.2.2 Application: Results of the fully Bayesian analysis.\n[Table 3 about here.]\n[Figure 2 about here.]\n[Figure 3 about here.]\n[Figure 4 about here.]\n[Figure 5 about here.]\n[Figure 6 about here.]\n\n# REFERENCES \n\nBartolucci, F. and Farcomeni, A. (2019). A shared-parameter continuous-time hidden Markov and survival model for longitudinal data with informative dropout. Statistics in Medicine 38, 1056-1073.\n\nBaum, L. and Eagon, J. (1967). An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology. Bulletin of the American Mathematical Society 73, 360-363.\n\nBaum, L. and Sell, G. (1968). Growth transformations for functions on manifolds. Pacific Journal of Mathematics 27, 211-227.\n\nBaum, L. E., Petrie, T., Soules, G., and Weiss, N. (1970). A maximization technique occurring in the statistical analysis of probabilistic functions of markov chains. The Annals of Mathematical Statistics 41, 164-171."
    },
    {
      "markdown": "Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977). Maximum likelihood from incomplete data via the EM algorithm (with discussion). Journal of the Royal Statistical Society. Series B (Statistical Methodology) 39, 1-38.\n\nJackson, C. H. (2011). Multi-state models for panel data: the msm package for R. Journal of Statistical Software 38, 1-29.\n\nLange, J., Hubbard, R., Inoue, L., and Minin, V. (2015). A joint model for multi-state disease processes and random informative observation times, with applications to electronic medical records data. Biometrics 71, 90-101.\n\nMark, B. L. and Ephraim, Y. (2013). An EM algorithm for continuous-time bivariate Markov chains. Computational Statistics \\& Data Analysis 57, 504-517.\n\nMetzner, P., Horenko, I., and Schütte, C. (2007). Generator estimation of Markov jump processes based on incomplete observations nonequidistant in time. Physical Review E. 76, 066702 .\n\nRydén, T. (1996). An EM algorithm for estimation in Markov-modulated Poisson processes. Computational Statistics \\& Data Analysis 21, 431-447."
    },
    {
      "markdown": "Figure 1. EM Analysis: Residual Plot of the 3-State Poisson Model\n![img-3.jpeg](img-3.jpeg)"
    },
    {
      "markdown": "Figure 2. Fully Bayesian analysis: Trace plots for coefficients $\\xi$ (parameters in the infinitesimal generator) in the COPD application.\n![img-4.jpeg](img-4.jpeg)"
    },
    {
      "markdown": "Figure 3. Fully Bayesian analysis: Trace plots for the initial distribution $\\pi$ in the COPD application.\n![img-5.jpeg](img-5.jpeg)"
    },
    {
      "markdown": "Figure 4. Fully Bayesian analysis: Trace plots for coefficients $\\beta$ (parameters in the GLM for each state) in the COPD application.\n![img-6.jpeg](img-6.jpeg)"
    },
    {
      "markdown": "Figure 5. Fully Bayesian analysis: The dotted lines represent transition probability over time at age 66 and the solid lines represent transition probability over time at age 80 . State $1,2,3$ are in black, red and green respectively. The shading represent the $95 \\%$ credible intervals.\n![img-7.jpeg](img-7.jpeg)"
    },
    {
      "markdown": "Figure 6. Fully Bayesian analysis: Box plot of Posterior samples of Number of Expected Drugs for Individual Patients at Age 66 and 80.\n![img-8.jpeg](img-8.jpeg)"
    },
    {
      "markdown": "Table 1\nSimulation studies with 4 Latent States.\n\n| Iterations | Example 3.1 |  |  | Example 3.2 |  |  | Example 3.3 |  |  |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  | EM | MCMC |  | EM | MCMC |  | EM | MCMC |  |\n|  |  | 3000 | 10000 |  | 3000 | 10000 |  | 3000 | 10000 |\n| $\\left\\|\\bar{B}-\\bar{B}\\right\\|$ | 0.12 | 0.11 | 0.11 | 0.08 | 0.08 | 0.08 | 0.12 | 0.13 | 0.13 |\n| $\\left\\|\\xi_{0}-\\bar{\\xi}_{0}\\right\\|$ | 0.43 | 0.38 | 0.37 | 1.30 | 1.18 | 1.12 | 1.39 | 0.52 | 0.53 |\n| $\\left\\|\\xi_{1}-\\bar{\\xi}_{1}\\right\\|$ | 0.57 | 0.58 | 0.59 | 1.16 | 0.91 | 0.91 | 1.22 | 0.57 | 0.57 |\n| $\\|\\pi-\\bar{\\pi}\\|$ | 0.06 | 0.04 | 0.04 | 0.08 | 0.09 | 0.09 | - | - | - |\n| $\\left\\|\\mathbf{C}-\\overline{\\mathbf{C}}\\right\\|$ | - |  | - | - |  | - | 0.84 | 0.58 | 0.58 |\n| Reconstruction Rate | $82.75 \\%$ | $82.74 \\%$ | $82.74 \\%$ | $80.30 \\%$ | $80.29 \\%$ | $80.30 \\%$ | $82.50 \\%$ | $82.49 \\%$ | $82.48 \\%$ |"
    },
    {
      "markdown": "Table 2\nSimulation results averaged over 1000 replicates (with standard errors (SEs)): norm differences between the true $Q$ and the estimate, $\\|\\mathbf{Q}-\\overline{\\mathbf{Q}}\\|$ using the EM algorithm with our method (CTHMM-GLM) and Bartolucci and Farcomeni (2019)'s approach (BF), for different values of $n$ with four hidden states.\n\n| $n$ | $T_{\\max }$ | Approach | Average norm difference (SE) | Root mean square error | Average computation time per replicate (second) |\n| :--: | :--: | :--: | :--: | :--: | :--: |\n| 500 | 10 | CTHMM-GLM | $0.361(0.078)$ | 0.369 | 12 |\n|  |  | BF $M=20$ | $0.419(0.198)$ | 0.463 | 13 |\n|  |  | BF $M=100$ | $0.328(0.241)$ | 0.407 | 16 |\n| 500 | 60 | CTHMM-GLM | $0.225(0.045)$ | 0.229 | 17 |\n|  |  | BF $M=20$ | $0.436(0.398)$ | 0.590 | 14 |\n|  |  | BF $M=100$ | $0.319(0.438)$ | 0.542 | 17 |\n| 1000 | 10 | CTHMM-GLM | $0.344(0.062)$ | 0.350 | 25 |\n|  |  | BF $M=20$ | $0.367(0.207)$ | 0.421 | 35 |\n|  |  | BF $M=100$ | $0.315(0.243)$ | 0.398 | 38 |\n| 1000 | 60 | CTHMM-GLM | $0.205(0.035)$ | 0.208 | 33 |\n|  |  | BF $M=20$ | $0.394(0.424)$ | 0.579 | 37 |\n|  |  | BF $M=100$ | $0.351(0.517)$ | 0.625 | 41 |"
    },
    {
      "markdown": "Table 3\nResults of the fully Bayesian analysis: Effective sample sizes (ESSs) for 2000 MCMC samples\n\n| Parameter | ESS | Parameter | ESS | Parameter | ESS |\n| :--: | :--: | :--: | :--: | :--: | :--: |\n| $\\xi_{0,12}$ | 769.69 | $\\pi_{1}$ | 1694.37 | $\\beta_{41}$ | 760.54 |\n| $\\xi_{0,13}$ | 855.19 | $\\pi_{2}$ | 1293.83 | $\\beta_{42}$ | 1092.35 |\n| $\\xi_{0,21}$ | 714.55 | $\\pi_{3}$ | 1572.90 | $\\beta_{43}$ | 1460.01 |\n| $\\xi_{0,23}$ | 852.28 | $\\beta_{11}$ | 700.05 |  |  |\n| $\\xi_{0,31}$ | 1158.22 | $\\beta_{12}$ | 485.23 |  |  |\n| $\\xi_{0,32}$ | 719.40 | $\\beta_{13}$ | 785.43 |  |  |\n| $\\xi_{1,12}$ | 741.92 | $\\beta_{21}$ | 831.78 |  |  |\n| $\\xi_{1,13}$ | 800.09 | $\\beta_{22}$ | 1037.92 |  |  |\n| $\\xi_{1,21}$ | 715.50 | $\\beta_{23}$ | 1532.66 |  |  |\n| $\\xi_{1,23}$ | 823.43 | $\\beta_{31}$ | 1119.16 |  |  |\n| $\\xi_{1,31}$ | 1185.80 | $\\beta_{32}$ | 1533.86 |  |  |\n| $\\xi_{1,32}$ | 693.04 | $\\beta_{33}$ | 1695.19 |  |  |"
    }
  ],
  "usage_info": {
    "pages_processed": 55,
    "doc_size_bytes": 2121306
  },
  "_metadata": {
    "model_version": "0.0.0",
    "llm_model": "mistral-ocr-2505",
    "query_data": {
      "pdf": "/Users/satyaortiz-gagne/CODE/paperext/data/cache/fulltext/8174b267177444c4c58ec6db34b8e878/fulltext.pdf"
    },
    "model_id": "parsepdf"
  }
}